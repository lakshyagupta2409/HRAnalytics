{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NphQoUAj6ZlA"
   },
   "source": [
    "# <div style=\"text-align: center\"> HR Analytics Data Exploration and Cleaning </div>                               \n",
    "\n",
    "\n",
    "####      <div style=\"text-align: right\">  by- Lakshya Gupta & Abhiraj Singh</div>           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JAFowhTO6ZlD"
   },
   "source": [
    "# Introduction\n",
    "HR analytics is revolutionising the way human resources departments operate, leading to higher efficiency and better results overall. Human resources has been using analytics for years. However, the collection, processing and analysis of data has been largely manual, and given the nature of human resources dynamics and HR KPIs, the approach has been constraining HR. Therefore, it is surprising that HR departments woke up to the utility of machine learning so late in the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "pURKSHFL6ZlG",
    "outputId": "b2f3313d-698c-4982-e680-846a4baca484"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rTbwrRFW6ZlS"
   },
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPIDKzb36Zld"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rtQd80rN6Zlk",
    "outputId": "26adb522-9163-41e8-f819-fdd6b5511ddc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id         department     region         education gender  \\\n",
       "0        65438  Sales & Marketing   region_7  Master's & above      f   \n",
       "1        65141         Operations  region_22        Bachelor's      m   \n",
       "2         7513  Sales & Marketing  region_19        Bachelor's      m   \n",
       "3         2542  Sales & Marketing  region_23        Bachelor's      m   \n",
       "4        48945         Technology  region_26        Bachelor's      m   \n",
       "\n",
       "  recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0            sourcing                1   35                   5.0   \n",
       "1               other                1   30                   5.0   \n",
       "2            sourcing                1   34                   3.0   \n",
       "3               other                2   39                   1.0   \n",
       "4               other                1   45                   3.0   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0                  8              1            0                  49   \n",
       "1                  4              0            0                  60   \n",
       "2                  7              0            0                  50   \n",
       "3                 10              0            0                  50   \n",
       "4                  2              0            0                  73   \n",
       "\n",
       "   is_promoted  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>53478</td>\n",
       "      <td>Legal</td>\n",
       "      <td>region_2</td>\n",
       "      <td>Below Secondary</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23486</th>\n",
       "      <td>25600</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_25</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23487</th>\n",
       "      <td>45409</td>\n",
       "      <td>HR</td>\n",
       "      <td>region_16</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>1186</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>region_31</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23489</th>\n",
       "      <td>5973</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_17</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       employee_id   department     region         education gender  \\\n",
       "23485        53478        Legal   region_2   Below Secondary      m   \n",
       "23486        25600   Technology  region_25        Bachelor's      m   \n",
       "23487        45409           HR  region_16        Bachelor's      f   \n",
       "23488         1186  Procurement  region_31        Bachelor's      m   \n",
       "23489         5973   Technology  region_17  Master's & above      m   \n",
       "\n",
       "      recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "23485            sourcing                1   24                   3.0   \n",
       "23486            sourcing                1   31                   3.0   \n",
       "23487            sourcing                1   26                   4.0   \n",
       "23488            sourcing                3   27                   NaN   \n",
       "23489               other                3   40                   5.0   \n",
       "\n",
       "       length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \n",
       "23485                  1              0            0                  61  \n",
       "23486                  7              0            0                  74  \n",
       "23487                  4              0            0                  50  \n",
       "23488                  1              0            0                  70  \n",
       "23489                  5              1            0                  89  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gP3X1FjB6Zlt",
    "outputId": "3ac914d9-c839-4295-eda8-f5a2ac8bfccd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>50684.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39195.830627</td>\n",
       "      <td>1.253011</td>\n",
       "      <td>34.803915</td>\n",
       "      <td>3.329256</td>\n",
       "      <td>5.865512</td>\n",
       "      <td>0.351974</td>\n",
       "      <td>0.023172</td>\n",
       "      <td>63.386750</td>\n",
       "      <td>0.085170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22586.581449</td>\n",
       "      <td>0.609264</td>\n",
       "      <td>7.660169</td>\n",
       "      <td>1.259993</td>\n",
       "      <td>4.265094</td>\n",
       "      <td>0.477590</td>\n",
       "      <td>0.150450</td>\n",
       "      <td>13.371559</td>\n",
       "      <td>0.279137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19669.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39225.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58730.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78298.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        employee_id  no_of_trainings           age  previous_year_rating  \\\n",
       "count  54808.000000     54808.000000  54808.000000          50684.000000   \n",
       "mean   39195.830627         1.253011     34.803915              3.329256   \n",
       "std    22586.581449         0.609264      7.660169              1.259993   \n",
       "min        1.000000         1.000000     20.000000              1.000000   \n",
       "25%    19669.750000         1.000000     29.000000              3.000000   \n",
       "50%    39225.500000         1.000000     33.000000              3.000000   \n",
       "75%    58730.500000         1.000000     39.000000              4.000000   \n",
       "max    78298.000000        10.000000     60.000000              5.000000   \n",
       "\n",
       "       length_of_service  KPIs_met >80%   awards_won?  avg_training_score  \\\n",
       "count       54808.000000   54808.000000  54808.000000        54808.000000   \n",
       "mean            5.865512       0.351974      0.023172           63.386750   \n",
       "std             4.265094       0.477590      0.150450           13.371559   \n",
       "min             1.000000       0.000000      0.000000           39.000000   \n",
       "25%             3.000000       0.000000      0.000000           51.000000   \n",
       "50%             5.000000       0.000000      0.000000           60.000000   \n",
       "75%             7.000000       1.000000      0.000000           76.000000   \n",
       "max            37.000000       1.000000      1.000000           99.000000   \n",
       "\n",
       "        is_promoted  \n",
       "count  54808.000000  \n",
       "mean       0.085170  \n",
       "std        0.279137  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describeDf=train.describe()\n",
    "print(type(describeDf))\n",
    "describeDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zGfFm7CX6Zl1"
   },
   "outputs": [],
   "source": [
    "y_train=train['is_promoted']\n",
    "x_train=train.drop(columns=['is_promoted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=54808, step=1)\n",
      "RangeIndex(start=0, stop=23490, step=1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.index)\n",
    "print(test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_file = x_train.append(test,ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78298, 13)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fIkmywP36Zl7"
   },
   "outputs": [],
   "source": [
    "#preprocess pipeline\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "dropColumnList= ['employee_id']\n",
    "imputeList = ['education']\n",
    "knnImputeList = ['previous_year_rating']\n",
    "catColumnList=['department', 'region','education','gender','recruitment_channel']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "09-Nivcg6ZmC"
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "* drop columns\n",
    "* NA values of education\n",
    "* KNN Impute for previous_year_rating\n",
    "* onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentile(array):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Sales & Marketing\n",
       "1               Operations\n",
       "2        Sales & Marketing\n",
       "3        Sales & Marketing\n",
       "4               Technology\n",
       "               ...        \n",
       "78293                Legal\n",
       "78294           Technology\n",
       "78295                   HR\n",
       "78296          Procurement\n",
       "78297           Technology\n",
       "Name: department, Length: 78298, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_file['department']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([49, 50, 50, ..., 49, 49, 51], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departmentVals=append_file['avg_training_score'][append_file['department']==append_file['department'][0]]\n",
    "departmentVals.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "percentile=[]\n",
    "for ind in append_file.index: \n",
    "    departmentVals=append_file['avg_training_score'][append_file['department']==append_file['department'][ind]].values\n",
    "    perc =stats.percentileofscore(departmentVals, append_file['avg_training_score'][ind])\n",
    "    percentile.append(perc)\n",
    "     #print(append_file['department'][ind]) \n",
    "    #append_file['training_score_percentile']=append_file['avg_training_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_file['spending_percentile']=percentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "append_file['work_fraction'] = append_file['length_of_service'] / append_file['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>spending_percentile</th>\n",
       "      <th>work_fraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>41.579383</td>\n",
       "      <td>0.228571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>54.543198</td>\n",
       "      <td>0.133333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>55.555786</td>\n",
       "      <td>0.205882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>55.555786</td>\n",
       "      <td>0.256410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0.847374</td>\n",
       "      <td>0.044444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78293</th>\n",
       "      <td>53478</td>\n",
       "      <td>Legal</td>\n",
       "      <td>region_2</td>\n",
       "      <td>Below Secondary</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>69.373315</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78294</th>\n",
       "      <td>25600</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_25</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "      <td>2.000197</td>\n",
       "      <td>0.225806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78295</th>\n",
       "      <td>45409</td>\n",
       "      <td>HR</td>\n",
       "      <td>region_16</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>55.209820</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78296</th>\n",
       "      <td>1186</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>region_31</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>54.976373</td>\n",
       "      <td>0.037037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78297</th>\n",
       "      <td>5973</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_17</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>97.787959</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78298 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       employee_id         department     region         education gender  \\\n",
       "0            65438  Sales & Marketing   region_7  Master's & above      f   \n",
       "1            65141         Operations  region_22        Bachelor's      m   \n",
       "2             7513  Sales & Marketing  region_19        Bachelor's      m   \n",
       "3             2542  Sales & Marketing  region_23        Bachelor's      m   \n",
       "4            48945         Technology  region_26        Bachelor's      m   \n",
       "...            ...                ...        ...               ...    ...   \n",
       "78293        53478              Legal   region_2   Below Secondary      m   \n",
       "78294        25600         Technology  region_25        Bachelor's      m   \n",
       "78295        45409                 HR  region_16        Bachelor's      f   \n",
       "78296         1186        Procurement  region_31        Bachelor's      m   \n",
       "78297         5973         Technology  region_17  Master's & above      m   \n",
       "\n",
       "      recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0                sourcing                1   35                   5.0   \n",
       "1                   other                1   30                   5.0   \n",
       "2                sourcing                1   34                   3.0   \n",
       "3                   other                2   39                   1.0   \n",
       "4                   other                1   45                   3.0   \n",
       "...                   ...              ...  ...                   ...   \n",
       "78293            sourcing                1   24                   3.0   \n",
       "78294            sourcing                1   31                   3.0   \n",
       "78295            sourcing                1   26                   4.0   \n",
       "78296            sourcing                3   27                   NaN   \n",
       "78297               other                3   40                   5.0   \n",
       "\n",
       "       length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0                      8              1            0                  49   \n",
       "1                      4              0            0                  60   \n",
       "2                      7              0            0                  50   \n",
       "3                     10              0            0                  50   \n",
       "4                      2              0            0                  73   \n",
       "...                  ...            ...          ...                 ...   \n",
       "78293                  1              0            0                  61   \n",
       "78294                  7              0            0                  74   \n",
       "78295                  4              0            0                  50   \n",
       "78296                  1              0            0                  70   \n",
       "78297                  5              1            0                  89   \n",
       "\n",
       "       spending_percentile  work_fraction  \n",
       "0                41.579383       0.228571  \n",
       "1                54.543198       0.133333  \n",
       "2                55.555786       0.205882  \n",
       "3                55.555786       0.256410  \n",
       "4                 0.847374       0.044444  \n",
       "...                    ...            ...  \n",
       "78293            69.373315       0.041667  \n",
       "78294             2.000197       0.225806  \n",
       "78295            55.209820       0.153846  \n",
       "78296            54.976373       0.037037  \n",
       "78297            97.787959       0.125000  \n",
       "\n",
       "[78298 rows x 15 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84       96.563342\n",
       "156      88.241240\n",
       "208      29.851752\n",
       "257      93.665768\n",
       "272      79.986523\n",
       "           ...    \n",
       "78065    56.704852\n",
       "78095    93.665768\n",
       "78198    56.704852\n",
       "78283    69.373315\n",
       "78293    69.373315\n",
       "Name: spending_percentile, Length: 1484, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "append_file['spending_percentile'][append_file['department']=='Legal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x229bea78d48>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(append_file['avg_training_score'][append_file['department']=='Sales & Marketing'],append_file['spending_percentile'][append_file['department']=='Sales & Marketing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IlVfKHTl6ZmD"
   },
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    \n",
    "    data = data.drop(columns=['employee_id','avg_training_score'])   #drop columns\n",
    "    \n",
    "    for column in imputeList:\n",
    "        data[column].fillna('unknown',inplace=True)\n",
    "        \n",
    "    data= pd.get_dummies(data) \n",
    "    \n",
    "    data_columns=data.columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=11)\n",
    "    data=imputer.fit_transform(data)\n",
    "    \n",
    "    data=pd.DataFrame(data, columns=data_columns)\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=preprocessing(append_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(78298, 60)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=data.iloc[:y_train.shape[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54808, 60)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=data.iloc[y_train.shape[0]:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8724</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74430</td>\n",
       "      <td>HR</td>\n",
       "      <td>region_4</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72255</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_13</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38562</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>region_2</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "      <td>31</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64486</td>\n",
       "      <td>Finance</td>\n",
       "      <td>region_29</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>53478</td>\n",
       "      <td>Legal</td>\n",
       "      <td>region_2</td>\n",
       "      <td>Below Secondary</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23486</th>\n",
       "      <td>25600</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_25</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23487</th>\n",
       "      <td>45409</td>\n",
       "      <td>HR</td>\n",
       "      <td>region_16</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>1186</td>\n",
       "      <td>Procurement</td>\n",
       "      <td>region_31</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23489</th>\n",
       "      <td>5973</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_17</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23490 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       employee_id         department     region         education gender  \\\n",
       "0             8724         Technology  region_26        Bachelor's      m   \n",
       "1            74430                 HR   region_4        Bachelor's      f   \n",
       "2            72255  Sales & Marketing  region_13        Bachelor's      m   \n",
       "3            38562        Procurement   region_2        Bachelor's      f   \n",
       "4            64486            Finance  region_29        Bachelor's      m   \n",
       "...            ...                ...        ...               ...    ...   \n",
       "23485        53478              Legal   region_2   Below Secondary      m   \n",
       "23486        25600         Technology  region_25        Bachelor's      m   \n",
       "23487        45409                 HR  region_16        Bachelor's      f   \n",
       "23488         1186        Procurement  region_31        Bachelor's      m   \n",
       "23489         5973         Technology  region_17  Master's & above      m   \n",
       "\n",
       "      recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0                sourcing                1   24                   NaN   \n",
       "1                   other                1   31                   3.0   \n",
       "2                   other                1   31                   1.0   \n",
       "3                   other                3   31                   2.0   \n",
       "4                sourcing                1   30                   4.0   \n",
       "...                   ...              ...  ...                   ...   \n",
       "23485            sourcing                1   24                   3.0   \n",
       "23486            sourcing                1   31                   3.0   \n",
       "23487            sourcing                1   26                   4.0   \n",
       "23488            sourcing                3   27                   NaN   \n",
       "23489               other                3   40                   5.0   \n",
       "\n",
       "       length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \n",
       "0                      1              1            0                  77  \n",
       "1                      5              0            0                  51  \n",
       "2                      4              0            0                  47  \n",
       "3                      9              0            0                  65  \n",
       "4                      7              0            0                  61  \n",
       "...                  ...            ...          ...                 ...  \n",
       "23485                  1              0            0                  61  \n",
       "23486                  7              0            0                  74  \n",
       "23487                  4              0            0                  50  \n",
       "23488                  1              0            0                  70  \n",
       "23489                  5              1            0                  89  \n",
       "\n",
       "[23490 rows x 13 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>department_Analytics</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>...</th>\n",
       "      <th>region_region_9</th>\n",
       "      <th>education_Bachelor's</th>\n",
       "      <th>education_Below Secondary</th>\n",
       "      <th>education_Master's &amp; above</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>54808</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.545455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54809</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54810</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54811</th>\n",
       "      <td>3.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54812</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78293</th>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78294</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78295</th>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78296</th>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78297</th>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23490 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       no_of_trainings   age  previous_year_rating  length_of_service  \\\n",
       "54808              1.0  24.0              3.545455                1.0   \n",
       "54809              1.0  31.0              3.000000                5.0   \n",
       "54810              1.0  31.0              1.000000                4.0   \n",
       "54811              3.0  31.0              2.000000                9.0   \n",
       "54812              1.0  30.0              4.000000                7.0   \n",
       "...                ...   ...                   ...                ...   \n",
       "78293              1.0  24.0              3.000000                1.0   \n",
       "78294              1.0  31.0              3.000000                7.0   \n",
       "78295              1.0  26.0              4.000000                4.0   \n",
       "78296              3.0  27.0              2.909091                1.0   \n",
       "78297              3.0  40.0              5.000000                5.0   \n",
       "\n",
       "       KPIs_met >80%  awards_won?  avg_training_score  department_Analytics  \\\n",
       "54808            1.0          0.0                77.0                   0.0   \n",
       "54809            0.0          0.0                51.0                   0.0   \n",
       "54810            0.0          0.0                47.0                   0.0   \n",
       "54811            0.0          0.0                65.0                   0.0   \n",
       "54812            0.0          0.0                61.0                   0.0   \n",
       "...              ...          ...                 ...                   ...   \n",
       "78293            0.0          0.0                61.0                   0.0   \n",
       "78294            0.0          0.0                74.0                   0.0   \n",
       "78295            0.0          0.0                50.0                   0.0   \n",
       "78296            0.0          0.0                70.0                   0.0   \n",
       "78297            1.0          0.0                89.0                   0.0   \n",
       "\n",
       "       department_Finance  department_HR  ...  region_region_9  \\\n",
       "54808                 0.0            0.0  ...              0.0   \n",
       "54809                 0.0            1.0  ...              0.0   \n",
       "54810                 0.0            0.0  ...              0.0   \n",
       "54811                 0.0            0.0  ...              0.0   \n",
       "54812                 1.0            0.0  ...              0.0   \n",
       "...                   ...            ...  ...              ...   \n",
       "78293                 0.0            0.0  ...              0.0   \n",
       "78294                 0.0            0.0  ...              0.0   \n",
       "78295                 0.0            1.0  ...              0.0   \n",
       "78296                 0.0            0.0  ...              0.0   \n",
       "78297                 0.0            0.0  ...              0.0   \n",
       "\n",
       "       education_Bachelor's  education_Below Secondary  \\\n",
       "54808                   1.0                        0.0   \n",
       "54809                   1.0                        0.0   \n",
       "54810                   1.0                        0.0   \n",
       "54811                   1.0                        0.0   \n",
       "54812                   1.0                        0.0   \n",
       "...                     ...                        ...   \n",
       "78293                   0.0                        1.0   \n",
       "78294                   1.0                        0.0   \n",
       "78295                   1.0                        0.0   \n",
       "78296                   1.0                        0.0   \n",
       "78297                   0.0                        0.0   \n",
       "\n",
       "       education_Master's & above  education_unknown  gender_f  gender_m  \\\n",
       "54808                         0.0                0.0       0.0       1.0   \n",
       "54809                         0.0                0.0       1.0       0.0   \n",
       "54810                         0.0                0.0       0.0       1.0   \n",
       "54811                         0.0                0.0       1.0       0.0   \n",
       "54812                         0.0                0.0       0.0       1.0   \n",
       "...                           ...                ...       ...       ...   \n",
       "78293                         0.0                0.0       0.0       1.0   \n",
       "78294                         0.0                0.0       0.0       1.0   \n",
       "78295                         0.0                0.0       1.0       0.0   \n",
       "78296                         0.0                0.0       0.0       1.0   \n",
       "78297                         1.0                0.0       0.0       1.0   \n",
       "\n",
       "       recruitment_channel_other  recruitment_channel_referred  \\\n",
       "54808                        0.0                           0.0   \n",
       "54809                        1.0                           0.0   \n",
       "54810                        1.0                           0.0   \n",
       "54811                        1.0                           0.0   \n",
       "54812                        0.0                           0.0   \n",
       "...                          ...                           ...   \n",
       "78293                        0.0                           0.0   \n",
       "78294                        0.0                           0.0   \n",
       "78295                        0.0                           0.0   \n",
       "78296                        0.0                           0.0   \n",
       "78297                        1.0                           0.0   \n",
       "\n",
       "       recruitment_channel_sourcing  \n",
       "54808                           1.0  \n",
       "54809                           0.0  \n",
       "54810                           0.0  \n",
       "54811                           0.0  \n",
       "54812                           1.0  \n",
       "...                             ...  \n",
       "78293                           1.0  \n",
       "78294                           1.0  \n",
       "78295                           1.0  \n",
       "78296                           1.0  \n",
       "78297                           0.0  \n",
       "\n",
       "[23490 rows x 59 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "7aRYPXf46ZmI",
    "outputId": "50471827-cb5c-43e9-c8d7-62ee5461027f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54808, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58896</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>region_2</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20379</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_20</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16290</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_34</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73202</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>region_20</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28911</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_1</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29934</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>49017</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employee_id         department     region         education gender  \\\n",
       "0         65438  Sales & Marketing   region_7  Master's & above      f   \n",
       "1         65141         Operations  region_22        Bachelor's      m   \n",
       "2          7513  Sales & Marketing  region_19        Bachelor's      m   \n",
       "3          2542  Sales & Marketing  region_23        Bachelor's      m   \n",
       "4         48945         Technology  region_26        Bachelor's      m   \n",
       "5         58896          Analytics   region_2        Bachelor's      m   \n",
       "6         20379         Operations  region_20        Bachelor's      f   \n",
       "7         16290         Operations  region_34  Master's & above      m   \n",
       "8         73202          Analytics  region_20        Bachelor's      m   \n",
       "9         28911  Sales & Marketing   region_1  Master's & above      m   \n",
       "10        29934         Technology  region_23               NaN      m   \n",
       "11        49017  Sales & Marketing   region_7        Bachelor's      f   \n",
       "\n",
       "   recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0             sourcing                1   35                   5.0   \n",
       "1                other                1   30                   5.0   \n",
       "2             sourcing                1   34                   3.0   \n",
       "3                other                2   39                   1.0   \n",
       "4                other                1   45                   3.0   \n",
       "5             sourcing                2   31                   3.0   \n",
       "6                other                1   31                   3.0   \n",
       "7             sourcing                1   33                   3.0   \n",
       "8                other                1   28                   4.0   \n",
       "9             sourcing                1   32                   5.0   \n",
       "10            sourcing                1   30                   NaN   \n",
       "11            sourcing                1   35                   5.0   \n",
       "\n",
       "    length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \n",
       "0                   8              1            0                  49  \n",
       "1                   4              0            0                  60  \n",
       "2                   7              0            0                  50  \n",
       "3                  10              0            0                  50  \n",
       "4                   2              0            0                  73  \n",
       "5                   7              0            0                  85  \n",
       "6                   5              0            0                  59  \n",
       "7                   6              0            0                  63  \n",
       "8                   5              0            0                  83  \n",
       "9                   5              1            0                  54  \n",
       "10                  1              0            0                  77  \n",
       "11                  3              1            0                  50  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_train.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "id": "CEeQBiLn6ZmP",
    "outputId": "1dfb87e5-c797-40db-db36-0ac479623dc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54808, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>department_Analytics</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>...</th>\n",
       "      <th>region_region_9</th>\n",
       "      <th>education_Bachelor's</th>\n",
       "      <th>education_Below Secondary</th>\n",
       "      <th>education_Master's &amp; above</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    no_of_trainings   age  previous_year_rating  length_of_service  \\\n",
       "0               1.0  35.0              5.000000                8.0   \n",
       "1               1.0  30.0              5.000000                4.0   \n",
       "2               1.0  34.0              3.000000                7.0   \n",
       "3               2.0  39.0              1.000000               10.0   \n",
       "4               1.0  45.0              3.000000                2.0   \n",
       "5               2.0  31.0              3.000000                7.0   \n",
       "6               1.0  31.0              3.000000                5.0   \n",
       "7               1.0  33.0              3.000000                6.0   \n",
       "8               1.0  28.0              4.000000                5.0   \n",
       "9               1.0  32.0              5.000000                5.0   \n",
       "10              1.0  30.0              2.909091                1.0   \n",
       "11              1.0  35.0              5.000000                3.0   \n",
       "\n",
       "    KPIs_met >80%  awards_won?  avg_training_score  department_Analytics  \\\n",
       "0             1.0          0.0                49.0                   0.0   \n",
       "1             0.0          0.0                60.0                   0.0   \n",
       "2             0.0          0.0                50.0                   0.0   \n",
       "3             0.0          0.0                50.0                   0.0   \n",
       "4             0.0          0.0                73.0                   0.0   \n",
       "5             0.0          0.0                85.0                   1.0   \n",
       "6             0.0          0.0                59.0                   0.0   \n",
       "7             0.0          0.0                63.0                   0.0   \n",
       "8             0.0          0.0                83.0                   1.0   \n",
       "9             1.0          0.0                54.0                   0.0   \n",
       "10            0.0          0.0                77.0                   0.0   \n",
       "11            1.0          0.0                50.0                   0.0   \n",
       "\n",
       "    department_Finance  department_HR  ...  region_region_9  \\\n",
       "0                  0.0            0.0  ...              0.0   \n",
       "1                  0.0            0.0  ...              0.0   \n",
       "2                  0.0            0.0  ...              0.0   \n",
       "3                  0.0            0.0  ...              0.0   \n",
       "4                  0.0            0.0  ...              0.0   \n",
       "5                  0.0            0.0  ...              0.0   \n",
       "6                  0.0            0.0  ...              0.0   \n",
       "7                  0.0            0.0  ...              0.0   \n",
       "8                  0.0            0.0  ...              0.0   \n",
       "9                  0.0            0.0  ...              0.0   \n",
       "10                 0.0            0.0  ...              0.0   \n",
       "11                 0.0            0.0  ...              0.0   \n",
       "\n",
       "    education_Bachelor's  education_Below Secondary  \\\n",
       "0                    0.0                        0.0   \n",
       "1                    1.0                        0.0   \n",
       "2                    1.0                        0.0   \n",
       "3                    1.0                        0.0   \n",
       "4                    1.0                        0.0   \n",
       "5                    1.0                        0.0   \n",
       "6                    1.0                        0.0   \n",
       "7                    0.0                        0.0   \n",
       "8                    1.0                        0.0   \n",
       "9                    0.0                        0.0   \n",
       "10                   0.0                        0.0   \n",
       "11                   1.0                        0.0   \n",
       "\n",
       "    education_Master's & above  education_unknown  gender_f  gender_m  \\\n",
       "0                          1.0                0.0       1.0       0.0   \n",
       "1                          0.0                0.0       0.0       1.0   \n",
       "2                          0.0                0.0       0.0       1.0   \n",
       "3                          0.0                0.0       0.0       1.0   \n",
       "4                          0.0                0.0       0.0       1.0   \n",
       "5                          0.0                0.0       0.0       1.0   \n",
       "6                          0.0                0.0       1.0       0.0   \n",
       "7                          1.0                0.0       0.0       1.0   \n",
       "8                          0.0                0.0       0.0       1.0   \n",
       "9                          1.0                0.0       0.0       1.0   \n",
       "10                         0.0                1.0       0.0       1.0   \n",
       "11                         0.0                0.0       1.0       0.0   \n",
       "\n",
       "    recruitment_channel_other  recruitment_channel_referred  \\\n",
       "0                         0.0                           0.0   \n",
       "1                         1.0                           0.0   \n",
       "2                         0.0                           0.0   \n",
       "3                         1.0                           0.0   \n",
       "4                         1.0                           0.0   \n",
       "5                         0.0                           0.0   \n",
       "6                         1.0                           0.0   \n",
       "7                         0.0                           0.0   \n",
       "8                         1.0                           0.0   \n",
       "9                         0.0                           0.0   \n",
       "10                        0.0                           0.0   \n",
       "11                        0.0                           0.0   \n",
       "\n",
       "    recruitment_channel_sourcing  \n",
       "0                            1.0  \n",
       "1                            0.0  \n",
       "2                            1.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "5                            1.0  \n",
       "6                            0.0  \n",
       "7                            1.0  \n",
       "8                            0.0  \n",
       "9                            1.0  \n",
       "10                           1.0  \n",
       "11                           1.0  \n",
       "\n",
       "[12 rows x 59 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=preprocessing(x_train)\n",
    "print(x_train.shape)\n",
    "x_train.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v1RDdyc06ZmU",
    "outputId": "6af5e2ae-3849-48b7-9d1e-101524136d6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10       2.909091\n",
       "23       3.000000\n",
       "29       3.545455\n",
       "56       3.272727\n",
       "58       3.727273\n",
       "           ...   \n",
       "54703    3.363636\n",
       "54734    3.454545\n",
       "54746    3.818182\n",
       "54773    3.363636\n",
       "54801    2.090909\n",
       "Name: previous_year_rating, Length: 4124, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputedRatingsDf=x_train[train['previous_year_rating'].isnull()]\n",
    "imputedRatings=imputedRatingsDf['previous_year_rating']\n",
    "imputedRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ISkaU0zu6Zmb",
    "outputId": "7a9a53a0-7bbf-4029-cd31-464b4d66b528"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22cf4962848>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEHCAYAAAC+1b08AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3xV5Z3v8c8v9zvkBgGSQIAARkSBCCretQ5YKz1qFdR22mnHTlun7fS0Pe2cju105kynnTntaae2Vq1j1VptrVWqWGy1RUEFwp1wvwQC4ZIEciOQ237OH3uDMSZkAztZe698369XXqy915O9vyzIL89+1lrPY845REQk9sV5HUBERCJDBV1ExCdU0EVEfEIFXUTEJ1TQRUR8IsGrN87Ly3Pjxo3z6u1FRGLS6tWr65xz+b3t86ygjxs3joqKCq/eXkQkJpnZ3r72achFRMQnVNBFRHxCBV1ExCdU0EVEfEIFXUTEJ1TQRUR8QgVdRMQnVNBFRHyi34JuZo+Z2REz29TH/nvMbEPo6y0zuzjyMUVEpD/h3Cn6OPBj4Ik+9u8BrnHOHTOzecDDwOzIxBOJTk+v2Nfr83fPLh7kJCLv6regO+feMLNxZ9j/VreH7wCF5x9LRETOVqTH0D8JvNLXTjO7z8wqzKyitrY2wm8tIjK0Raygm9l1BAv6/+qrjXPuYedcuXOuPD+/18nCRETkHEVktkUzmwY8CsxzztVH4jVFROTsnHcP3cyKgeeBjzrntp9/JBERORf99tDN7FfAtUCeme0HvgkkAjjnHgIeAHKBn5gZQKdzrnygAouISO/CucplYT/7PwV8KmKJRAaYLjkUv9KdoiIiPuHZEnQisaKvHr1ItFEPXUTEJ1TQRUR8QgVdRMQnVNBFRHxCBV1ExCdU0EVEfEIFXUTEJ1TQRUR8QgVdRMQnVNBFRHxCBV1ExCdU0EVEfEIFXUTEJzTbooiHNDe7RJJ66CIiPqGCLiLiEyroIiI+oYIuIuITKugiIj6hgi4i4hMq6CIiPqGCLiLiEyroIiI+0W9BN7PHzOyImW3qY7+Z2Y/MbKeZbTCzGZGPKSIi/Qnn1v/HgR8DT/Sxfx5QGvqaDfw09KfIkKNb+cVL/fbQnXNvAEfP0GQ+8IQLegcYbmajIhVQRETCE4kx9DFAdbfH+0PPvY+Z3WdmFWZWUVtbG4G3FhGRUyJR0K2X51xvDZ1zDzvnyp1z5fn5+RF4axEROSUS0+fuB4q6PS4EaiLwuiLnpa/xbBG/ikQPfRHwsdDVLpcBjc65gxF4XREROQv99tDN7FfAtUCeme0HvgkkAjjnHgIWAzcDO4FW4BMDFVZERPrWb0F3zi3sZ78DPhexRCIick60BJ3EPI2ViwTp1n8REZ9QQRcR8QkVdBERn1BBFxHxCRV0ERGfUEEXEfEJFXQREZ9QQRcR8QkVdBERn1BBFxHxCRV0ERGfUEEXEfEJFXQREZ9QQRcR8QkVdBERn1BBFxHxCRV0ERGf0IpFIn3YcbiZlzYcZEnlIZwDMyjOSeOCUVmMyEzGzLyOKPIeKugiPWyuaeLrz29g/f5GzGBEZjIJcXF0dAXYeqiZVzcfpig7lfmXjGH08FSv44qcpoIuEtIVcPzsjV384I/bGZaaxLc+VMbN00bxp81HTrdpPNFBZU0jf95Wy4N/3snlE3KZe2EBCfEavRTvqaCLAAHn+OpzG/jtmv3cfFEB//rhi8hJT3pfu2GpiVwxIY/pRdm8uvkQb+2q52DjSe6dPZbUpHgPkou8S90KGfKcc/x+fQ2/XbOfL95YyoN3z+i1mHeXmhTP/EvGcGd5EfvqW3nojV00tLYPUmKR3qmgy5D3xy2HWbHnKJ++ejxfuKH0rE52XlI0nE/MGUfzyQ4eXbaHppMdA5hU5MxU0GVI23aoib9sq6V8bDZfmzflnK5cGZ+fwcevKKHlZCf/vXwPre2dA5BUpH9hFXQzm2tm28xsp5l9rZf9xWb2ZzNba2YbzOzmyEcViaymEx38ZvV+CrJS+NDFo8/rMsTinDTuvWwsdS3tPP5WFW0dXeeV7ekV+973JdKffgu6mcUDDwLzgDJgoZmV9Wj2DeDXzrnpwALgJ5EOKhJJAef4dUU1HV0BFswqIjECV6lMHJHBwkuLqWk4wZPv7KWjKxCBpCLhC+d/8Sxgp3Nut3OuHXgGmN+jjQOyQtvDgJrIRRSJvBV7jrK77jgfmjaaEZkpEXvdstFZ3D6jkN11x/nVyn10BVzEXlukP+FctjgGqO72eD8wu0ebbwGvmtnfA+nAjRFJJ0NWb0MMd88ujshrN57o4NXKQ0wckcHMsdkRec3uphdn09YZYFHoypk7ZhZG/D1EehNOD723gcWe3Y6FwOPOuULgZuBJM3vfa5vZfWZWYWYVtbW1Z59WJAJe2lBDV8Ax/zzHzc/ksvG53FQ2knXVDfx+fQ3OqacuAy+cgr4fKOr2uJD3D6l8Evg1gHPubSAFyOv5Qs65h51z5c658vz8/HNLLHIethxsorKmieunjCA3I3lA3+uaSflcVZrHij1H+c9Xtw3oe4lAeAV9FVBqZiVmlkTwpOeiHm32ATcAmNkFBAu6uuASVdo6u1i0voaRWclcVTrwHQozY+6FBVw6LpsH/7yLny3dNeDvKUNbv2PozrlOM7sfWALEA4855yrN7NtAhXNuEfA/gUfM7B8IDsd83OkzpkSZP20+TOOJDhZcOp74uMGZKdHMmH/JGEZmpfCdV7aSlZrIwlmRORcg0lNYc7k45xYDi3s890C37c3AnMhGE4mcAw0neGtXPbNKchibmz6o7x1nxvfvvISWtk7+8XcbKchK4bopIwY1gwwNulNUfK8r4Hhh7QEykhP4q7ICTzIkJcTxk3tmcEFBFp9/Zi27als8ySH+poIuvrd8Zx0HGk5wy8WjPZ0RMS0pgYc/NpPE+Dj+9okKzfsiEaeCLr5W19zGn7YcpmxUFlNHZ/X/DQOsMDuNn94zg331rTzwwiav44jPqKCLbwWc47dr95MQb9x6ycBdc362Zo/P5bPXTeSFdTVsP9zsdRzxERV08a0Ve46yt76VD140mqyURK/jvMfnrpvA+Px0Xlx3gPZOzfkikaGCLr50rLWdJZWHKB2RwYzi4V7HeZ/khHj+/bZpHGvt4E9bDnsdR3xCBV18x7ngVS0AH54+JmqGWnqaVZJD+dhs3tpVxzGtdiQRoIIuvrNm3zF2HGlh7oUFZKedeSk5r91wwUjMjKXbdGO1nD8VdPGVphMdvLzxIONy05hVkuN1nH4NS02kfGw2q/ce05qkct5U0MU3nHO8sO4AXQHHbTMKiYvSoZaerpkUnFdm6Xb10uX8qKCLb6yrbmDroWY+UFZA3gDPpBhJw9OSmDE2m4q9x2g8oZuN5NypoIsvNJ/s4KUNBynOSeOKCblexzlr10zKJxBwrNhT73UUiWEq6BLznHO8uK6Gjq4At80YEzNDLd3lpCcxuSCTiqpjdAZ0XbqcGxV0iXkbDzSy+WATN14wMqLrgw622SU5tLR1srmmyesoEqNU0CWm1bW0sWh9DYXZqcyZ+L5FsmJK6chMstMSWbHnqNdRJEapoEtM+7eXt9DWGeD2GYWDtmjFQIkzY9a4HPbUHedw00mv40gMUkGXmLVm3zGeX3uAKyfmMTIrdodaups5Lod4M1aqly7nQAVdYlIg4Pjn329mRGYy107yz4LjGckJlI3OYl11A51dOjkqZyesJehEBsrTK/ad0/f9bu0B1lc38H8/cjFtPputcObYbDYeaGTroWamjhnmdRyJISroEnNOtHfx3T9s5eKi4fyP6WN4ZlW115EiauKIDLJSEliz79h5FfS+flnePVuLVPuVhlwk5jzxdhVHmtv4x3lTiIvxE6G9iTNjenE22w8306xl6uQsqIcuMaX5ZAc/XbqLq0rzmD0+9u4IDdf04uEs3V7LuuoGrioNniNQj1v6ox66xJSfL9tDQ2sHX75pstdRBtSIzBSKslNZvfcYzjmv40iMUEGXmHHseDuPvrmHm8pGcnFR9K1CFGkzxmZzpLmNAw0nvI4iMUIFXWLGf79VRUtbJ1+6aZLXUQbFtDHDSYgz1uw75nUUiRFhFXQzm2tm28xsp5l9rY82d5rZZjOrNLOnIxtThrq2zi5+8VYVHygbyZSCLK/jDIrUpHjKRmexvrpR16RLWPot6GYWDzwIzAPKgIVmVtajTSnwdWCOc+5C4IsDkFWGsFVVwbnCP3PtBK+jDKoZxdmc6Ohiy6Fmr6NIDAinhz4L2Omc2+2caweeAeb3aPO3wIPOuWMAzrkjkY0pQ1lnIMCyHbXMLslhRnG213EG1elr0vdq2EX6F05BHwN0v3Njf+i57iYBk8xsuZm9Y2ZzIxVQZH11A00nO/nsdRO9jjLoul+T3qRr0qUf4RT03u7c6HkdVQJQClwLLAQeNbP3XYZgZveZWYWZVdTWav1E6V/AOZZur2PUsBSuLo3t6XHP1YzibBywdl+D11EkyoVT0PcDRd0eFwI1vbR50TnX4ZzbA2wjWODfwzn3sHOu3DlXnp/vnwmVZOBsOdhEXUsb10zKx2JwJaJIyM9MZlxuGquqjhLQNelyBuEU9FVAqZmVmFkSsABY1KPNC8B1AGaWR3AIZnckg8rQ45xj6fZactKTuHD00J6kavb4XI4eb2fnkRavo0gU67egO+c6gfuBJcAW4NfOuUoz+7aZ3RpqtgSoN7PNwJ+BrzjntNqtnJfddcfZf+wEV5XmxfziFefrwtFZpCcn8M5u/VhJ38Kay8U5txhY3OO5B7ptO+BLoS8ZwiI538gb22vJSE4Ycle29CYhLo5Lx2azdHstDa3tDE9L8jqSRCHdKSpR6UDDCXYcaWHOhFwS4/XfFODSkhwAVlZpNSPpnX5SJCot3V5LckKcr2dUPFvZaUlMLshk1Z6jtPtsUQ+JDBV0iTp1zW1UHmjksvG5pCTGex0nqlxVms/x9i4q9qqXLu+ngi5R540dtcTHGVdMUO+8p5K8dMblpvHmjjo6A+qly3upoEtUaTzRwdp9Dcwcm01mSqLXcaLStZNHnD5OIt2poEtUWb6zDofj6lLdeNaX0hEZjBmeytLttXQFdKORvEsFXaJGa1snK/ccZVrhcLLTdVleX8yM6ybnc/R4u+ZKl/dQQZeo8fbuetq7Alw9Sb3z/lwwKouxOWm8uvmwJu2S01TQJSq0dXbx1q56phRkUpCV4nWcqGdm3DJtNK1tnfzXazu8jiNRQgVdokJF1TFOdHRxrXrnYRuTncrMsdn89/IqdtVqjhdRQZco0NEV4M0dtYzLTac4N93rODHlA2UjSU2M55svVuI0E+OQp4IunltVdZSmk53ccMEIr6PEnMyURL46bwrLdtbxq5XV/X+D+JoKuniqvTPA0m21lOSlMz5PvfNzcc+sYuZMzOX/vLyZ6qOtXscRD6mgi6dW7Kmnua2TGy8YOWQXsDhfcXHGd2+fhpnx1ec2ENC16UOWCrp45nhbJ29sr2VifgYl6p2fl8LsNL7xwQt4e3c9T63Y63Uc8YgKunjmsWV7ON7exY1lI72O4gt3XVrE1ZPy+c7ireytP+51HPGACrp4oq6ljYeW7uLC0VkU56R5HccXzIzv3n4RCfHGV36zQeuPDkEq6OKJH722g5OdAW4qK/A6iq+MGpbKA7eUsbLqqJarG4JU0GXQ7a5t4ekV+1g4q4j8zGSv4/jOHTMLuXpSPn/cfJimE5oWYChRQZdB9x9LtpGUEMcXbpjkdRRfMjO+feuFdAUcL2886HUcGUQq6DKoVu89xiubDvHpqyeodz6AxuWlc+3kfDYeaGT74Wav48ggUUGXQeOc4zuLt5CfmcynrirxOo7vXV2aT15GEr9fX6PVjYYIFXQZNK9uPkzF3mP8w42TSE9O8DqO7yXEx3HzRaOoP95ORZXmTR8K9FMlg6KjK8B3X9nKhPx07iwv9DrOkDF5ZCbjctN5fesRphcPJzkhnqdX7Ou17d2ziwc5nUSaCrqck76KQl+eXVXN7rrjPPKxchLi9cFwsJgZc6cW8NDSXSzfWcf1U3QTl5+F9ZNlZnPNbJuZ7TSzr52h3R1m5sysPHIRJda1dXbx//60g1njcrhRMyoOuuKcNMpGZfHmjjpa2jq9jiMDqN+CbmbxwIPAPKAMWGhmZb20ywQ+D6yIdEiJbct21FHX0sbXb56iCbg8clPZSNo7AyzbUet1FBlA4fTQZwE7nXO7nXPtwDPA/F7a/QvwPeBkBPNJjGs+2cGbO+r44EWjmF6c7XWcIWtEVgoXFQ7jnd1HOa5eum+FU9DHAN1nzt8feu40M5sOFDnnXopgNvGB17YeoTMQ4Ct/NdnrKEPe9ZNH0NEVYNnOOq+jyAAJp6D39hn59Kw/ZhYH/AD4n/2+kNl9ZlZhZhW1tfro53dHmk9SUXWU2SW5jNP0uJ471Ut/e1e9euk+FU5B3w8UdXtcCNR0e5wJTAX+YmZVwGXAot5OjDrnHnbOlTvnyvPztRiw371aeZjE+Dium6ITodHiOvXSfS2cgr4KKDWzEjNLAhYAi07tdM41OufynHPjnHPjgHeAW51zFQOSWGJCVd1xNh9s4upJ+WToJqKoMTIrhaljhvH27npa1Uv3nX4LunOuE7gfWAJsAX7tnKs0s2+b2a0DHVBij3OOVzYdJCslgTkT8ryOIz1cP2UEHZ0Blu1SL91vwuo6OecWA4t7PPdAH22vPf9YEssqa5qoPnaC26aPISlBNxFFm5FZKVw4JjiWfuXEPNKS9AnKL/QvKRHVFXAsqTzEiMxkXaYYxa6fPIJNBxpZvrOOD/SzyEhvdwVrmoDopO6TRNTKqqPUH29n7tQC4uN0E1G0KhiWwtTRWby1q57Wdo2l+4UKukTMyY4uXt9ymJK8dCaPzPQ6jvTj+ikjaesMsHynlqrzCxV0iZg3d9RxvL2LeVMLdIt/DCgYlsKFo7N4a1cdJ9q7vI4jEaCCLhHRdKKDZTtrmVY4jMLsNK/jSJiunzIi2EvXFS++oJOiQ9BAzIf92tbDBAJwUz8n2CS6jBqWStmoYC+98UQHw1ITvY4k50E9dDlvh5tOUlF1jMvG55CTnuR1HDlL108ZwcmOAD9busvrKHKe1EOX8/aHTYdITozjusm6xT8WjR6eyvSi4Tz65h4+Ul5ESRjz7mjVo+ikHrqcl22Hmth2uJnrJo8gTbf4x6y5UwtISojjW4sqcc71/w0SlVTQ5Zx1BgK8vPEgeRlJXD4h1+s4ch4yUxL54o2lLN1eyx83H/Y6jpwjFXQ5Z2/vqqeupZ0PXjSKhDj9V4p1f33FOCaNzOBbiyppPNHhdRw5B/qMLGfU11hp44kOXt96hMkjM5lckDXIqWQgJMbH8b07Lub2n77FAy9u4ocLpnsdSc6SulVy1pxzvLD2AAHnuGXaKK/jSARdUjScL9xQyovranhx3QGv48hZUkGXs7auuoFth5u5qayA3Ixkr+NIhH322gnMHJvNN17YRPXRVq/jyFlQQZez0nSyg5c2HKQ4J00nQn0qIT6OH9x5CQbc9+Rq2jsDXkeSMKmgS9i6Ao5nV1XT0RXg9hmFxGm+Ft8qzk3jRwuns/VQE8+v3a9LGWOECrqE7Q+bDrKn7jgfnj6G/EwNtfjdtZNH8JW/msyG/Y28uUNzvcQCFXQJy9p9x1i+q57LJ+QyQwtXDBmfuWYCU8cMY0nlIXYcbvY6jvRDBV36tbmmiefXHKAkL52bp+qqlqHEzLhjRiEjs1J4ZlU19S1tXkeSM1BBlzPaXNPIr1buY9TwFO6dPVarEA1BSQlx3HvZWACeWrGXtk7NnR6tVNClT8+s3MfTK/cxengKfzOnhNSkeK8jiUdy0pNYMKuII01t/Ha1TpJGKxV0eZ/2zgD/+3cb+drzG5mQn8En5pSQkqhiPtSVjshk7tQCNtU0sXR7rddxpBe69V/e40jzST771Boq9h7j09eMpyg7TZcnymlXTszjQMMJ/rj5MKOGpWjahyijHrqctq66gVv/azmbahr50cLpfH3eBSrm8h5mxm3TCykYlsKzFdXU6SRpVFFBFwA2Hmjkzp+9TUK88fxn5nDrxaO9jiRRKikhjntnjyXOjKfe2Utbh06SRgsVdGH5zjqeWbmPi8YMY9H9V1I2Wh+j5cyy05NYOKuYupY2nlujk6TRIqyCbmZzzWybme00s6/1sv9LZrbZzDaY2WtmNjbyUWUg/GnLYV7eeJALRmXxy0/N1pqgErYJ+RncVFZAZU0Ta6sbvI4jhHFS1MzigQeBDwD7gVVmtsg5t7lbs7VAuXOu1cw+A3wPuGsgAkv4+prL/JRlO2p5fesRZhRnc9uMMbqSRc7alaV5bD3UxO/X1zA+jLVIZWCF00OfBex0zu12zrUDzwDzuzdwzv3ZOXdqns13gMLIxpRIq6g6yuJNh5g6OovbZozRyU85J3Fm3DGzCOfg+TUHCAQ09OKlcAr6GKC62+P9oef68kngld52mNl9ZlZhZhW1tbqO1Su7a1t4Yd0BSkdkcGd5kYq5nJec9CTmXVTAztoWnlqx1+s4Q1o4Bb23n/Zefw2b2b1AOfAfve13zj3snCt3zpXn5+eHn1IipqG1nadX7iM3PZmFs4pJiNd5cTl/s8blUDoig+8s3sqeuuNexxmywvlp3g8UdXtcCNT0bGRmNwL/G7jVOaeLU6NQR1eAp97ZS1fAce9lYzVmLhFjZtw2o5DEeOPLv1lPl4ZePBFOQV8FlJpZiZklAQuARd0bmNl04GcEi/mRyMeUSHhpw0FqGk9yV3mR5jOXiBuWmsi3509l9d5jPPzGbq/jDEn9FnTnXCdwP7AE2AL82jlXaWbfNrNbQ83+A8gAfmNm68xsUR8vJx7ZsL+BVVVHubo0nymjdJ25DIz5l4xm3tQCfvDH7Ww91OR1nCEnrLlcnHOLgcU9nnug2/aNEc4lEVTf0sbv1h6gOCeND5SN9DqO+JiZ8a8fnsqqqjf40rPreeFzc0hK0HmawaIj7XOdXQGeWVWNGdx1aZHmM5cB9fSKfSypPMzcCwvYfLCJTz9Z0e/9EBI5Kug+t6TyEAcaTnDHjEKy03QXqAyOstHDmF40nKXba6k+2tr/N0hEqKD72JaDTcF1QMfnUjZ6mNdxZIi5ZdpoMlMSeW71fk5qAq9BoYLuU9VHW3lu9X5GD09h3tQCr+PIEJSaFM/tMwqpbWnje3/Y5nWcIUELXPhQa3snf/tEBQ7Hwkt185B4Z+KIDGaX5PDY8j1cP2UEV5bmvWd/X+Prd88uHox4vqOfdJ9xzvGV5zaw/XAzCy4tJjdD15uLt+ZNHUXpiAw+9/Qadte2eB3H11TQfeYHf9zOyxsO8tW5U5g0MtPrOCIkJcTx87++lPg4428eX8Wx4+1eR/ItFXQf+dnSXfzo9Z3cWV7Ip68e73UckdOKc9N45GMzqWk8yX1PVnCiXSdJB4LG0KNUb2OLZxpXfOLtKr7zylZumTaK79w2DdMMihJlZo7N4ft3Xsznf7WW+56s4JGPlXsdyXdU0GNcV8Dx8cdW8ubOOqYUZDK7JJdnV1X3/40iHrhl2mhOtHfxlec2cP/Ta7h6Uj4JcRooiBQV9BjW0NrOl3+znjd31nHZ+Bw+eNFo3QkqUe8j5UWc7AzwTy9sYt/RVu6eNVbTA0SICnoMcs7x8saDfGtRJQ2tHXzo4tFcPj7X61giYfvoZWNJiDP+8fmNPP7WHj52+ThN5xwB+rUYQ5xzvLG9lrsfWcH9T69l1LBUFt1/pYq5xKSFs4q589Ii9h1t5efL9nC8rdPrSDFPPfQY0BVwVNY08ssVe6msaWJEZjIP3FLGxy4fS0J8HOu04rrEqIsLh5OcEMfTK/bxyJu7+Zs5JWSlJnodK2apoEexjq4Aq/ceY9nOOo4eb2d8fjrfvf0iPjx9DMkJ+ngq/jClIIuPXzGOJ97Zy8/e2MUnrijxOlLMUkH3WG+XJ55o7+KdPfW8tbOO4+1dFGWnMm9qMf8yfypxOukpPjQ+P4NPXVnC429V8dAbu5hTmsvMsTlex4o5KuhRpPFEB8t31rGy6ijtnQEmjczg6kn5lOSmY2Yq5uJrhdlpfOaaCTz+VhV3P7KCHy6YzlxNLHdWVNCjwKGmkyzbUcf66gYcjmmFw7mqNI9Rw1K9jiYyqHIzkvn0NRN48u0qPvPUaj44bRRXTAhO6KUJu/qngu6R9s4ASyoP8fAbu6iqbyUx3phVksOVE/PITtdCFDJ0ZSQn8Mkrx/NsRTUvbTjIsePtzJ06yutYMUEFfZBV1R3n+TX7+dWqamqb28hJT2Le1AJmFmeTlqx/DhEITuh1z+xiXt54kOW76qlpPMm8iwrI0+yhZ6QKco7Cncc5EHBsPtjED1/bQWVNIzUNJzFgckEmN08dRenIDOI074rI+8SZ8aFpoxkzPJUX1h7glh8t4//eeTFzJub1/81DlAp6hJ3s6KKyppHVe4+xeu8xKqqOUR+aLrQwO5WbpxYwdcwwhmt9T5GwzCjOpiArhcUbD3LPoyu497Jivj7vAtL1ifZ9dETOU9PJDvbVt7LvaPDrW4sqae8KADA2N41rJuVzZWketc1tZKbohgmRczF6eCqLv3AV/7lkGz9fvocllYf5wg2l3HVpEYlakes0FfSz0NEVYOvBZtbsO8bza/az72grx1o7AEiIM8YMT+UTc8YxY2w2M4qzyc98d7yvryEaEQlPSmI837iljA9OG8V3Fm/lGy9s4uE3dnPvZcXcMbOIHF1MoILeF+cctS1trNvXwJp9DazZd4wN+xs42RHsfWemJFCck8bl43Mpzk1n9LAUEuLjdGmVyACbXpzNs5++jNe3HuGhpbv4t8Vb+c8l27liYi7XTQ6uW1qSmz4k79sIq6Cb2Vzgh0A88Khz7t977E8GngBmAvXAXc65qshGHRjOOeqPt7O3vpVdR1rYcqiJbYea2Xao+fTYd7wZo4anMKM4m+KcNIpz0hiWmqhFJEQGUW+fcv/H9EL+9cMX8euKal7bcphvbqsEIDM5gbzMZPIykslJTzr9lZ2WyCevLPHtz26/BTP2DrwAAAq8SURBVN3M4oEHgQ8A+4FVZrbIObe5W7NPAseccxPNbAHwXeCugQgcjkDAcbKzi+NtXbS2d9J8spPaljZqm9uoC/15sOEke4+2sq/+OMe7LYeVGG+MzEqhJC+dy8bnUpidyujhqRqnE4lSkwsy+adbyvinW8rYU3ecVVVH2bC/gaXbatlc0/ien2+A7/1hG7kZSeRlJJOXkUR2WhKZKQlkpCSQkZxIRkoCWSkJZCQnkJaUQHJiHMkJcSQnxAf/TOy2nRAXVb8cwumhzwJ2Oud2A5jZM8B8oHtBnw98K7T9HPBjMzPnnItgVgD+vPUI//TiJgIBR5dzdAUg4BxdAUcg4OgMFfMzvXNGcgIjspIZm5PG7JIcinPSGJubRmVNEznpSbqMUCRGleSlU5KXzp3lRad79G0dXRxtbae+pZ3GEx20tAU7eS1tHWw73MyJ9i5OdgRo6+wicA4VKykhjoQ4I86MOIO4OCPeDDMjPo7T23FxYARry92zi/m7ayZE8q8OgPVXc83sDmCuc+5ToccfBWY75+7v1mZTqM3+0ONdoTZ1PV7rPuC+0MPJwLbzzJ8H1PXbKjrEUlZQ3oEUS1lBeQfSuWQd65zL721HOD303rqrPX8LhNMG59zDwMNhvGdYzKzCORcTK83GUlZQ3oEUS1lBeQdSpLOGMzC8Hyjq9rgQqOmrjZklAMOAo5EIKCIi4QmnoK8CSs2sxMySgAXAoh5tFgF/Hdq+A3h9IMbPRUSkb/0OuTjnOs3sfmAJwcsWH3POVZrZt4EK59wi4OfAk2a2k2DPfMFAhu4mYsM3gyCWsoLyDqRYygrKO5AimrXfk6IiIhIbdHG1iIhPqKCLiPhE1Bd0M3vMzI6ErnXvbf+1ZtZoZutCXw8MdsZuWYrM7M9mtsXMKs3sC720MTP7kZntNLMNZjbDi6yhLOHkjabjm2JmK81sfSjvP/fSJtnMng0d3xVmNm7wk4ad9eNmVtvt2H7Ki6w9MsWb2Voze6mXfVFxbLvlOVPWqDq2ZlZlZhtDWSp62R+ZuuCci+ov4GpgBrCpj/3XAi95nTOUZRQwI7SdCWwHynq0uRl4heC1+5cBK6I8bzQdXwMyQtuJwArgsh5tPgs8FNpeADwbxVk/DvzY6+PaI9OXgKd7+zePlmMbZtaoOrZAFZB3hv0RqQtR30N3zr1BjFzT7pw76JxbE9puBrYAY3o0mw884YLeAYabmScLJoaZN2qEjllL6GFi6KvnWf35wC9C288BN5gHk22EmTWqmFkh8EHg0T6aRMWxhbCyxpqI1IWoL+hhujz00fYVM7vQ6zAAoY+j0wn2zLobA1R3e7yfKCiiZ8gLUXR8Qx+z1wFHgD865/o8vs65TqARyB3clEFhZAW4PfQR+zkzK+pl/2D6f8BXgUAf+6Pm2NJ/VoiuY+uAV81sdWgKlJ4iUhf8UNDXEJzb4GLgv4AXPM6DmWUAvwW+6Jxr6rm7l2/xtOfWT96oOr7OuS7n3CUE71ieZWZTezSJmuMbRtbfA+Occ9OAP/Fu73fQmdktwBHn3OozNevluUE/tmFmjZpjGzLHOTcDmAd8zsyu7rE/Isc25gu6c67p1Edb59xiINHMPFtF1swSCRbHXzrnnu+lSThTKQya/vJG2/E9xTnXAPwFmNtjV9RNQ9FXVudcvXOuLfTwEYLrCXhlDnCrmVUBzwDXm9lTPdpEy7HtN2uUHVucczWhP48AvyM4i213EakLMV/Qzazg1Diemc0i+Heq9yiLEbxrdotz7vt9NFsEfCx0VvsyoNE5d3DQQnYTTt4oO775ZjY8tJ0K3Ahs7dEsKqahCCdrjzHSWwmew/CEc+7rzrlC59w4gic8X3fO3dujWVQc23CyRtOxNbN0M8s8tQ3cBPS8ai8idSHql6Azs18RvNIiz8z2A98keIIJ59xDBP9jfcbMOoETwAIv/pOFzAE+CmwMjZ0C/CNQDKfzLiZ4Rnsn0Ap8woOcp4STN5qO7yjgFxZcdCUO+LVz7iWLjmkoziXr583sVqAzlPXjHmXtU5Qe215F8bEdCfwu1C9KAJ52zv3BzP4OIlsXdOu/iIhPxPyQi4iIBKmgi4j4hAq6iIhPqKCLiPiECrqIiE+ooIuI+IQKukQ1M/u2md3odQ4vhKaAHd3t8aNmVuZlJoluug5dBo2ZxTvnurzOMRhCd9eac+5Mk0ed8ZiY2V+ALzvn3jd/tkhv1EOXiDCzcWa21cx+0W2Gu7TQxP4PmNky4CNmNsHM/hCade5NM5tiZsNC7eJCr5VmZtVmlmhmj5vZHaHnb7DgggYbLbjwSXLo+apT88uYWXmoEGJm19i7CxysPXX7dS/ZnzSz+d0e/9LMbrXgbIn/YWarQn+nT4f2Z5jZa2a2JpRlfrdjsMXMfkJwUrNeZ/gzs5bQJ48VBGeyfCD0HpvM7OHQ7d93AOXAL0P5U83sL2ZW3u01/o8FZ8F8x8xGhp6fEHq8KvQeLb1lEJ86l0nU9aWvnl/AOIKzw80JPX4M+DLBif2/2q3da0BpaHs2wXk4AF4Ergtt3wU8Gtp+nOD0AykEpxedFHr+CYKzQ0K3xQMIFsG/hLZ/3y1PBpDQR/ZrgBdC28OAPQRv0b4P+Ebo+WSgAigJ7csKPZ9H8HZtCx2DAD0Wsujl/RxwZ7fHOd22nwQ+FNr+C1Debd/px6HXONXue91yvgQsDG3/HdDi9f8NfQ3el3roEknVzrnloe2ngCtD28/C6Wl6rwB+E5o75mcE5zw51eau0PaCU9/TzWRgj3Nue+jxLwiuZnUmy4Hvm9nngeEuOIf3+zjnlgITzWwEsBD4bajtTQQnTFpHcJ74XKCUYPH+NzPbQHBq1jEE5+sA2OuCCxScSRfBGS5Puc6CS7ptBK4Hwplzvp1g8QZYTfCXCcDlwG9C20+H8TriI1E/OZfElJ4nZE49Ph76Mw5ocME5wntaBHzHzHIITnX6eo/9Z1oZp5N3hw9TTr+5c/9uZi8TnPToHTO70TnXc3bGU54E7iH4y+Rvur3n3zvnlrwniNnHgXxgpnOuw4LTuJ563+P076QLjZubWQrwE4I972oz+1b3v8MZdDjnTh3fLvSzLGgMXSKr2MwuD20vBJZ13+mCi2fsMbOPwOmFcS8O7WsBVgI/JLhGZM8ThVuBcWY2MfT4o8DS0HYV7853ffupbzCzCc65jc657xIcLplyhuyPA18MZakMPbeE4EyTiaHXm2TB6U+HEVxgocPMrgPGnuF1+3OqeNeFPsHc0W1fM8G1Xs/GO7x7DKJqNkQZeCroEklbgL8ODUXkAD/tpc09wCfNbD1QSXAtxVOeBe7l/cMtOOdOEpxS9DehoYkA8FBo9z8DPzSzNwn2Vk/5YuhE43qCU/++0ldw59zhUP7/7vb0o8BmYI2ZbSI4RJQA/BIot+Dq7ffw/jnZw+aCi188AmwkuBrUqm67HwceOnVSNMyX/CLwJTNbSXA4q/Fcs0ns0WWLEhEWXJP0Jedcz2XWYoKZpREsqjOcczFbBEN/jxPOOWdmCwieIJ3f3/eJP2jcTYY8C9649Bjw/Vgu5iEzgR+bmQENvHs+QIYA9dBlyDCziwie/OyuzTk3e4DebwXByx27+6hzbuNAvJ+ICrqIiE/opKiIiE+ooIuI+IQKuoiIT6igi4j4xP8HIqaeWlRm02AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(imputedRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p7mfxy-M6Zmh",
    "outputId": "a5ce089f-83f8-4460-9194-11a1b9be13ec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22c81b23508>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train['previous_year_rating'][train['length_of_service']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOePL8Xv6Zmm",
    "outputId": "014b9047-6824-4502-e586-c62c6f153bbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.909090909090909"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['previous_year_rating'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XM5iQWBH6Zmr"
   },
   "source": [
    "### Train Validation Spliting\n",
    "\n",
    "75:25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8tWDIbdt6Zms"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x1d-1ID56Zmx"
   },
   "source": [
    "## Basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U6y-HdQZ6Zmy",
    "outputId": "c08da778-5012-4a7c-d290-ff8af130d83d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilaks\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr_pipe = make_pipeline( LogisticRegression(solver='lbfgs',max_iter=100))\n",
    "model_Lr=logr_pipe.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pzRueaJG6Zm3"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate, ShuffleSplit, LeaveOneOut\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9MvC0iiM6Zm9",
    "outputId": "3a8c98b5-1338-4f45-a747-a51b493d9682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.13%\n",
      "Balanced Accuracy: 58.16%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     12533\n",
      "           1       0.65      0.17      0.27      1169\n",
      "\n",
      "    accuracy                           0.92     13702\n",
      "   macro avg       0.79      0.58      0.62     13702\n",
      "weighted avg       0.90      0.92      0.90     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12423</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>968</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1\n",
       "is_promoted            \n",
       "0            12423  110\n",
       "1              968  201"
      ]
     },
     "execution_count": 103,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_Lr.predict(X_val)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5eRtGThX6ZnC",
    "outputId": "5f2bc056-7183-4ed8-fd3f-fbdf57a6784c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.05%\n",
      "Balanced Accuracy: 73.57%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.79      0.87     12533\n",
      "           1       0.23      0.68      0.35      1169\n",
      "\n",
      "    accuracy                           0.78     13702\n",
      "   macro avg       0.60      0.74      0.61     13702\n",
      "weighted avg       0.90      0.78      0.82     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9897</td>\n",
       "      <td>2636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>372</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0           0     1\n",
       "is_promoted            \n",
       "0            9897  2636\n",
       "1             372   797"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mythreshold=0.1\n",
    "y_pred = (model_Lr.predict_proba(X_val) >= mythreshold).astype(int)\n",
    "#y_pred = model_Lr.predict(X_val)\n",
    "y_pred=y_pred[:,1]\n",
    "#y_pred\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GuNd2Ujt6ZnH"
   },
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "colab_type": "code",
    "id": "sGKTLJ8-6ZnI",
    "outputId": "862763bf-6889-4dcf-b47c-d836199160f0"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "ThBiG76P6ZnP",
    "outputId": "ac65dfc9-5de7-46c6-ba55-fc32029eaac2"
   },
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0,sampling_strategy=0.9)\n",
    "X_SMOTE, y_SMOTE = sm.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "viVRnLje6ZnT",
    "outputId": "5c2d2dfc-0880-4c3a-af50-c85d001a04cc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilaks\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logr_pipe = make_pipeline( LogisticRegression(solver='lbfgs',max_iter=100))\n",
    "model_Lr=logr_pipe.fit(X_SMOTE, y_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uzwkQsAS6ZnY",
    "outputId": "da7462f1-076b-4846-d0eb-ff42cc99a75d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33846"
      ]
     },
     "execution_count": 156,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_SMOTE.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DuF1R2jw6Znd",
    "outputId": "75f31afd-55bd-439b-c961-5f4f470a59b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.42%\n",
      "Balanced Accuracy: 74.58%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85     12533\n",
      "           1       0.22      0.74      0.34      1169\n",
      "\n",
      "    accuracy                           0.75     13702\n",
      "   macro avg       0.59      0.75      0.59     13702\n",
      "weighted avg       0.90      0.75      0.81     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9474</td>\n",
       "      <td>3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0           0     1\n",
       "is_promoted            \n",
       "0            9474  3059\n",
       "1             309   860"
      ]
     },
     "execution_count": 157,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mythreshold=0.48\n",
    "y_pred = (model_Lr.predict_proba(X_val) >= mythreshold).astype(int)\n",
    "#y_pred = model_Lr.predict(X_val)\n",
    "y_pred=y_pred[:,1]\n",
    "#y_pred\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "npAQ_w2p6Znh"
   },
   "outputs": [],
   "source": [
    "#\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=0)\n",
    "model_gbt = clf.fit(X_SMOTE, y_SMOTE)\n",
    "# clf.predict(X_test[:2])\n",
    "# clf.score(X_SMOTE, Y_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "H2LWhEvu6Znm",
    "outputId": "5d6e45f2-e98d-41d5-eac3-da722caa65d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.64%\n",
      "Balanced Accuracy: 63.21%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96     12533\n",
      "           1       0.67      0.28      0.39      1169\n",
      "\n",
      "    accuracy                           0.93     13702\n",
      "   macro avg       0.80      0.63      0.68     13702\n",
      "weighted avg       0.91      0.93      0.91     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12370</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>845</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1\n",
       "is_promoted            \n",
       "0            12370  163\n",
       "1              845  324"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_gbt.predict(X_val)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tMz2PMO-8neB"
   },
   "outputs": [],
   "source": [
    "grid_values = {'n_estimators': [500,100],'min_samples_split':[250,300,350],'min_samples_leaf':[50],'max_depth':[5,6], 'max_features':['sqrt']}\n",
    "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values,scoring = 'f1',cv=3,n_jobs=-1)\n",
    "model_gbt_cv = grid_clf_acc.fit(X_SMOTE, y_SMOTE)\n",
    "y_pred_acc = model_gbt_cv.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "colab_type": "code",
    "id": "RQ2CIDGpCCW_",
    "outputId": "b0e6c235-0246-4347-f183-31bcaa186c3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.85%\n",
      "Balanced Accuracy: 66.39%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     12533\n",
      "           1       0.86      0.33      0.48      1169\n",
      "\n",
      "    accuracy                           0.94     13702\n",
      "   macro avg       0.90      0.66      0.72     13702\n",
      "weighted avg       0.93      0.94      0.93     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12471</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>780</td>\n",
       "      <td>389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1\n",
       "is_promoted            \n",
       "0            12471   62\n",
       "1              780  389"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_gbt_cv.predict(X_val)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "2HdqQNp2G2Wf",
    "outputId": "be662030-ab53-4396-98b7-26b5a9084f02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'max_features': 'sqrt',\n",
       " 'min_samples_leaf': 50,\n",
       " 'min_samples_split': 350,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gbt_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzhEy407-xeN"
   },
   "outputs": [],
   "source": [
    "#250-500 min_sample_split  0.5-1% of total data\n",
    "#min_samples_leaf = 50\n",
    "#max_depth = 8 .. should be 5-8\n",
    "#max_features = ‘sqrt’\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2fwCcDGfHWGi"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 840 candidates, totalling 2520 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  5.6min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 27.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 47.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 75.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2426 tasks      | elapsed: 123.4min\n",
      "[Parallel(n_jobs=-1)]: Done 2520 out of 2520 | elapsed: 131.7min finished\n"
     ]
    }
   ],
   "source": [
    "grid_values = {'n_estimators': [500],'min_samples_split':[2,3,5,10,50,100,350],'min_samples_leaf':[2,3,5,10,20,50],'max_depth':[4,5,6,7,10], 'max_features':[6,7,8,9]}\n",
    "grid_clf_acc = GridSearchCV(clf, param_grid = grid_values,scoring = 'f1',cv=3,n_jobs=-1,verbose=1)\n",
    "model_gbt_cv = grid_clf_acc.fit(X_SMOTE, y_SMOTE)\n",
    "y_pred_acc = model_gbt_cv.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6,\n",
       " 'max_features': 9,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 350,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gbt_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([21.16524736, 21.29542263, 21.29542613, 20.89781618, 21.54744713,\n",
       "        21.19167113, 21.46898937, 21.4514161 , 21.81717483, 22.2436409 ,\n",
       "        22.05980905, 21.90868123, 21.35167209, 20.97541746, 21.53588788,\n",
       "        21.30393871, 20.80901734, 20.97769181, 20.77641749, 20.72436889,\n",
       "        20.26428866, 20.35482939, 20.49092261, 20.71826951, 20.53915381,\n",
       "        20.48204001, 20.47978131, 20.27532307, 20.44683305, 20.65889692,\n",
       "        20.70733364, 21.07297556, 20.27908071, 20.25605734, 20.3353107 ,\n",
       "        20.43165731, 20.08964507, 20.35605597, 20.22920903, 20.53932858,\n",
       "        19.81878408, 20.15768361, 22.49383616, 22.73071615, 22.23091364,\n",
       "        22.3905623 , 22.34957671, 22.28369768, 22.22800962, 22.23434718,\n",
       "        22.27615937, 22.45166286, 22.40662964, 22.0289185 , 22.11043795,\n",
       "        22.26733128, 22.46276736, 22.46023575, 22.64063533, 22.5691967 ,\n",
       "        22.21849656, 22.37733364, 22.17658798, 22.51501179, 22.10801593,\n",
       "        22.55933825, 22.46194442, 22.34223294, 22.10862589, 22.43980296,\n",
       "        22.12701495, 22.53679331, 22.43373672, 22.70433346, 22.47235099,\n",
       "        22.40376051, 22.01650389, 22.30082138, 22.13568791, 22.14298399,\n",
       "        22.31380963, 22.18397347, 22.05373216, 22.0440313 , 24.59557263,\n",
       "        24.49598463, 24.03911257, 24.25268563, 24.25205406, 23.97353752,\n",
       "        23.7964917 , 24.53111418, 24.34999998, 24.2041978 , 24.27420497,\n",
       "        24.06601516, 24.04545911, 23.92968114, 24.28837276, 24.32644169,\n",
       "        24.09618465, 24.29562028, 24.63391574, 24.48153559, 23.83990963,\n",
       "        24.0658764 , 24.1019609 , 24.16352272, 24.05686442, 24.10279846,\n",
       "        24.2187504 , 23.93136819, 24.33603422, 24.24916132, 24.14363686,\n",
       "        24.35908659, 23.9692022 , 24.08000485, 24.19478067, 23.82993078,\n",
       "        24.193741  , 24.23162897, 24.30555916, 23.98139493, 24.2176764 ,\n",
       "        23.87957255, 26.5059251 , 26.07527502, 26.06555525, 26.23603749,\n",
       "        26.56038396, 25.96025896, 26.15871628, 26.16550557, 26.02554552,\n",
       "        26.12167668, 26.20231477, 26.27676225, 25.88068215, 25.87289135,\n",
       "        26.01152372, 26.09535003, 26.20745929, 26.06432056, 26.05858421,\n",
       "        25.97451337, 26.16869505, 26.2358315 , 26.58013225, 26.3282028 ,\n",
       "        26.11471089, 26.51135429, 25.95639459, 25.63931243, 26.175373  ,\n",
       "        26.08613777, 25.8514607 , 25.91426269, 26.25187135, 26.05725996,\n",
       "        25.68330423, 25.9575181 , 26.02000419, 26.09810909, 25.95518335,\n",
       "        26.23279532, 26.4797438 , 26.65191634, 25.24487011, 25.17604097,\n",
       "        24.75747196, 24.67936325, 24.6640106 , 24.41711879, 23.98270615,\n",
       "        24.92102957, 24.72413603, 24.8450036 , 24.63764278, 24.62385853,\n",
       "        24.45072961, 24.03584234, 24.73880402, 24.6711301 , 24.97588754,\n",
       "        24.8113296 , 24.75921575, 24.41003704, 24.37138112, 24.59880201,\n",
       "        24.57108386, 24.78809325, 24.70329563, 24.59320362, 24.49168897,\n",
       "        23.96172301, 24.56473541, 24.59059985, 24.46847296, 24.57019838,\n",
       "        24.54431923, 24.46915547, 24.17499924, 24.2051359 , 24.45057138,\n",
       "        24.32785114, 24.27167678, 24.29173223, 24.43110021, 23.90797544,\n",
       "        27.3353885 , 27.38038937, 27.49129955, 27.16397238, 27.06626678,\n",
       "        26.96949013, 26.49569122, 27.24592916, 27.31287018, 27.24627097,\n",
       "        27.3018558 , 27.16309524, 27.15496937, 26.6390121 , 27.39979188,\n",
       "        27.43051895, 27.2580022 , 27.28444815, 27.16835713, 26.98361238,\n",
       "        26.47242244, 27.10886614, 27.28507932, 27.18114551, 27.19429946,\n",
       "        27.12481149, 26.89380964, 26.80433734, 26.91711346, 27.00610034,\n",
       "        27.05682715, 27.07920933, 26.97382998, 26.87724233, 26.64045056,\n",
       "        26.89228153, 26.73004945, 26.6961635 , 26.72520073, 26.86455663,\n",
       "        26.83940522, 26.3606267 , 30.13114635, 30.47374662, 30.26336177,\n",
       "        30.24444254, 29.79894114, 29.65493751, 29.18009774, 29.76299977,\n",
       "        29.7395107 , 29.85040466, 29.73541387, 29.5955685 , 29.26113009,\n",
       "        28.96887596, 29.63248507, 29.78870281, 29.70805939, 29.75606831,\n",
       "        29.43319607, 29.56285866, 29.24098802, 29.82519023, 29.51738866,\n",
       "        29.7771546 , 29.49907565, 29.55920029, 29.5276316 , 29.19020955,\n",
       "        30.52528564, 30.01864012, 30.01779103, 29.90520692, 29.54019451,\n",
       "        29.24798322, 29.25427381, 29.6311299 , 29.41674407, 29.50832097,\n",
       "        29.16417241, 29.40350262, 29.30714679, 29.15682316, 32.82544351,\n",
       "        32.97537057, 33.04220549, 32.64816451, 32.08834251, 31.8695004 ,\n",
       "        31.3344388 , 32.35871506, 32.23040605, 32.26184646, 31.99702668,\n",
       "        31.85830148, 31.70638625, 31.26744684, 31.99315302, 32.15138737,\n",
       "        31.94223809, 32.23634553, 31.86380577, 31.99843923, 31.3048195 ,\n",
       "        32.08069944, 32.06321081, 32.17597183, 32.07629538, 32.061553  ,\n",
       "        31.72165799, 31.21405435, 31.72383849, 32.03103177, 32.0096217 ,\n",
       "        32.10986487, 32.01739875, 31.90819232, 31.63524175, 32.08194908,\n",
       "        31.56249897, 32.09246445, 31.61711327, 31.93440398, 32.11639349,\n",
       "        32.66147137, 30.40455445, 31.01178749, 30.20417643, 29.71006576,\n",
       "        28.99021546, 29.27560488, 28.08362937, 29.49404136, 29.42439628,\n",
       "        29.9745295 , 29.71953654, 29.56128438, 28.62849148, 28.46051105,\n",
       "        29.68155964, 29.79259451, 29.51835966, 29.67329208, 29.21971973,\n",
       "        29.17439747, 28.16494028, 29.54731623, 29.24035756, 29.57169938,\n",
       "        29.18192633, 29.12953536, 28.93424265, 28.6565392 , 29.0222129 ,\n",
       "        29.19996436, 29.20853146, 29.34073639, 29.10212127, 28.88867458,\n",
       "        28.51448846, 29.24093755, 29.31302444, 29.33504725, 28.92330011,\n",
       "        28.71141958, 29.12537599, 28.95109518, 34.76419226, 34.74519626,\n",
       "        33.80919623, 33.74486192, 32.3395075 , 32.10693518, 32.48019799,\n",
       "        34.59454934, 34.37693755, 34.19795712, 33.53091025, 32.06471372,\n",
       "        31.87841201, 31.36352078, 33.02848562, 33.0691181 , 33.18944128,\n",
       "        33.42252477, 32.8764499 , 32.57216525, 31.67951186, 32.77090089,\n",
       "        32.85775932, 32.92052396, 32.23037489, 32.20451625, 31.94859258,\n",
       "        31.71217704, 32.30158361, 32.36269601, 32.30430547, 32.50299629,\n",
       "        32.0442911 , 32.39513461, 31.44990889, 31.91743128, 31.87782995,\n",
       "        32.03146895, 31.95345291, 32.39509654, 32.75634543, 32.064243  ,\n",
       "        36.74468279, 36.29558396, 36.23768997, 36.05721943, 35.56842907,\n",
       "        34.82795564, 33.94208137, 36.08625054, 36.06153274, 35.65253425,\n",
       "        35.82375733, 35.06079714, 35.17721836, 33.95166294, 35.75455602,\n",
       "        35.70532584, 36.71411975, 36.59810154, 35.7492195 , 35.46699421,\n",
       "        34.02245712, 35.56250803, 35.0072902 , 35.47512921, 35.33297523,\n",
       "        35.08907914, 34.63828103, 34.44967357, 35.48574106, 35.36652303,\n",
       "        35.0663112 , 35.13763126, 35.25575137, 34.99578746, 34.82239453,\n",
       "        35.47920648, 35.50390069, 35.95304092, 34.77838214, 34.86117148,\n",
       "        34.70059919, 34.14029129, 38.99111271, 38.90843256, 39.21074001,\n",
       "        39.32043099, 38.74525921, 38.31288362, 36.93020344, 38.6368773 ,\n",
       "        38.53562673, 38.63144565, 38.42380929, 38.08156959, 37.58191744,\n",
       "        37.10702236, 38.33765817, 38.54127574, 38.65048997, 38.75211549,\n",
       "        37.90405035, 37.83852037, 37.04472589, 38.76459575, 38.52599223,\n",
       "        38.97200648, 38.66196354, 38.30011956, 39.83956146, 38.59442806,\n",
       "        41.01017427, 39.98005859, 39.74841078, 39.21411149, 38.24822537,\n",
       "        37.67457509, 37.35067042, 37.66140238, 37.36687016, 37.8290987 ,\n",
       "        37.83530545, 37.95876773, 37.58226728, 37.05451012, 35.99305288,\n",
       "        35.75192761, 35.5256993 , 35.20703069, 34.47903323, 33.887947  ,\n",
       "        32.64325507, 35.59921344, 35.44361488, 35.53204513, 35.17479396,\n",
       "        34.49977183, 33.96295309, 32.86161208, 35.38104137, 35.04120612,\n",
       "        34.95601384, 35.17717338, 34.09298929, 33.92040706, 32.6426026 ,\n",
       "        34.63740389, 34.57009594, 34.48896329, 34.62564874, 34.38594222,\n",
       "        33.45821889, 32.58070779, 34.07650407, 34.10916996, 34.0148108 ,\n",
       "        34.02835759, 33.96744188, 33.67875417, 32.59820437, 33.22401396,\n",
       "        33.30772209, 33.16056808, 33.14686894, 33.17204833, 33.28502917,\n",
       "        32.12816223, 39.55319341, 39.6743052 , 39.74490786, 39.68917155,\n",
       "        38.40012662, 37.9059635 , 35.68498206, 38.99686472, 39.00906388,\n",
       "        39.46832132, 39.02381579, 38.4049747 , 37.77679634, 36.0901955 ,\n",
       "        38.46957429, 38.75046062, 38.53454995, 38.57872931, 37.69502775,\n",
       "        37.30458053, 36.00739153, 38.27616882, 38.08998076, 38.11165611,\n",
       "        38.1286788 , 37.78892104, 37.19286283, 36.08409413, 37.69783298,\n",
       "        37.77944875, 37.54088171, 38.02108947, 37.52130683, 37.37915683,\n",
       "        35.92245166, 36.97788326, 36.99904172, 36.83901103, 36.83244912,\n",
       "        36.93908493, 36.82032712, 35.93336622, 43.26242924, 43.26723822,\n",
       "        42.94837205, 42.45836004, 41.14711388, 40.74298247, 39.51334683,\n",
       "        42.57432946, 42.48667137, 42.4460748 , 42.39254101, 41.22319134,\n",
       "        40.89714281, 39.56653611, 42.20089761, 42.37769612, 42.34374976,\n",
       "        42.32555437, 40.90986649, 40.54861601, 39.38812272, 41.48797425,\n",
       "        41.36857017, 41.08741752, 41.44378312, 41.07812198, 40.6070466 ,\n",
       "        39.49352535, 41.06738011, 41.10287293, 41.03898549, 40.85211364,\n",
       "        40.9947106 , 40.56184618, 39.19960157, 40.24514945, 40.23258766,\n",
       "        40.14054608, 40.2090439 , 40.14229361, 39.93242764, 38.94594765,\n",
       "        46.46302327, 46.10736855, 46.47230419, 46.2846663 , 45.41278919,\n",
       "        44.76722225, 42.68913349, 46.10576455, 45.86300476, 45.77185225,\n",
       "        45.66831382, 44.36529684, 43.94890308, 42.59293103, 45.70325184,\n",
       "        45.2861584 , 45.36286124, 45.43289383, 44.4625806 , 43.95031945,\n",
       "        42.50324281, 44.95481499, 44.71400825, 44.90182257, 45.14257073,\n",
       "        44.42134134, 43.62498236, 43.06937011, 44.34479356, 44.56244675,\n",
       "        44.24353123, 44.71560311, 44.17714341, 44.05667909, 42.30172857,\n",
       "        43.88576969, 43.46213587, 43.64276425, 43.44171604, 43.58333723,\n",
       "        43.13443955, 41.72447578, 60.70405364, 60.8236649 , 60.42656144,\n",
       "        57.16747069, 51.54371929, 48.92423765, 44.68245212, 58.29222027,\n",
       "        57.68476184, 57.29536335, 57.08713595, 52.09659378, 49.66021808,\n",
       "        46.9523836 , 55.79025157, 55.60027647, 55.27649411, 55.15117717,\n",
       "        50.89208714, 48.78143676, 45.15234987, 52.05251376, 51.91341416,\n",
       "        51.77777759, 51.87647033, 49.84324185, 48.27747242, 45.22633338,\n",
       "        49.25929062, 49.2570378 , 49.22052081, 49.27958083, 49.28924227,\n",
       "        47.95049874, 44.91915298, 46.433508  , 46.8167034 , 46.64783247,\n",
       "        46.36564008, 46.32563607, 45.79503989, 43.41096711, 66.92407521,\n",
       "        66.89986809, 65.59618648, 62.50456039, 56.72627211, 54.56290118,\n",
       "        50.52135189, 65.16328812, 64.61335373, 63.86203273, 62.66062323,\n",
       "        55.81132849, 53.79722794, 50.12081734, 61.38544432, 61.1838901 ,\n",
       "        61.38958851, 61.3138353 , 56.28453167, 54.48171552, 50.90955162,\n",
       "        58.12856881, 57.7689991 , 57.77050535, 57.89796042, 55.71651141,\n",
       "        53.66691494, 50.38969326, 55.05167866, 54.9668866 , 54.97114189,\n",
       "        55.01688178, 54.73011947, 53.30225849, 50.07709225, 51.9480118 ,\n",
       "        52.42708643, 52.35459057, 52.52620554, 52.44573712, 51.41134914,\n",
       "        48.58130773, 72.36642249, 72.2310334 , 70.98984083, 67.71805509,\n",
       "        61.35737363, 58.65099629, 54.41348044, 69.31286502, 68.96373415,\n",
       "        68.88294498, 67.27678863, 60.97911588, 58.9050281 , 54.87910088,\n",
       "        66.6395336 , 66.82790399, 66.29820037, 66.25627128, 61.24438596,\n",
       "        59.11371962, 52.81570244, 60.43676313, 59.58005301, 59.86805169,\n",
       "        62.45168749, 60.0281918 , 58.84132735, 55.08220283, 60.25914391,\n",
       "        60.36963582, 60.52335509, 60.098159  , 60.13676802, 58.25413219,\n",
       "        55.13630223, 57.18127672, 57.0549039 , 57.11529922, 57.47928365,\n",
       "        57.34730331, 58.46588413, 56.09437998, 79.98688889, 80.38392528,\n",
       "        77.17364661, 73.69907896, 66.44076761, 63.4305288 , 59.5461634 ,\n",
       "        74.76502419, 74.25790564, 75.24026219, 72.97879958, 66.56907598,\n",
       "        63.90440408, 59.96017623, 71.84502141, 71.61042658, 72.89220166,\n",
       "        72.6291062 , 67.04006441, 64.50536656, 59.6700894 , 68.68604279,\n",
       "        68.08070215, 68.34853959, 68.39629618, 66.03014183, 64.08179577,\n",
       "        60.35636306, 66.30311497, 66.42563208, 66.51763503, 66.55963437,\n",
       "        64.78510276, 63.06923525, 59.56757808, 62.36294476, 62.7881693 ,\n",
       "        62.4800779 , 62.38654804, 62.2435325 , 51.82768599, 46.53320726]),\n",
       " 'std_fit_time': array([3.62832021e-01, 2.04593810e-01, 2.77355075e-01, 3.51278467e-01,\n",
       "        1.12389801e-01, 2.83146978e-01, 4.02489325e-01, 4.33769489e-01,\n",
       "        2.32901154e-01, 1.18442956e-01, 1.73683843e-01, 5.66527592e-01,\n",
       "        5.81935522e-01, 4.51543408e-01, 5.10187723e-02, 4.43319202e-01,\n",
       "        6.45428009e-02, 4.46987102e-01, 4.91582590e-01, 1.40725523e-03,\n",
       "        2.95574588e-01, 2.91504605e-01, 1.54674723e-01, 3.57049261e-01,\n",
       "        1.61395438e-01, 3.02756687e-01, 3.22547713e-01, 3.13178125e-01,\n",
       "        6.76554636e-02, 4.69161652e-01, 3.52743638e-01, 1.17433708e-01,\n",
       "        3.74770075e-01, 4.17237614e-01, 3.57509820e-01, 3.37134965e-01,\n",
       "        1.51376179e-01, 3.77497081e-01, 2.24922959e-01, 2.60458310e-01,\n",
       "        3.05815298e-01, 1.44867330e-01, 2.53282770e-01, 3.00751796e-01,\n",
       "        3.20755318e-01, 2.68658660e-01, 2.52888876e-01, 2.73657479e-01,\n",
       "        1.54025077e-01, 3.29902005e-01, 4.24301736e-01, 4.87189541e-01,\n",
       "        3.45605879e-01, 2.84609005e-01, 1.44865393e-01, 7.02600697e-02,\n",
       "        4.38425408e-01, 6.30772145e-01, 2.58367365e-01, 2.67557130e-01,\n",
       "        5.98657814e-01, 4.14676106e-01, 8.49247292e-02, 4.14675145e-01,\n",
       "        2.89592706e-01, 3.05957768e-01, 8.36416409e-02, 2.19935981e-01,\n",
       "        1.91333139e-01, 2.97672035e-01, 2.50746977e-01, 4.11290352e-01,\n",
       "        5.41695106e-01, 2.35025777e-01, 5.32743731e-01, 1.03613167e-01,\n",
       "        1.86641806e-01, 3.09889863e-01, 4.15731078e-01, 3.80581522e-01,\n",
       "        3.24764766e-01, 2.01288072e-01, 4.19848360e-01, 3.95271459e-01,\n",
       "        2.28640091e-01, 3.90845006e-01, 2.85591397e-01, 2.75368412e-01,\n",
       "        5.05436977e-01, 4.62937581e-01, 4.33909710e-01, 4.04952887e-01,\n",
       "        2.88323992e-01, 2.48746839e-01, 3.24876287e-01, 3.16129864e-01,\n",
       "        5.85470591e-01, 3.34775533e-01, 3.70963998e-01, 4.97433939e-01,\n",
       "        3.04780788e-01, 6.21326335e-01, 5.26042749e-01, 3.87629589e-01,\n",
       "        1.72628388e-01, 3.34313264e-01, 4.64105203e-01, 4.59349179e-01,\n",
       "        3.37938207e-01, 3.96481604e-01, 7.69949887e-02, 2.64595422e-01,\n",
       "        9.29437558e-01, 1.76889529e-01, 4.20548469e-01, 4.24650216e-01,\n",
       "        3.00191440e-01, 1.85856810e-01, 6.31723365e-01, 4.62251152e-01,\n",
       "        4.25359442e-01, 2.26943203e-01, 1.02961408e-01, 3.92160914e-01,\n",
       "        1.56160235e-01, 1.86230115e-01, 2.10052088e-01, 5.19612717e-01,\n",
       "        3.87889292e-01, 4.29956649e-01, 3.06833028e-01, 2.74780834e-01,\n",
       "        2.01091669e-01, 4.44011261e-01, 3.67594953e-01, 3.78314343e-01,\n",
       "        3.19285384e-01, 6.33821994e-01, 3.53702298e-01, 2.43455456e-01,\n",
       "        3.49819415e-01, 5.54866831e-01, 2.48963334e-01, 3.12074862e-01,\n",
       "        4.95209914e-01, 3.14900435e-01, 4.33612564e-01, 4.71712346e-01,\n",
       "        1.50285247e-01, 3.66468256e-01, 3.99763027e-01, 4.97452429e-01,\n",
       "        2.73328658e-01, 3.57421715e-01, 6.29306788e-01, 4.02766005e-01,\n",
       "        3.55549893e-01, 3.54007313e-01, 2.42280236e-01, 4.37899961e-01,\n",
       "        3.57152779e-01, 4.97107530e-01, 3.92919789e-01, 5.32652739e-01,\n",
       "        4.12183240e-01, 3.21177192e-01, 5.43293048e-01, 3.76426607e-01,\n",
       "        3.48747403e-01, 1.55451341e-01, 5.01993298e-01, 4.41839406e-01,\n",
       "        3.38020850e-01, 5.41339917e-01, 3.52161551e-01, 4.96840092e-01,\n",
       "        3.37853973e-01, 3.20354884e-01, 3.45833643e-01, 3.75353888e-01,\n",
       "        1.21672226e-01, 3.69006927e-01, 2.98638681e-01, 3.20746750e-01,\n",
       "        4.85683719e-01, 3.83280226e-01, 2.02475689e-01, 2.58784558e-01,\n",
       "        5.09425318e-01, 2.63988130e-01, 3.31584984e-01, 1.47945162e-01,\n",
       "        1.36381440e-01, 4.27680452e-01, 3.68648585e-01, 3.31706587e-01,\n",
       "        2.68761330e-01, 2.00185997e-01, 4.04642593e-01, 2.30953234e-01,\n",
       "        4.27090027e-01, 4.63205832e-01, 4.96372705e-01, 3.81988955e-01,\n",
       "        2.08803467e-01, 2.86470476e-01, 2.80103667e-01, 3.66198680e-01,\n",
       "        4.04616308e-01, 2.29761043e-01, 3.32175844e-01, 4.78936469e-01,\n",
       "        4.44667699e-01, 4.33599763e-01, 4.15055451e-01, 2.99062201e-01,\n",
       "        3.68418276e-01, 4.08222014e-01, 3.43195694e-01, 3.19755907e-01,\n",
       "        5.06954975e-01, 4.97066394e-01, 3.80938547e-01, 4.08044036e-01,\n",
       "        4.31949995e-01, 2.78152522e-01, 5.30357458e-01, 4.52614619e-01,\n",
       "        1.68149124e-01, 5.72057050e-01, 5.30409204e-01, 5.79292038e-01,\n",
       "        2.69668141e-01, 2.42001848e-01, 5.26762364e-01, 3.38982949e-01,\n",
       "        4.51869073e-01, 2.71611116e-01, 4.93492980e-01, 2.94836675e-01,\n",
       "        4.69757568e-01, 5.82079081e-01, 1.89649732e-01, 6.35677159e-01,\n",
       "        2.25276897e-01, 6.65028136e-01, 4.12710327e-01, 2.47778234e-01,\n",
       "        4.91734937e-01, 2.83448010e-01, 4.86536829e-01, 3.03618925e-01,\n",
       "        3.74838864e-01, 1.89082457e-01, 3.34859937e-01, 6.31026655e-01,\n",
       "        3.78761849e-01, 4.03609542e-01, 5.25624896e-01, 3.83563786e-01,\n",
       "        4.10537354e-01, 2.93604980e-01, 5.80912812e-01, 4.08750610e-01,\n",
       "        3.42882087e-01, 4.26283759e-01, 2.96484713e-01, 5.15004777e-01,\n",
       "        5.10758786e-01, 3.82392705e-01, 4.80133048e-01, 6.50914098e-01,\n",
       "        3.41527130e-01, 8.08824799e-01, 6.85941358e-01, 3.77221003e-01,\n",
       "        5.80014251e-01, 5.66673628e-01, 4.83072029e-01, 2.65594652e-01,\n",
       "        7.76603316e-01, 1.59606657e-01, 7.97012624e-01, 3.91474047e-01,\n",
       "        5.00448127e-01, 4.42536126e-01, 5.70479742e-01, 3.79013653e-01,\n",
       "        5.90440162e-01, 6.63186208e-01, 3.74164773e-01, 4.58939239e-01,\n",
       "        3.28998965e-01, 7.79312725e-02, 6.63459256e-01, 4.84617484e-01,\n",
       "        8.69954170e-01, 4.08923493e-01, 3.33364180e-01, 6.79248442e-01,\n",
       "        4.31747515e-01, 5.75137122e-01, 5.88037810e-01, 5.82657209e-01,\n",
       "        5.92609979e-01, 5.96371347e-01, 4.37987119e-01, 6.03978752e-01,\n",
       "        6.03298348e-01, 6.73853260e-01, 3.99870145e-01, 6.44116383e-01,\n",
       "        5.09589047e-01, 3.77301313e-01, 5.84023058e-01, 5.24606579e-01,\n",
       "        5.13300770e-01, 5.93108019e-01, 4.55461320e-01, 5.34026593e-01,\n",
       "        6.64709672e-01, 6.59832316e-01, 7.46388123e-01, 6.05891528e-01,\n",
       "        4.82720391e-01, 5.05437852e-01, 5.12946583e-01, 6.53716637e-01,\n",
       "        5.88392642e-01, 5.10095007e-01, 5.35701294e-01, 7.71670423e-01,\n",
       "        6.25725403e-01, 4.76143167e-01, 4.85534190e-01, 4.82140628e-01,\n",
       "        4.16111418e-01, 6.69032086e-01, 5.95470758e-01, 1.67021003e-01,\n",
       "        4.80339597e-01, 4.64839017e-01, 7.17093496e-02, 9.03232653e-01,\n",
       "        4.02363428e-01, 3.40392588e-01, 1.24276504e-01, 4.70291001e-01,\n",
       "        4.12900990e-01, 5.31259949e-01, 1.02705738e-01, 4.41841035e-01,\n",
       "        4.85616458e-01, 1.48434922e-01, 1.59130602e-01, 4.88918988e-01,\n",
       "        2.63844753e-01, 6.47231284e-01, 2.34502666e-01, 5.06404498e-01,\n",
       "        4.05226112e-01, 3.82471537e-02, 5.92171238e-01, 3.66302010e-01,\n",
       "        4.19968250e-01, 2.84108232e-01, 2.41645086e-01, 3.07780210e-01,\n",
       "        2.11258044e-01, 1.47423654e-01, 1.31060537e-01, 2.00243797e-01,\n",
       "        6.97325106e-01, 1.74754150e-01, 6.45054747e-01, 4.94383049e-01,\n",
       "        3.43777252e-01, 3.78868567e-01, 1.29028506e-01, 6.77688518e-01,\n",
       "        2.23152306e-01, 2.88651775e-01, 3.26717316e-01, 3.26864070e-01,\n",
       "        6.47622843e-01, 6.79878604e-01, 5.49820703e-01, 8.58588647e-01,\n",
       "        4.91346446e-01, 4.92093517e-01, 3.12337151e-01, 5.31177355e-01,\n",
       "        6.02966223e-01, 6.97603729e-01, 5.43699562e-01, 5.71364442e-01,\n",
       "        5.82309714e-01, 4.86890384e-01, 6.25255758e-01, 5.67190948e-01,\n",
       "        7.53015996e-01, 3.94023927e-01, 7.87508375e-01, 5.62669520e-01,\n",
       "        2.85021738e-01, 4.84251614e-01, 8.32340929e-01, 4.47418237e-01,\n",
       "        4.87560289e-01, 6.34292144e-01, 4.59126809e-01, 6.94868880e-01,\n",
       "        4.21573852e-01, 4.36290881e-01, 6.85125629e-01, 7.02592655e-01,\n",
       "        5.50546550e-01, 6.18888452e-01, 7.61974121e-01, 5.64997061e-02,\n",
       "        5.80913438e-01, 6.22126881e-01, 7.99258681e-01, 5.45326834e-01,\n",
       "        6.53481834e-01, 5.06821062e-01, 8.98998850e-01, 4.72440957e-01,\n",
       "        6.74614107e-01, 8.28350045e-01, 9.39078753e-01, 6.99424441e-01,\n",
       "        3.26270511e-01, 3.90785501e-01, 9.24495683e-01, 6.93192963e-01,\n",
       "        8.41927769e-01, 1.09994690e+00, 6.76484331e-01, 5.01709003e-01,\n",
       "        4.52064915e-01, 2.68872190e-01, 6.09903477e-01, 5.33155493e-01,\n",
       "        6.38800163e-01, 5.18733226e-01, 6.10690844e-01, 4.62231198e-01,\n",
       "        1.70280977e-01, 6.85791204e-01, 7.86968724e-01, 4.18475537e-01,\n",
       "        2.28273123e-01, 4.71866596e-01, 3.64856491e-01, 1.14634662e+00,\n",
       "        5.71857859e-01, 1.13903455e+00, 6.22054295e-01, 6.99037587e-01,\n",
       "        6.37779429e-01, 4.13685089e-01, 7.55310116e-01, 4.45318396e-01,\n",
       "        4.13170775e-01, 7.64966517e-01, 5.24190034e-01, 5.49203253e-01,\n",
       "        5.38183627e-01, 5.74227958e-01, 5.00594535e-01, 8.70865953e-01,\n",
       "        7.12412627e-01, 7.31505710e-01, 9.26981319e-01, 7.10541523e-01,\n",
       "        7.55012413e-01, 6.34110767e-01, 7.40717914e-01, 6.47288026e-01,\n",
       "        8.49390688e-01, 1.18113041e+00, 6.88790702e-01, 9.44486273e-01,\n",
       "        5.59232910e-01, 5.02826416e-01, 7.63168408e-01, 8.50143900e-01,\n",
       "        4.12768964e-01, 6.13717463e-01, 1.12307171e+00, 5.40986696e-01,\n",
       "        1.04497710e+00, 5.85495281e-01, 1.16027075e+00, 7.52200521e-01,\n",
       "        8.65311724e-01, 5.28420178e-01, 6.25105800e-01, 4.57844503e-01,\n",
       "        6.14252122e-01, 5.73182959e-01, 4.99514670e-01, 9.27922858e-01,\n",
       "        7.40193314e-01, 3.84832673e-01, 5.96933533e-01, 6.52426875e-01,\n",
       "        7.21534698e-01, 8.80391699e-01, 6.27030085e-01, 5.02278354e-01,\n",
       "        8.01251899e-01, 5.15619832e-01, 4.90188367e-01, 8.40805372e-01,\n",
       "        5.87851093e-01, 2.69283517e-01, 6.80403054e-01, 4.62411995e-01,\n",
       "        6.36789485e-01, 6.19183595e-01, 5.66675289e-01, 4.66116696e-01,\n",
       "        6.16090299e-01, 5.53788529e-01, 6.39361978e-01, 6.23290359e-01,\n",
       "        6.53898406e-01, 6.99197055e-01, 5.60634025e-01, 4.83303171e-01,\n",
       "        4.57767888e-01, 3.07790543e-01, 4.79678444e-01, 4.29086924e-01,\n",
       "        3.98644467e-01, 7.34863030e-01, 5.94066516e-01, 4.65217501e-01,\n",
       "        7.46235555e-01, 2.63140513e-01, 2.43445838e-01, 3.05923046e-01,\n",
       "        2.58833768e-01, 3.90064819e-01, 8.13785812e-01, 1.05269887e+00,\n",
       "        1.00165680e+00, 8.58586080e-01, 4.76676735e-01, 5.23326045e-01,\n",
       "        4.77961199e-01, 4.79377074e-01, 6.82440835e-01, 1.03284234e+00,\n",
       "        7.83712121e-01, 6.21232893e-01, 1.02424622e+00, 2.28287906e-01,\n",
       "        5.10741898e-01, 7.59485297e-01, 5.45542884e-01, 3.18128576e-01,\n",
       "        7.97117094e-01, 8.26183448e-01, 8.02194433e-01, 3.17966941e-01,\n",
       "        3.84784301e-01, 8.07119940e-01, 3.92920854e-01, 3.17422700e-01,\n",
       "        4.03007839e-01, 6.77814230e-01, 7.77070632e-01, 8.77086448e-01,\n",
       "        8.38790942e-01, 6.96624915e-01, 4.99270417e-01, 6.25279712e-01,\n",
       "        5.19284640e-01, 5.45230747e-01, 6.58513116e-01, 6.81025902e-01,\n",
       "        3.70937594e-01, 8.01827868e-01, 6.55846937e-01, 7.27067042e-01,\n",
       "        7.76267623e-01, 7.20721073e-01, 7.64261734e-01, 8.87610513e-01,\n",
       "        8.51387657e-01, 8.03215276e-01, 8.17463125e-01, 7.69445084e-01,\n",
       "        8.36419411e-01, 7.01452587e-01, 7.50677427e-01, 7.99219777e-01,\n",
       "        9.55357176e-01, 7.76653694e-01, 9.53662177e-01, 9.06897950e-01,\n",
       "        1.02031541e+00, 1.16240594e+00, 5.85063941e-01, 5.10403579e-01,\n",
       "        6.08983162e-01, 8.35876454e-01, 4.86076480e-01, 1.29268766e+00,\n",
       "        7.58429348e-01, 7.52207123e-01, 8.27892883e-01, 6.53893819e-01,\n",
       "        6.70130630e-01, 6.92959496e-01, 6.80960430e-01, 5.08854145e-01,\n",
       "        8.15326252e-01, 7.42131613e-01, 7.32058234e-01, 8.63171974e-01,\n",
       "        6.54860429e-01, 6.55847880e-01, 7.59345493e-01, 7.76187916e-01,\n",
       "        8.37942536e-01, 8.76370962e-01, 1.10378853e+00, 9.66093003e-01,\n",
       "        1.15977051e+00, 7.80507900e-01, 1.35537095e+00, 1.28293708e+00,\n",
       "        1.27185421e+00, 1.19595913e+00, 6.46765413e-01, 1.05521329e+00,\n",
       "        7.39322604e-01, 7.89601017e-01, 9.14122260e-01, 5.68383921e-01,\n",
       "        9.23017898e-01, 1.24731458e+00, 7.76544826e-01, 7.17058336e-01,\n",
       "        5.18449251e-01, 8.65356225e-01, 9.31461256e-01, 1.01078035e+00,\n",
       "        9.63804968e-01, 1.02526964e+00, 1.12607167e+00, 4.34246179e-01,\n",
       "        7.58919598e-01, 6.56890295e-01, 8.98463763e-01, 1.08727585e+00,\n",
       "        7.15948379e-01, 7.76679903e-01, 7.81938146e-01, 4.79053707e-01,\n",
       "        6.60774999e-01, 8.25964480e-01, 5.59056089e-01, 4.89148765e-01,\n",
       "        7.66575723e-01, 8.00089549e-01, 5.57311887e-01, 1.01711605e+00,\n",
       "        1.30766169e+00, 1.52192092e+00, 1.89061813e+00, 1.58604036e+00,\n",
       "        1.84188541e+00, 9.27093414e-01, 1.31265694e+00, 1.70600756e+00,\n",
       "        1.73643880e+00, 1.54777014e+00, 5.21934691e-01, 1.37425201e+00,\n",
       "        7.28339534e-01, 1.69080795e+00, 1.02099417e+00, 9.38450411e-01,\n",
       "        9.68735036e-01, 1.54601873e+00, 9.27797695e-01, 8.24695364e-01,\n",
       "        1.04652453e+00, 1.44201682e+00, 1.15154662e+00, 1.39534760e+00,\n",
       "        7.52497452e-01, 1.05766869e+00, 1.31898475e+00, 7.88098255e-01,\n",
       "        1.16283952e+00, 1.12781716e+00, 9.63284295e-01, 1.20656332e+00,\n",
       "        1.43363523e+00, 7.89505730e-01, 1.09725418e+00, 8.26464315e-01,\n",
       "        8.72205331e-01, 1.13812031e+00, 1.09614628e+00, 1.15246944e+00,\n",
       "        1.04719438e+00, 9.56703303e-01, 1.18101590e+00, 1.34905576e+00,\n",
       "        1.26202273e+00, 1.48338065e+00, 1.15604761e+00, 1.19972161e+00,\n",
       "        1.28014969e+00, 1.98587669e+00, 1.92923387e+00, 1.56913302e+00,\n",
       "        9.47244966e-01, 1.27997689e+00, 1.03796429e+00, 1.01678340e+00,\n",
       "        1.54968627e+00, 1.43406056e+00, 1.63155841e+00, 1.60575776e+00,\n",
       "        1.20611555e+00, 1.19325199e+00, 9.88365723e-01, 1.34482901e+00,\n",
       "        1.50303782e+00, 1.57333504e+00, 1.45630123e+00, 1.26339763e+00,\n",
       "        1.20500100e+00, 1.20994905e+00, 1.26123537e+00, 1.20583684e+00,\n",
       "        1.36124314e+00, 1.41746208e+00, 1.28479289e+00, 1.16746604e+00,\n",
       "        9.92769727e-01, 1.14155741e+00, 1.03693271e+00, 1.36054458e+00,\n",
       "        1.17726505e+00, 1.16346733e+00, 1.16805915e+00, 1.01861402e+00,\n",
       "        1.52492841e+00, 1.48314055e+00, 1.38947007e+00, 1.24237830e+00,\n",
       "        1.31630770e+00, 1.28322060e+00, 1.16864194e+00, 1.27512023e+00,\n",
       "        1.36848537e+00, 1.37992943e+00, 1.26410759e+00, 1.06549008e+00,\n",
       "        1.41402268e+00, 1.34638284e+00, 1.84051784e+00, 1.27824729e+00,\n",
       "        1.42261685e+00, 1.39433257e+00, 1.29839202e+00, 1.71813443e+00,\n",
       "        7.94697489e-01, 1.71931759e+00, 1.65938150e+00, 1.27986360e+00,\n",
       "        1.55372155e+00, 1.10703484e+00, 1.35290309e+00, 1.15317545e+00,\n",
       "        1.48031770e+00, 1.29914265e+00, 1.30931796e+00, 1.54481798e+00,\n",
       "        1.53347180e+00, 1.24169265e+00, 1.42106265e+00, 9.47802086e-01,\n",
       "        1.30241446e+00, 1.23768879e+00, 1.15313488e+00, 1.14726320e+00,\n",
       "        2.34936501e+00, 1.96888068e+00, 1.81403189e+00, 2.41728249e+00,\n",
       "        1.25611986e+00, 1.37104539e+00, 1.73661178e+00, 1.53258953e+00,\n",
       "        1.41310373e+00, 1.20864272e+00, 1.39778694e+00, 1.22867988e+00,\n",
       "        9.70532459e-01, 1.19711125e+00, 1.34575267e+00, 1.39878752e+00,\n",
       "        1.34986843e+00, 1.57344838e+00, 1.92654113e+00, 9.14458593e-01,\n",
       "        1.36383715e+00, 1.16893132e+00, 1.17417742e+00, 1.20600512e+00,\n",
       "        1.18513160e+00, 1.43156811e+00, 1.20113190e+00, 1.46925226e+00,\n",
       "        1.48301409e+00, 1.32237222e+00, 1.71577291e+00, 2.24121416e+00,\n",
       "        2.63125647e+00, 7.83565922e-01, 1.39416644e+00, 1.32710293e+00,\n",
       "        1.13238058e+00, 1.79888095e+00, 1.20341124e+00, 1.13906837e+00,\n",
       "        1.31391930e+00, 1.37866155e+00, 7.17493064e-01, 4.59693804e-01]),\n",
       " 'mean_score_time': array([0.91963847, 0.96650648, 1.01336424, 0.89700516, 0.9495643 ,\n",
       "        0.97659485, 0.98197548, 0.93483305, 0.79220533, 0.95818377,\n",
       "        0.98659476, 0.87578861, 0.90323321, 0.9197584 , 0.90603399,\n",
       "        0.88343183, 0.7879413 , 0.81931822, 0.83834696, 0.86857406,\n",
       "        0.72378596, 0.8130153 , 0.83455292, 0.8123103 , 0.74067156,\n",
       "        0.85156345, 0.82378189, 0.86193228, 0.73333549, 0.7800444 ,\n",
       "        0.78935417, 0.8141226 , 0.7572666 , 0.78136587, 0.7614998 ,\n",
       "        0.75878811, 0.73135654, 0.77585848, 0.80710268, 0.79668601,\n",
       "        0.70401597, 0.73331928, 0.72723087, 0.74461595, 0.69687319,\n",
       "        0.74461508, 0.78392641, 0.73940921, 0.71948926, 0.76362602,\n",
       "        0.73823524, 0.71162438, 0.70171642, 0.7447331 , 0.74982532,\n",
       "        0.71560407, 0.68589592, 0.68125804, 0.73420366, 0.76544372,\n",
       "        0.70816684, 0.67171518, 0.72378929, 0.70816763, 0.71032   ,\n",
       "        0.72811882, 0.70816644, 0.7853876 , 0.74300345, 0.70730249,\n",
       "        0.71371198, 0.73166172, 0.70640143, 0.70274075, 0.6982166 ,\n",
       "        0.7372841 , 0.742541  , 0.7356805 , 0.69325384, 0.72379176,\n",
       "        0.75157118, 0.77344124, 0.71374631, 0.72595127, 0.74982365,\n",
       "        0.70816851, 0.73420254, 0.72378858, 0.69774938, 0.67692208,\n",
       "        0.67692431, 0.7193346 , 0.7289923 , 0.70816747, 0.72754566,\n",
       "        0.70816946, 0.70816978, 0.71537169, 0.72292209, 0.76544182,\n",
       "        0.69167566, 0.69502004, 0.67762415, 0.70332503, 0.70521339,\n",
       "        0.72389332, 0.73764809, 0.74802621, 0.70295954, 0.71337104,\n",
       "        0.73332206, 0.73432461, 0.67337513, 0.66130129, 0.68646439,\n",
       "        0.71314534, 0.69232368, 0.70296001, 0.68761722, 0.73940992,\n",
       "        0.6982921 , 0.68386348, 0.66429885, 0.82613436, 0.66130193,\n",
       "        0.66996702, 0.68126464, 0.67045482, 0.66763449, 0.64598862,\n",
       "        0.68261154, 0.68213113, 0.67435543, 0.69775192, 0.71858112,\n",
       "        0.68125621, 0.64742192, 0.67692256, 0.73940889, 0.75814684,\n",
       "        0.68186084, 0.68964823, 0.7239902 , 0.68733811, 0.64655153,\n",
       "        0.70932937, 0.71337295, 0.72933825, 0.64714146, 0.70727897,\n",
       "        0.69254533, 0.66696779, 0.69812997, 0.70296137, 0.67919215,\n",
       "        0.73762019, 0.648597  , 0.73420119, 0.74461722, 0.69775367,\n",
       "        0.6855735 , 0.68213185, 0.70816549, 0.71858128, 0.64568448,\n",
       "        0.69567227, 0.66684588, 0.71337422, 0.75850677, 0.80189522,\n",
       "        0.7654438 , 0.7706519 , 0.72722586, 0.72291652, 0.73200194,\n",
       "        0.72681729, 0.77064912, 0.75503071, 0.77375213, 0.72811882,\n",
       "        0.78106642, 0.70640167, 0.76023897, 0.80831067, 0.73750742,\n",
       "        0.75539788, 0.79148046, 0.72031951, 0.78453732, 0.76023769,\n",
       "        0.7360901 , 0.7531569 , 0.76544404, 0.76023817, 0.75502936,\n",
       "        0.73747921, 0.76312502, 0.77499096, 0.74689833, 0.75417932,\n",
       "        0.79668625, 0.72291573, 0.7550296 , 0.75668057, 0.78627054,\n",
       "        0.75098793, 0.73420087, 0.75087325, 0.73067617, 0.71271189,\n",
       "        0.74289107, 0.71460191, 0.73763188, 0.73420294, 0.72619176,\n",
       "        0.73922936, 0.71328012, 0.75327174, 0.76544468, 0.71300395,\n",
       "        0.73763418, 0.72536119, 0.72899501, 0.75806626, 0.7116069 ,\n",
       "        0.7333312 , 0.69775414, 0.71419263, 0.74982444, 0.72259776,\n",
       "        0.77065094, 0.70883139, 0.76463405, 0.76964299, 0.73073665,\n",
       "        0.74982246, 0.7349089 , 0.75242694, 0.72379073, 0.71857913,\n",
       "        0.7150596 , 0.71683073, 0.70488238, 0.71250017, 0.72484279,\n",
       "        0.68991152, 0.77585896, 0.72926792, 0.75470956, 0.70729168,\n",
       "        0.71386401, 0.72724231, 0.69111053, 0.68713339, 0.69359525,\n",
       "        0.71158353, 0.71858358, 0.75502841, 0.73456891, 0.73419984,\n",
       "        0.73960892, 0.76890667, 0.71337255, 0.76544785, 0.71895409,\n",
       "        0.70314177, 0.73940873, 0.70442716, 0.73904276, 0.73766478,\n",
       "        0.73699633, 0.74867845, 0.72553619, 0.68098521, 0.67481184,\n",
       "        0.70433704, 0.7012976 , 0.68125836, 0.65298438, 0.73854423,\n",
       "        0.70816684, 0.69315386, 0.69076149, 0.70143207, 0.70394309,\n",
       "        0.73043911, 0.72663927, 0.74800237, 0.69775089, 0.71858048,\n",
       "        0.73332365, 0.73140693, 0.7550265 , 0.69254708, 0.67011595,\n",
       "        0.73827728, 0.67944503, 0.77644324, 0.72944371, 0.68928742,\n",
       "        0.68871427, 0.6845065 , 0.67515103, 0.67692367, 0.65581274,\n",
       "        0.73021444, 0.71226239, 0.71508797, 0.68387024, 0.76766753,\n",
       "        0.74035494, 0.67818697, 0.66399407, 0.69078358, 0.69167105,\n",
       "        0.72058169, 0.70167001, 0.68733811, 0.70172652, 0.70295922,\n",
       "        0.71621577, 0.68280959, 0.68733907, 0.6847233 , 0.76544309,\n",
       "        0.69254486, 0.67692415, 0.72899413, 0.71291908, 0.76960786,\n",
       "        0.66516916, 0.70639777, 0.69297123, 0.71636009, 0.69354884,\n",
       "        0.7029597 , 0.76502045, 0.69478861, 0.71382777, 0.78423285,\n",
       "        0.72922889, 0.74446289, 0.70337876, 0.72219801, 0.74555119,\n",
       "        0.75565712, 0.76559329, 0.76094325, 0.76040196, 0.75151475,\n",
       "        0.73533829, 0.76386817, 0.73447935, 0.76542894, 0.77399341,\n",
       "        0.75836261, 0.7731754 , 0.7293272 , 0.80710228, 0.79148022,\n",
       "        0.75505193, 0.73890336, 0.74280071, 0.77781574, 0.77802499,\n",
       "        0.72724072, 0.77024221, 0.7984314 , 0.82272188, 0.74522424,\n",
       "        0.74389259, 0.81543509, 0.75417209, 0.74805435, 0.73420231,\n",
       "        0.76833614, 0.73877088, 0.76577218, 0.6997149 , 0.72970271,\n",
       "        0.74668948, 0.79732911, 0.7333324 , 0.7558372 , 0.67585206,\n",
       "        0.68646208, 0.72722785, 0.72725193, 0.75328763, 0.71342055,\n",
       "        0.7367382 , 0.72398448, 0.69811519, 0.72601151, 0.73764062,\n",
       "        0.76563819, 0.75131162, 0.80253919, 0.70968175, 0.73853755,\n",
       "        0.75627915, 0.75503087, 0.7376705 , 0.74387813, 0.74693735,\n",
       "        0.79799453, 0.7027878 , 0.75849287, 0.73123058, 0.74455754,\n",
       "        0.73762671, 0.73670236, 0.77519202, 0.79848433, 0.72756179,\n",
       "        0.73941072, 0.75846465, 0.78689766, 0.71711357, 0.70880898,\n",
       "        0.72899683, 0.70730654, 0.71373789, 0.78627459, 0.73482577,\n",
       "        0.73420254, 0.71646198, 0.72378961, 0.72368121, 0.71337461,\n",
       "        0.7790215 , 0.70209535, 0.70817137, 0.68646391, 0.71337446,\n",
       "        0.69254486, 0.7127889 , 0.72121604, 0.70714951, 0.71250923,\n",
       "        0.73941247, 0.71685576, 0.72354499, 0.71343573, 0.73245899,\n",
       "        0.7081666 , 0.86550705, 0.75036605, 0.73431865, 0.72287226,\n",
       "        0.72384222, 0.74768933, 0.73973163, 0.87042967, 0.70816557,\n",
       "        0.72366238, 0.72032404, 0.71330889, 0.71886905, 0.71803006,\n",
       "        0.74716886, 0.68125129, 0.718515  , 0.67605281, 0.71337493,\n",
       "        0.72227446, 0.74508707, 0.72378914, 0.68977404, 0.72291565,\n",
       "        0.73246193, 0.69818068, 0.70816652, 0.71877925, 0.6801877 ,\n",
       "        0.70640874, 0.68124398, 0.7073036 , 0.68389829, 0.77064959,\n",
       "        0.69826579, 0.6916647 , 0.68062282, 0.71700382, 0.72766081,\n",
       "        0.73274589, 0.71099226, 0.73420382, 0.89261349, 0.85025112,\n",
       "        0.7076176 , 0.72851221, 0.70356154, 0.76457636, 0.70150256,\n",
       "        0.72963683, 0.69188039, 0.7324628 , 0.71250558, 0.72966115,\n",
       "        0.71573814, 0.7309312 , 0.79216329, 0.6651051 , 0.72064281,\n",
       "        0.77599406, 0.77576184, 0.77082102, 0.77065142, 0.74387566,\n",
       "        0.72379009, 0.74229614, 0.74461516, 0.76767747, 0.8166248 ,\n",
       "        0.7705876 , 0.75367808, 0.7342031 , 0.73941072, 0.7717429 ,\n",
       "        0.76612655, 0.78695997, 0.74344595, 0.78106674, 0.77367147,\n",
       "        0.78373988, 0.74521875, 0.74286461, 0.79090285, 0.76148502,\n",
       "        0.76544444, 0.78106411, 0.81231133, 0.76372147, 0.78230898,\n",
       "        0.77499048, 0.80803402, 0.77125049, 0.78106594, 0.82792958,\n",
       "        0.79707964, 0.7843341 , 0.82603073, 0.77605089, 0.71983091,\n",
       "        0.73244818, 0.73420143, 0.72203   , 0.7751557 , 0.75353297,\n",
       "        0.74963069, 0.73148338, 0.70843418, 0.75415047, 0.75521382,\n",
       "        0.75725174, 0.77103885, 0.74447036, 0.73765484, 0.74982309,\n",
       "        0.74894977, 0.74432731, 0.7492768 , 0.78291353, 0.7486221 ,\n",
       "        0.74806412, 0.74982476, 0.75936222, 0.76331186, 0.76460147,\n",
       "        0.78348517, 0.7623171 , 0.7897222 , 0.7758588 , 0.76286896,\n",
       "        0.75055035, 0.75678531, 0.78239481, 0.76957027, 0.79581269,\n",
       "        0.74982905, 0.76023833, 0.75014806, 0.809244  , 0.77321442,\n",
       "        0.74818349, 0.72899508, 0.71985857, 0.72293766, 0.75218876,\n",
       "        0.7472287 , 0.76469302, 0.74982484, 0.72748089, 0.70728676,\n",
       "        0.72721076, 0.73420191, 0.74635196, 0.76437163, 0.73591781,\n",
       "        0.73449222, 0.75271082, 0.73411139, 0.74177051, 0.76035873,\n",
       "        0.71702655, 0.79401135, 0.75503   , 0.76023817, 0.69973516,\n",
       "        0.75133228, 0.7244002 , 0.73855448, 0.75321937, 0.72918963,\n",
       "        0.72899445, 0.73489833, 0.76454488, 0.74914519, 0.75100652,\n",
       "        0.75097315, 0.77586015, 0.75936119, 0.7662739 , 0.77171008,\n",
       "        0.76544635, 0.75503079, 0.74461706, 0.71142268, 0.69640485,\n",
       "        0.70295906, 0.74282781, 0.72622967, 0.77082133, 0.73940857,\n",
       "        0.73630198, 0.69167757, 0.71858048, 0.72412769, 0.76544555,\n",
       "        0.73805134, 0.75861843, 0.74878224, 0.73416249, 0.73833219,\n",
       "        0.71875453, 0.74461587, 0.77660998, 0.73480392, 0.72378834,\n",
       "        0.71858176, 0.73420389, 0.73511608, 0.74332619, 0.73193407,\n",
       "        0.73563369, 0.7409447 , 0.72899628, 0.72888215, 0.7361091 ,\n",
       "        0.7438666 , 0.75324217, 0.75708795, 0.73420421, 0.73489118,\n",
       "        0.75503238, 0.78362791, 0.75915178, 0.7185808 , 0.70177571,\n",
       "        0.65387384, 0.61713799, 0.83676203, 0.85742299, 0.93714213,\n",
       "        0.89714622, 0.86880692, 0.81746133, 0.7726802 , 0.82703964,\n",
       "        0.85817719, 0.87655195, 0.98049339, 0.87008794, 0.85347684,\n",
       "        0.81310217, 0.8634944 , 0.86929774, 0.87009645, 0.87070624,\n",
       "        0.89448698, 0.8421727 , 0.81078537, 0.85441875, 0.86176888,\n",
       "        0.88034797, 0.8873771 , 0.86438012, 0.88409193, 0.864381  ,\n",
       "        0.84992337, 0.85074441, 0.87363148, 0.87440006, 0.88006488,\n",
       "        0.88398274, 0.85308083, 0.85157879, 0.85829171, 0.83870371,\n",
       "        0.85917123, 0.8355341 , 0.80187217, 0.76456022, 0.86930482,\n",
       "        0.87110249, 0.88937958, 0.89952405, 0.90470084, 0.83429495,\n",
       "        0.80464037, 0.84456182, 0.8848501 , 0.87960291, 0.90677786,\n",
       "        0.85538999, 0.85366782, 0.8061138 , 0.84320927, 0.88024116,\n",
       "        0.8797915 , 0.89613406, 0.90118901, 0.85472282, 0.84062831,\n",
       "        0.86861022, 0.88063399, 0.86571407, 0.87479424, 0.88779704,\n",
       "        0.86526577, 0.82704663, 0.85828177, 0.84786328, 0.85934552,\n",
       "        0.88000099, 0.86870758, 0.86659185, 0.89113196, 0.86566114,\n",
       "        0.87392481, 0.86804112, 0.86260732, 0.82855042, 0.79580673,\n",
       "        0.78116035, 0.86159094, 0.8637414 , 0.87993018, 0.89457448,\n",
       "        0.86634541, 0.82791305, 0.78526799, 0.84876116, 0.85919333,\n",
       "        0.88521242, 0.89506229, 0.86416348, 0.83857369, 0.80905946,\n",
       "        0.87161287, 0.88351885, 0.87233353, 0.8900044 , 0.85917385,\n",
       "        0.95079478, 0.75931756, 0.8162605 , 0.83834473, 0.87024061,\n",
       "        0.87369212, 0.87326884, 0.84875822, 0.83305836, 0.85683187,\n",
       "        0.86459041, 0.87489629, 0.86935178, 0.89159632, 0.85311174,\n",
       "        0.8534809 , 0.85253334, 0.85907952, 0.86841861, 0.94399651,\n",
       "        0.84481478, 0.80541277, 0.82032196, 0.85307225, 0.87909953,\n",
       "        0.92859721, 0.90777   , 0.86352452, 0.8239553 , 0.77229659,\n",
       "        0.85158038, 0.87392394, 0.95232924, 0.88863118, 0.86871314,\n",
       "        0.8478783 , 0.79665526, 0.88000186, 0.87411634, 0.88226469,\n",
       "        0.90038172, 0.85431377, 0.83898886, 0.81098946, 0.86922089,\n",
       "        0.89171576, 0.87821015, 0.87034623, 0.85968113, 0.87479536,\n",
       "        0.89931297, 0.85668349, 0.84791215, 0.86278788, 0.91887609,\n",
       "        0.87015589, 0.86207589, 0.83190767, 0.8383313 , 0.85962351,\n",
       "        0.87333457, 0.81924446, 0.76517081, 0.56955671, 0.49269636]),\n",
       " 'std_score_time': array([1.84414941e-02, 1.60262328e-02, 3.01685798e-02, 1.17418115e-01,\n",
       "        1.06434852e-01, 7.03722664e-02, 2.16690100e-02, 7.54852374e-02,\n",
       "        3.58281536e-02, 1.13722315e-02, 1.94821915e-02, 7.22966687e-02,\n",
       "        4.82106881e-02, 3.02507468e-02, 1.27552284e-02, 3.81375121e-02,\n",
       "        7.14647160e-02, 7.01582145e-02, 1.79509207e-02, 1.54941346e-02,\n",
       "        2.94567134e-02, 1.36306590e-02, 6.36389331e-03, 6.37734166e-02,\n",
       "        1.10481405e-02, 3.96503148e-02, 2.33062763e-02, 1.66749413e-02,\n",
       "        1.38316153e-02, 1.38244250e-02, 1.90013066e-02, 7.36367261e-03,\n",
       "        2.51420372e-02, 7.21146786e-03, 1.08028261e-02, 1.92023566e-02,\n",
       "        1.69225215e-02, 4.47948993e-02, 1.47269518e-02, 2.20909054e-02,\n",
       "        2.42278388e-02, 1.16910484e-02, 6.11488961e-03, 2.65517356e-02,\n",
       "        3.32423624e-02, 1.94824677e-02, 1.64302225e-02, 1.47289751e-02,\n",
       "        2.44055102e-02, 3.24825968e-02, 4.04822087e-02, 1.41485627e-02,\n",
       "        1.23082732e-02, 7.45866604e-03, 2.58500671e-06, 2.17877801e-02,\n",
       "        1.45566674e-02, 1.92855121e-02, 3.37449918e-02, 1.27575644e-02,\n",
       "        3.20984071e-02, 1.27561046e-02, 2.65482288e-02, 1.47297054e-02,\n",
       "        1.68883518e-02, 4.38239814e-02, 7.36518988e-03, 4.06112397e-02,\n",
       "        1.41869569e-02, 2.82343986e-02, 7.65225458e-03, 1.29061014e-02,\n",
       "        2.53396217e-02, 2.88507672e-02, 2.49164789e-02, 2.32584938e-02,\n",
       "        6.70907230e-02, 3.89563112e-02, 6.91844350e-03, 7.36041525e-03,\n",
       "        2.46963674e-03, 3.61394554e-02, 2.05032618e-02, 8.77209974e-02,\n",
       "        2.20885454e-02, 1.47274576e-02, 2.20932656e-02, 1.47286939e-02,\n",
       "        1.94824676e-02, 1.47261091e-02, 7.36080694e-03, 1.18427842e-02,\n",
       "        1.94816606e-02, 7.36479671e-03, 4.17042582e-02, 3.68193184e-02,\n",
       "        7.36637020e-03, 5.50028768e-02, 2.77425054e-02, 1.27526977e-02,\n",
       "        3.09745516e-02, 2.31705828e-02, 1.37352650e-02, 3.32426770e-02,\n",
       "        3.18506544e-03, 1.45736498e-02, 4.37735987e-02, 2.18085132e-02,\n",
       "        2.55078288e-02, 5.15473298e-02, 2.55404214e-02, 3.55858809e-02,\n",
       "        1.07891149e-02, 7.36547090e-03, 3.25322100e-02, 2.92966678e-02,\n",
       "        1.51762650e-02, 1.03008599e-06, 2.51686848e-02, 7.36474031e-03,\n",
       "        1.04529618e-02, 2.70048907e-02, 1.59912577e-03, 1.55931168e-01,\n",
       "        1.47265024e-02, 2.08554970e-02, 1.53740171e-02, 2.17906965e-02,\n",
       "        2.34094141e-02, 7.80025774e-03, 2.85731620e-02, 1.94826801e-02,\n",
       "        3.00921695e-02, 7.36434706e-03, 3.37447710e-02, 8.59975538e-03,\n",
       "        1.76978170e-02, 2.65522655e-02, 1.94841460e-02, 4.14472557e-02,\n",
       "        7.29743447e-03, 3.68740333e-02, 7.63401157e-03, 2.20906806e-02,\n",
       "        1.01743246e-02, 4.44391441e-02, 1.47293122e-02, 3.27805849e-02,\n",
       "        8.88895706e-03, 2.04485212e-02, 1.47289188e-02, 1.52613181e-02,\n",
       "        4.12632696e-02, 1.27532817e-02, 3.02036186e-02, 3.10951038e-02,\n",
       "        1.14905796e-02, 1.27557151e-02, 2.65520785e-02, 2.65519382e-02,\n",
       "        1.16946416e-02, 3.89633211e-02, 1.47286939e-02, 2.55077314e-02,\n",
       "        2.65505823e-02, 2.69853331e-02, 7.61335070e-03, 3.21007406e-02,\n",
       "        3.80472002e-02, 7.36400979e-03, 1.27560071e-02, 1.47278509e-02,\n",
       "        6.11303510e-03, 2.77530483e-02, 2.52196858e-02, 3.14789306e-02,\n",
       "        1.47253785e-02, 2.65505667e-02, 8.66868875e-03, 2.06590386e-02,\n",
       "        1.27535738e-02, 8.87926354e-03, 7.36631380e-03, 4.01578523e-02,\n",
       "        6.80077894e-03, 9.78830051e-03, 7.36333542e-03, 1.06973676e-02,\n",
       "        1.29887579e-02, 7.36372879e-03, 2.63385922e-02, 3.77190159e-02,\n",
       "        1.78416128e-06, 1.94832960e-02, 7.36395357e-03, 2.31858289e-03,\n",
       "        3.19251139e-02, 8.59621509e-03, 1.14736509e-02, 1.52552093e-02,\n",
       "        1.27561046e-02, 8.05197002e-03, 3.20974532e-02, 9.69473049e-03,\n",
       "        7.36530227e-03, 3.26904992e-02, 2.20970307e-02, 2.68061458e-02,\n",
       "        1.36970389e-02, 2.03678047e-02, 2.59760514e-02, 1.70304276e-02,\n",
       "        2.53352826e-02, 2.20919169e-02, 2.32690929e-02, 1.37167623e-04,\n",
       "        2.65878401e-02, 2.53439428e-02, 1.27538657e-02, 3.10629047e-02,\n",
       "        1.85495117e-02, 1.92170847e-02, 7.36468412e-03, 1.71760772e-02,\n",
       "        1.72081654e-02, 1.38457073e-02, 1.47299864e-02, 2.14940611e-02,\n",
       "        2.55102622e-02, 1.40623512e-02, 1.94825102e-02, 3.16986713e-02,\n",
       "        1.48310659e-02, 1.89017210e-02, 3.07611982e-02, 1.27548391e-02,\n",
       "        2.26082124e-02, 6.38569292e-03, 4.10013134e-02, 1.27528926e-02,\n",
       "        2.70728315e-02, 2.08534177e-02, 1.93732204e-02, 3.99064808e-02,\n",
       "        1.83797640e-02, 1.60022534e-02, 7.36513368e-03, 1.89089824e-02,\n",
       "        7.11458719e-03, 2.57073062e-02, 1.98104177e-02, 1.83161309e-02,\n",
       "        1.67598912e-02, 2.30098538e-02, 8.84875910e-03, 1.41391575e-02,\n",
       "        3.82630572e-02, 1.94836996e-02, 4.54932717e-02, 1.27538657e-02,\n",
       "        1.49404444e-02, 2.88597367e-02, 7.36361639e-03, 1.27547418e-02,\n",
       "        3.32274873e-02, 1.25335714e-02, 3.89655725e-02, 1.45897332e-02,\n",
       "        2.91026448e-02, 1.92865866e-02, 1.17195776e-02, 1.33408062e-02,\n",
       "        1.76889836e-02, 1.31120532e-02, 1.64712267e-02, 1.57889672e-02,\n",
       "        7.97888992e-03, 6.83203583e-03, 4.88736150e-02, 2.57182769e-02,\n",
       "        1.94851440e-02, 1.51574914e-02, 2.14548139e-02, 2.15679621e-03,\n",
       "        2.50336536e-02, 3.25885434e-02, 2.35013852e-02, 2.14773173e-02,\n",
       "        1.94836997e-02, 2.20921979e-02, 1.16941632e-02, 1.41029469e-02,\n",
       "        7.36327930e-03, 1.94824677e-02, 1.62796818e-02, 3.96527002e-02,\n",
       "        1.15242697e-02, 3.32463022e-02, 3.16302056e-02, 2.74251892e-02,\n",
       "        1.46182590e-02, 2.00870756e-02, 6.85349425e-03, 2.65509252e-02,\n",
       "        7.51465465e-03, 3.12575159e-03, 1.76408665e-02, 4.89808717e-03,\n",
       "        4.90718568e-03, 7.36254868e-03, 6.83028313e-03, 1.34049280e-02,\n",
       "        1.43472536e-02, 6.82703014e-03, 8.05274881e-03, 1.41261125e-04,\n",
       "        3.33275743e-02, 2.20911864e-02, 2.83126232e-02, 2.97360213e-07,\n",
       "        3.60256210e-02, 1.94516595e-02, 5.15042996e-07, 2.06716885e-02,\n",
       "        4.41840586e-02, 1.47258841e-02, 7.36260488e-03, 1.94825314e-02,\n",
       "        3.72727180e-02, 4.48316121e-03, 1.57598505e-02, 6.82281655e-03,\n",
       "        3.16151969e-02, 1.20894448e-02, 1.82380504e-02, 4.89903609e-07,\n",
       "        2.54569972e-02, 2.36283808e-02, 1.17339896e-02, 1.93109104e-02,\n",
       "        7.03121825e-03, 3.90099263e-02, 3.47278158e-02, 2.12332996e-02,\n",
       "        2.96476667e-02, 3.24556265e-02, 1.21686616e-02, 1.57298222e-02,\n",
       "        7.87707740e-03, 2.40668112e-02, 7.28576531e-03, 1.14369087e-02,\n",
       "        2.22890983e-02, 1.27751898e-02, 2.19941987e-02, 1.00160019e-02,\n",
       "        7.36232389e-03, 1.95782002e-02, 1.47265585e-02, 7.36198672e-03,\n",
       "        1.91346098e-02, 2.03547586e-02, 1.61659521e-02, 9.07046068e-03,\n",
       "        1.84421684e-02, 6.12286940e-03, 1.18953269e-02, 2.34054162e-02,\n",
       "        7.36384119e-03, 2.59639909e-02, 4.23928323e-03, 3.47379219e-02,\n",
       "        1.83398423e-02, 1.28152038e-02, 1.07214749e-06, 3.28577575e-02,\n",
       "        1.65407212e-02, 3.34476705e-02, 4.58878051e-03, 3.87890271e-02,\n",
       "        1.06292354e-02, 7.36445933e-03, 1.38366567e-02, 4.09311816e-02,\n",
       "        3.56801079e-02, 1.23434350e-03, 3.09575896e-02, 2.57120360e-02,\n",
       "        2.88584465e-02, 1.47929257e-02, 7.36372879e-03, 1.48752585e-02,\n",
       "        7.63472681e-03, 1.15804368e-02, 3.07049907e-02, 2.22264496e-02,\n",
       "        3.51581751e-02, 3.94276782e-02, 1.11467460e-02, 1.59640463e-02,\n",
       "        4.59358096e-02, 7.36507772e-03, 2.06475836e-02, 1.45462538e-02,\n",
       "        3.38681324e-02, 2.67423133e-02, 1.11120428e-02, 2.62372729e-02,\n",
       "        2.52616807e-02, 2.65791719e-02, 6.82231338e-03, 2.04822592e-02,\n",
       "        3.40439654e-02, 7.36372912e-03, 8.99918662e-03, 1.47263337e-02,\n",
       "        2.56982149e-02, 4.31371819e-02, 2.41685764e-02, 1.51828712e-02,\n",
       "        2.65501770e-02, 8.04303231e-03, 6.84948105e-03, 1.94814694e-02,\n",
       "        1.79393531e-02, 2.20911302e-02, 2.01378734e-02, 1.94818517e-02,\n",
       "        2.12918678e-02, 7.36423455e-03, 1.00945224e-01, 2.08595994e-02,\n",
       "        7.36120409e-03, 1.28136938e-02, 7.36226775e-03, 1.47277386e-02,\n",
       "        1.67605313e-02, 1.89111213e-02, 2.10715762e-02, 6.83714307e-03,\n",
       "        2.65515330e-02, 2.08716252e-02, 2.83701646e-02, 1.89836932e-02,\n",
       "        2.44494012e-02, 1.94823402e-02, 4.72296974e-02, 2.15443473e-02,\n",
       "        2.30324542e-02, 3.09167185e-02, 1.46481092e-02, 2.15472964e-02,\n",
       "        1.94025100e-02, 3.71226393e-02, 7.36597667e-03, 1.79294186e-02,\n",
       "        1.06895180e-02, 7.31752475e-03, 2.23758974e-03, 1.27780998e-02,\n",
       "        1.27555204e-02, 1.34815967e-02, 3.37758584e-02, 8.04961949e-03,\n",
       "        1.47292559e-02, 3.38378565e-02, 3.89360450e-02, 3.68184191e-02,\n",
       "        9.93665162e-03, 8.05116341e-03, 1.22967770e-03, 1.95473931e-02,\n",
       "        1.94838270e-02, 2.22355503e-02, 6.11150560e-03, 3.11090002e-02,\n",
       "        6.82236167e-03, 2.62395987e-02, 1.26604444e-02, 7.36580807e-03,\n",
       "        2.00407351e-02, 1.59798933e-02, 2.70860858e-02, 3.43141460e-03,\n",
       "        3.57577142e-02, 5.28127294e-02, 2.94637866e-02, 1.27541579e-02,\n",
       "        1.79696036e-02, 2.22545676e-02, 7.78297597e-03, 1.03483175e-02,\n",
       "        8.50524077e-04, 2.27319867e-02, 1.65957545e-03, 6.37713937e-03,\n",
       "        7.95461114e-03, 2.44531748e-02, 1.92926322e-02, 1.50324242e-02,\n",
       "        1.18956824e-02, 3.55282584e-02, 1.94830836e-02, 1.47485959e-02,\n",
       "        2.91538200e-03, 6.92987544e-03, 1.94584551e-02, 1.50343573e-02,\n",
       "        7.36451553e-03, 1.98536124e-02, 2.65504576e-02, 1.06410116e-02,\n",
       "        7.36243628e-03, 7.58699987e-03, 8.06822133e-03, 1.46812494e-02,\n",
       "        1.56226219e-02, 1.27565911e-02, 7.36518988e-03, 1.44031999e-02,\n",
       "        1.19283893e-02, 3.13258314e-02, 2.83824815e-03, 1.27574671e-02,\n",
       "        8.16626321e-03, 3.37593466e-02, 1.96628967e-02, 6.12781485e-03,\n",
       "        4.16969208e-02, 1.38697461e-02, 1.27584404e-02, 2.20933221e-02,\n",
       "        2.55053955e-02, 1.28099104e-02, 8.75418163e-04, 8.60177891e-03,\n",
       "        7.41611174e-03, 1.38816548e-02, 2.20927036e-02, 2.55080234e-02,\n",
       "        1.32358434e-02, 3.10006316e-02, 3.72507431e-02, 8.97756697e-03,\n",
       "        7.59487303e-03, 1.28156750e-02, 1.27530871e-02, 4.87464832e-03,\n",
       "        2.96193924e-02, 3.05775500e-02, 9.93319040e-03, 1.57229998e-02,\n",
       "        1.98408848e-02, 3.00963136e-02, 2.23609771e-02, 3.04882507e-02,\n",
       "        1.96913131e-02, 1.79642545e-02, 1.34871039e-02, 7.78671819e-07,\n",
       "        1.38398734e-02, 1.77493663e-02, 2.17575418e-02, 7.66467122e-03,\n",
       "        1.05037948e-02, 2.44384997e-02, 3.37429316e-02, 6.83051110e-03,\n",
       "        3.74668625e-03, 2.46516674e-02, 7.47566880e-03, 2.33534928e-03,\n",
       "        6.12090252e-03, 7.36518988e-03, 3.64764537e-02, 2.26061089e-02,\n",
       "        6.62482330e-03, 2.55778834e-02, 1.79299846e-02, 1.17001162e-02,\n",
       "        1.27530882e-02, 7.36552706e-03, 1.23589705e-02, 3.79810733e-02,\n",
       "        6.57272868e-03, 1.25131988e-02, 1.94839332e-02, 2.74068146e-02,\n",
       "        6.15237346e-03, 1.16669863e-02, 8.28398611e-03, 2.03468920e-02,\n",
       "        2.55095808e-02, 1.59081270e-02, 1.41487961e-02, 1.82962571e-02,\n",
       "        1.27550337e-02, 3.07563085e-02, 2.66094880e-02, 2.09851953e-02,\n",
       "        4.10230065e-04, 1.64230452e-02, 1.43055658e-02, 2.94833962e-02,\n",
       "        3.15143936e-02, 1.01325924e-02, 1.27556178e-02, 2.65490704e-02,\n",
       "        7.36389795e-03, 4.56298651e-03, 1.15139648e-02, 1.51786221e-02,\n",
       "        6.15563156e-03, 8.93254336e-03, 7.85732791e-03, 7.36530267e-03,\n",
       "        1.31849980e-02, 2.55405739e-02, 3.43828288e-02, 2.29731398e-02,\n",
       "        5.16061134e-03, 7.36361650e-03, 2.06573851e-02, 1.97565832e-02,\n",
       "        1.55292983e-02, 1.27548391e-02, 1.94822340e-02, 1.94831898e-02,\n",
       "        1.38992904e-02, 9.27090178e-03, 1.85701393e-06, 1.62878368e-02,\n",
       "        2.95640241e-02, 1.94402390e-02, 3.20990904e-02, 1.30344279e-02,\n",
       "        1.59508963e-02, 2.20955697e-02, 1.49722037e-02, 2.20918046e-02,\n",
       "        1.99422898e-02, 2.63052741e-02, 3.08487921e-02, 1.95537029e-02,\n",
       "        2.76079274e-02, 2.43608804e-04, 1.94809596e-02, 7.11175939e-03,\n",
       "        2.62390454e-02, 7.36299825e-03, 2.55076341e-02, 8.77806426e-07,\n",
       "        2.30568652e-02, 1.81429320e-02, 1.01051882e-02, 2.02383641e-03,\n",
       "        1.70542127e-02, 7.36524607e-03, 1.48115376e-02, 3.28351407e-02,\n",
       "        8.24509426e-03, 4.37588727e-02, 2.86465587e-02, 1.27542551e-02,\n",
       "        2.46708320e-02, 1.47270080e-02, 3.21002379e-02, 2.03246761e-02,\n",
       "        2.08152149e-06, 3.53159003e-02, 9.38036410e-03, 1.09095151e-02,\n",
       "        5.87836149e-03, 2.56295214e-02, 6.45208615e-02, 5.18289915e-03,\n",
       "        3.06467899e-02, 7.28865148e-03, 7.91558333e-03, 2.27487796e-02,\n",
       "        1.34571159e-02, 3.43812069e-02, 9.05230134e-02, 7.87852452e-03,\n",
       "        1.64681809e-02, 1.05414911e-02, 1.41443250e-02, 1.72829075e-02,\n",
       "        7.74673018e-03, 1.43823787e-02, 7.90663995e-03, 1.29030129e-02,\n",
       "        1.09400994e-02, 3.20694892e-02, 1.32797978e-02, 2.20823244e-02,\n",
       "        3.23804085e-02, 1.47281319e-02, 6.71608101e-03, 3.21000445e-02,\n",
       "        1.17718121e-02, 1.49069842e-02, 2.51841992e-02, 2.52657432e-02,\n",
       "        6.32237571e-03, 2.02043697e-02, 1.85556626e-02, 1.08498708e-02,\n",
       "        1.38498740e-02, 1.52377154e-02, 1.27553258e-02, 2.94453759e-02,\n",
       "        7.93795250e-03, 2.27428932e-02, 1.66757008e-02, 1.55227795e-02,\n",
       "        1.24523888e-02, 4.26815291e-03, 2.11881904e-02, 4.44841326e-03,\n",
       "        2.25973269e-02, 5.49824918e-03, 2.28048734e-02, 2.04460133e-02,\n",
       "        2.15850742e-02, 1.43780245e-02, 3.86120029e-02, 1.94066661e-02,\n",
       "        1.18755554e-02, 2.68241568e-02, 1.92022773e-02, 7.66450231e-03,\n",
       "        2.64154383e-02, 9.94466526e-03, 1.64671800e-02, 8.70478727e-03,\n",
       "        1.45097246e-02, 1.60314061e-02, 1.27558124e-02, 8.83070505e-03,\n",
       "        1.53773198e-02, 1.38494664e-02, 1.38611359e-02, 8.06950357e-03,\n",
       "        1.44980670e-02, 2.94566572e-02, 1.53932611e-02, 1.78726258e-02,\n",
       "        2.20912426e-02, 1.65227341e-02, 2.44544187e-02, 6.55025396e-03,\n",
       "        1.92871867e-02, 1.27848363e-02, 1.24591704e-03, 1.18323842e-02,\n",
       "        1.48496820e-02, 1.95157126e-02, 7.25841866e-03, 1.60550542e-02,\n",
       "        3.19377216e-02, 1.27778174e-02, 8.12959640e-03, 7.36283005e-03,\n",
       "        1.27553606e-02, 1.47257720e-02, 8.50740737e-03, 1.64774667e-02,\n",
       "        1.74486392e-02, 1.35571252e-02, 3.51813842e-02, 1.61080759e-02,\n",
       "        2.00566293e-02, 4.90588582e-03, 1.27541579e-02, 1.41834449e-01,\n",
       "        1.34258505e-02, 1.93882981e-02, 7.36502135e-03, 2.63087210e-02,\n",
       "        2.38522809e-02, 1.29358809e-02, 1.47293120e-02, 7.42117597e-03,\n",
       "        3.87627752e-03, 1.94315268e-02, 9.83440165e-03, 2.03868894e-02,\n",
       "        1.13392552e-02, 1.35193603e-02, 2.04339179e-02, 9.39183515e-03,\n",
       "        1.34308098e-04, 3.51764909e-02, 3.15365748e-02, 2.38770326e-02,\n",
       "        1.14923282e-02, 5.69610811e-02, 6.81996255e-03, 1.97647298e-02,\n",
       "        3.19060073e-02, 3.30262295e-02, 1.95225639e-02, 8.37308481e-03,\n",
       "        7.48015093e-03, 5.72573565e-03, 2.65836021e-02, 7.28830175e-03,\n",
       "        2.15237863e-02, 6.82990127e-03, 1.83121430e-02, 1.27546309e-02,\n",
       "        7.36282965e-03, 1.16004380e-02, 2.51026618e-02, 2.34720512e-02,\n",
       "        1.90178597e-02, 1.96764796e-02, 1.28976250e-02, 6.70173086e-03,\n",
       "        1.27851857e-02, 1.34602423e-02, 1.71636861e-02, 1.12753031e-02,\n",
       "        1.27563964e-02, 7.34545138e-02, 1.30147194e-02, 1.98197302e-02,\n",
       "        3.87773988e-02, 6.99537463e-02, 2.27465704e-02, 1.61300345e-02,\n",
       "        2.50517996e-02, 1.47068337e-02, 2.27277162e-02, 1.45796277e-02,\n",
       "        4.14971836e-02, 1.92427731e-02, 2.80938509e-02, 2.17318797e-02]),\n",
       " 'param_max_depth': masked_array(data=[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500}],\n",
       " 'split0_test_score': array([0.82419758, 0.82419758, 0.82351715, 0.82499349, 0.82655714,\n",
       "        0.82633111, 0.82251669, 0.8248464 , 0.8248464 , 0.8248464 ,\n",
       "        0.8243567 , 0.82478521, 0.82298946, 0.82444259, 0.82548275,\n",
       "        0.82548275, 0.82548275, 0.82548275, 0.82517701, 0.82607565,\n",
       "        0.82327788, 0.82349875, 0.82349875, 0.82349875, 0.82349875,\n",
       "        0.82497526, 0.82482816, 0.82343742, 0.82134837, 0.82134837,\n",
       "        0.82134837, 0.82134837, 0.82231383, 0.82482816, 0.82171757,\n",
       "        0.82378694, 0.82378694, 0.82378694, 0.82378694, 0.82378694,\n",
       "        0.82378694, 0.82120658, 0.82542161, 0.82542161, 0.82419758,\n",
       "        0.82550091, 0.82517701, 0.8268261 , 0.82672212, 0.8240567 ,\n",
       "        0.8240567 , 0.8240567 , 0.82694807, 0.82609374, 0.82525636,\n",
       "        0.82401376, 0.826399  , 0.826399  , 0.826399  , 0.826399  ,\n",
       "        0.82507289, 0.8267651 , 0.8237502 , 0.82458333, 0.82458333,\n",
       "        0.82458333, 0.82458333, 0.82438135, 0.825605  , 0.82529932,\n",
       "        0.82595348, 0.82595348, 0.82595348, 0.82595348, 0.82722785,\n",
       "        0.82827024, 0.82595348, 0.82554387, 0.82554387, 0.82554387,\n",
       "        0.82554387, 0.82554387, 0.82554387, 0.8243201 , 0.82327788,\n",
       "        0.82327788, 0.8219078 , 0.82511584, 0.82450383, 0.82517701,\n",
       "        0.82629499, 0.82295253, 0.82295253, 0.82295253, 0.82450383,\n",
       "        0.82327788, 0.82619097, 0.82472402, 0.82227674, 0.82227674,\n",
       "        0.82227674, 0.82227674, 0.82407504, 0.8238666 , 0.82349875,\n",
       "        0.82460801, 0.82460801, 0.82460801, 0.82460801, 0.82358461,\n",
       "        0.82554387, 0.82474871, 0.82321652, 0.82321652, 0.82321652,\n",
       "        0.82321652, 0.82307532, 0.82305085, 0.82438135, 0.8231367 ,\n",
       "        0.8231367 , 0.8231367 , 0.8231367 , 0.8231367 , 0.8231367 ,\n",
       "        0.82376857, 0.82638094, 0.82638094, 0.82454678, 0.82370726,\n",
       "        0.8263199 , 0.82401376, 0.8227683 , 0.82482816, 0.82482816,\n",
       "        0.82482816, 0.82577019, 0.8263199 , 0.82511584, 0.82558684,\n",
       "        0.82417926, 0.82417926, 0.82417926, 0.82417926, 0.82332082,\n",
       "        0.82609374, 0.82664309, 0.82550091, 0.82550091, 0.82550091,\n",
       "        0.82550091, 0.82540344, 0.82485287, 0.82446088, 0.82705204,\n",
       "        0.82705204, 0.82705204, 0.82705204, 0.82479167, 0.82613672,\n",
       "        0.8231367 , 0.8240567 , 0.8240567 , 0.8240567 , 0.8240567 ,\n",
       "        0.8240567 , 0.8240567 , 0.82619778, 0.82747869, 0.82747869,\n",
       "        0.82528113, 0.82629499, 0.82591051, 0.82562315, 0.82566611,\n",
       "        0.82501171, 0.82501171, 0.82501171, 0.82834891, 0.82723493,\n",
       "        0.82536047, 0.82502993, 0.82641706, 0.82641706, 0.82641706,\n",
       "        0.82641706, 0.82694807, 0.82470576, 0.82741776, 0.8273927 ,\n",
       "        0.8273927 , 0.8273927 , 0.8273927 , 0.82731383, 0.825605  ,\n",
       "        0.82344353, 0.82554387, 0.82554387, 0.82554387, 0.82554387,\n",
       "        0.8248464 , 0.82629499, 0.82584942, 0.82584942, 0.82584942,\n",
       "        0.82584942, 0.82584942, 0.82584942, 0.82584942, 0.82584942,\n",
       "        0.82582458, 0.82582458, 0.82505467, 0.82497526, 0.82536047,\n",
       "        0.82556203, 0.82686909, 0.82786204, 0.82786204, 0.82786204,\n",
       "        0.8274357 , 0.82578832, 0.82543978, 0.8251588 , 0.82751455,\n",
       "        0.82751455, 0.82751455, 0.82751455, 0.82548275, 0.82521997,\n",
       "        0.82519521, 0.82597159, 0.82597159, 0.82597159, 0.82597159,\n",
       "        0.82733177, 0.82652106, 0.8267651 , 0.82753247, 0.82753247,\n",
       "        0.82753247, 0.82753247, 0.82833108, 0.82607565, 0.82589239,\n",
       "        0.82800166, 0.82800166, 0.82800166, 0.82800166, 0.82800166,\n",
       "        0.82800166, 0.82854918, 0.82307532, 0.82307532, 0.82786204,\n",
       "        0.82601457, 0.82548275, 0.82577019, 0.82215378, 0.82607565,\n",
       "        0.82607565, 0.82607565, 0.82474871, 0.82603267, 0.82686909,\n",
       "        0.82376857, 0.82662507, 0.82662507, 0.82662507, 0.82662507,\n",
       "        0.82700904, 0.82419758, 0.82436305, 0.82462628, 0.82462628,\n",
       "        0.82462628, 0.82462628, 0.82401376, 0.82456506, 0.82370726,\n",
       "        0.82625884, 0.82625884, 0.82625884, 0.82625884, 0.825605  ,\n",
       "        0.82460801, 0.82401376, 0.82425884, 0.82425884, 0.82425884,\n",
       "        0.82425884, 0.82425884, 0.82425884, 0.82378694, 0.82609374,\n",
       "        0.82609374, 0.82644198, 0.8287138 , 0.82713098, 0.82562315,\n",
       "        0.82755754, 0.82456506, 0.82456506, 0.82456506, 0.82444259,\n",
       "        0.82603267, 0.82517701, 0.82646003, 0.82767936, 0.82767936,\n",
       "        0.82767936, 0.82767936, 0.82714895, 0.82919996, 0.82411798,\n",
       "        0.82672212, 0.82672212, 0.82672212, 0.82672212, 0.8265391 ,\n",
       "        0.82745363, 0.825605  , 0.82586754, 0.82586754, 0.82586754,\n",
       "        0.82586754, 0.82719193, 0.82552571, 0.82609374, 0.82534229,\n",
       "        0.82534229, 0.82534229, 0.82534229, 0.82534229, 0.82534229,\n",
       "        0.82523817, 0.82696606, 0.82696606, 0.82576349, 0.82801952,\n",
       "        0.82680112, 0.82707001, 0.82543978, 0.82446088, 0.82446088,\n",
       "        0.82446088, 0.82592862, 0.82714895, 0.82570239, 0.82556203,\n",
       "        0.82946058, 0.82946058, 0.82946058, 0.82946058, 0.82611183,\n",
       "        0.82344353, 0.82429546, 0.82413631, 0.82413631, 0.82413631,\n",
       "        0.82413631, 0.82572722, 0.8258313 , 0.82731383, 0.82493231,\n",
       "        0.82493231, 0.82493231, 0.82493231, 0.82378694, 0.82617289,\n",
       "        0.82409337, 0.82696606, 0.82696606, 0.82696606, 0.82696606,\n",
       "        0.82696606, 0.82696606, 0.82556203, 0.82877459, 0.82877459,\n",
       "        0.825605  , 0.82580645, 0.82568425, 0.83000674, 0.82755754,\n",
       "        0.8274357 , 0.8274357 , 0.8274357 , 0.82717397, 0.82751455,\n",
       "        0.8259897 , 0.82542161, 0.82725288, 0.82725288, 0.82725288,\n",
       "        0.82725288, 0.82580645, 0.82694807, 0.82737477, 0.82647808,\n",
       "        0.82647808, 0.82647808, 0.82647808, 0.82737477, 0.82753247,\n",
       "        0.8267651 , 0.82777605, 0.82777605, 0.82777605, 0.82777605,\n",
       "        0.82698404, 0.82844537, 0.8280268 , 0.8279838 , 0.8279838 ,\n",
       "        0.8279838 , 0.8279838 , 0.8279838 , 0.8279838 , 0.8265391 ,\n",
       "        0.82548275, 0.82548275, 0.82635602, 0.82646003, 0.82627692,\n",
       "        0.82625884, 0.8274357 , 0.8263199 , 0.8263199 , 0.8263199 ,\n",
       "        0.82501171, 0.82482816, 0.82529932, 0.82627692, 0.82627692,\n",
       "        0.82627692, 0.82627692, 0.82627692, 0.8279838 , 0.82646003,\n",
       "        0.82568425, 0.82592862, 0.82592862, 0.82592862, 0.82592862,\n",
       "        0.82605077, 0.82534229, 0.82509763, 0.82558684, 0.82558684,\n",
       "        0.82558684, 0.82558684, 0.82595348, 0.82699106, 0.82556203,\n",
       "        0.82517701, 0.82517701, 0.82517701, 0.82517701, 0.82517701,\n",
       "        0.82517701, 0.82572722, 0.82584942, 0.82584942, 0.82633796,\n",
       "        0.82824507, 0.82660011, 0.82595348, 0.82885314, 0.82595348,\n",
       "        0.82595348, 0.82595348, 0.82694807, 0.82787992, 0.82601457,\n",
       "        0.8263199 , 0.82686909, 0.82686909, 0.82686909, 0.82686909,\n",
       "        0.82609374, 0.82812338, 0.82572722, 0.82680809, 0.82680809,\n",
       "        0.82680809, 0.82680809, 0.82572722, 0.8258313 , 0.82536047,\n",
       "        0.82775815, 0.82775815, 0.82775815, 0.82775815, 0.82664309,\n",
       "        0.82511584, 0.82848837, 0.82609374, 0.82609374, 0.82609374,\n",
       "        0.82609374, 0.82609374, 0.82609374, 0.82688709, 0.82800166,\n",
       "        0.82800166, 0.82713098, 0.82664309, 0.82693008, 0.8273927 ,\n",
       "        0.82617289, 0.82722785, 0.82722785, 0.82722785, 0.82786204,\n",
       "        0.82737477, 0.82897468, 0.82637408, 0.82796593, 0.82796593,\n",
       "        0.82796593, 0.82796593, 0.82594673, 0.82903544, 0.82766145,\n",
       "        0.82713098, 0.82713098, 0.82713098, 0.82713098, 0.82619097,\n",
       "        0.82698404, 0.82658208, 0.82713098, 0.82713098, 0.82713098,\n",
       "        0.82713098, 0.82856698, 0.82617289, 0.82570239, 0.82674014,\n",
       "        0.82674014, 0.82674014, 0.82674014, 0.82674014, 0.82674014,\n",
       "        0.82702703, 0.82419758, 0.82419758, 0.82644198, 0.82647808,\n",
       "        0.8268261 , 0.8267651 , 0.8282629 , 0.82895693, 0.82895693,\n",
       "        0.82895693, 0.82641706, 0.8279838 , 0.82647808, 0.82777605,\n",
       "        0.82729588, 0.82729588, 0.82729588, 0.82729588, 0.82881761,\n",
       "        0.82860999, 0.82814853, 0.82731383, 0.82731383, 0.82731383,\n",
       "        0.82731383, 0.82711301, 0.82816638, 0.82727084, 0.82761845,\n",
       "        0.82761845, 0.82761845, 0.82761845, 0.82727084, 0.82731383,\n",
       "        0.82710596, 0.82619097, 0.82619097, 0.82619097, 0.82619097,\n",
       "        0.82619097, 0.82619097, 0.8268441 , 0.82816638, 0.82816638,\n",
       "        0.82668608, 0.82816638, 0.82804466, 0.82713098, 0.82621586,\n",
       "        0.82753962, 0.82753962, 0.82753962, 0.82664309, 0.82672212,\n",
       "        0.82735682, 0.82664309, 0.82745363, 0.82745363, 0.82745363,\n",
       "        0.82745363, 0.82772236, 0.82806252, 0.82572722, 0.82694807,\n",
       "        0.82694807, 0.82694807, 0.82694807, 0.82700904, 0.82760054,\n",
       "        0.82700904, 0.82774026, 0.82774026, 0.82774026, 0.82774026,\n",
       "        0.82705204, 0.82713098, 0.82680112, 0.8273927 , 0.8273927 ,\n",
       "        0.8273927 , 0.8273927 , 0.8273927 , 0.8273927 , 0.82607565,\n",
       "        0.82625884, 0.82625884, 0.8267041 , 0.82662507, 0.82851358,\n",
       "        0.82822723, 0.82664309, 0.82556203, 0.82556203, 0.82556203,\n",
       "        0.82672212, 0.82725288, 0.82932144, 0.82580645, 0.82652106,\n",
       "        0.82652106, 0.82652106, 0.82652106, 0.82796593, 0.8268261 ,\n",
       "        0.82550091, 0.82656404, 0.82656404, 0.82656404, 0.82656404,\n",
       "        0.82731383, 0.82589239, 0.82452211, 0.82792292, 0.82792292,\n",
       "        0.82792292, 0.82792292, 0.82688709, 0.82881761, 0.82766145,\n",
       "        0.82711301, 0.82711301, 0.82711301, 0.82711301, 0.82711301,\n",
       "        0.82711301, 0.8274357 , 0.825605  , 0.825605  , 0.82519521,\n",
       "        0.82513405, 0.82537865, 0.8265391 , 0.82801952, 0.82488935,\n",
       "        0.82488935, 0.82488935, 0.82439965, 0.82533569, 0.82517701,\n",
       "        0.82556203, 0.82447917, 0.82447917, 0.82447917, 0.82447917,\n",
       "        0.82660011, 0.82556203, 0.82548275, 0.82606887, 0.82606887,\n",
       "        0.82606887, 0.82606887, 0.82501171, 0.82707001, 0.82707001,\n",
       "        0.82395247, 0.82395247, 0.82395247, 0.82395247, 0.8250911 ,\n",
       "        0.82558019, 0.82623394, 0.82647808, 0.82647808, 0.82647808,\n",
       "        0.82647808, 0.82647808, 0.82647808, 0.82519521, 0.82554387,\n",
       "        0.82554387, 0.82409337, 0.82574536, 0.82592862, 0.8268441 ,\n",
       "        0.82725288, 0.82517701, 0.82517701, 0.82517701, 0.82501171,\n",
       "        0.82621586, 0.82554387, 0.82566611, 0.82578832, 0.82578832,\n",
       "        0.82578832, 0.82578832, 0.82554387, 0.82439965, 0.82568425,\n",
       "        0.82495054, 0.82495054, 0.82495054, 0.82495054, 0.82562315,\n",
       "        0.82576349, 0.82564129, 0.82591051, 0.82591051, 0.82591051,\n",
       "        0.82591051, 0.825605  , 0.82658208, 0.82678311, 0.8268261 ,\n",
       "        0.8268261 , 0.8268261 , 0.8268261 , 0.8268261 , 0.8268261 ,\n",
       "        0.82664309, 0.82537865, 0.82537865, 0.82409337, 0.82523817,\n",
       "        0.8241117 , 0.82621586, 0.82448554, 0.826399  , 0.826399  ,\n",
       "        0.826399  , 0.82493231, 0.82372563, 0.82424053, 0.82462628,\n",
       "        0.82511584, 0.82511584, 0.82511584, 0.82511584, 0.82521997,\n",
       "        0.82525636, 0.82588566, 0.82537865, 0.82537865, 0.82537865,\n",
       "        0.82537865, 0.82499349, 0.82529932, 0.8242159 , 0.82474871,\n",
       "        0.82474871, 0.82474871, 0.82474871, 0.82450383, 0.82529932,\n",
       "        0.82519521, 0.82534229, 0.82534229, 0.82534229, 0.82534229,\n",
       "        0.82534229, 0.82534229, 0.82505467, 0.82511584, 0.82511584,\n",
       "        0.82456506, 0.82529932, 0.82496876, 0.82470576, 0.82550091,\n",
       "        0.82456506, 0.82456506, 0.82456506, 0.8243201 , 0.82499349,\n",
       "        0.8243384 , 0.82572722, 0.82536047, 0.82536047, 0.82536047,\n",
       "        0.82536047, 0.82378694, 0.8246875 , 0.8258313 , 0.82419758,\n",
       "        0.82419758, 0.82419758, 0.82419758, 0.82501171, 0.82680809,\n",
       "        0.82668608, 0.82487111, 0.82487111, 0.82487111, 0.82487111,\n",
       "        0.82425884, 0.82595348, 0.82731383, 0.82615481, 0.82615481,\n",
       "        0.82615481, 0.82615481, 0.82615481, 0.82615481, 0.82507289]),\n",
       " 'split1_test_score': array([0.98976531, 0.98976531, 0.99025358, 0.98924447, 0.98959619,\n",
       "        0.98898096, 0.98963616, 0.98954888, 0.98954888, 0.98954888,\n",
       "        0.99038292, 0.9897644 , 0.98967981, 0.98984906, 0.99003   ,\n",
       "        0.99003   , 0.99003   , 0.99003   , 0.98907104, 0.99034093,\n",
       "        0.98884037, 0.98990166, 0.98990166, 0.98990166, 0.98990166,\n",
       "        0.9902553 , 0.98989988, 0.98971983, 0.98941052, 0.98941052,\n",
       "        0.98941052, 0.98941052, 0.98984906, 0.99082164, 0.98962976,\n",
       "        0.99082164, 0.99082164, 0.99082164, 0.99082164, 0.99082164,\n",
       "        0.99082164, 0.98989453, 0.98972618, 0.98972618, 0.99029726,\n",
       "        0.98964347, 0.9901191 , 0.98977613, 0.98989899, 0.99047703,\n",
       "        0.99047703, 0.99047703, 0.98999603, 0.99077873, 0.98963616,\n",
       "        0.99047535, 0.99012607, 0.99012607, 0.99012607, 0.99012607,\n",
       "        0.99016798, 0.98920657, 0.99064348, 0.98964164, 0.98964164,\n",
       "        0.98964164, 0.98964164, 0.98977523, 0.98989988, 0.99025358,\n",
       "        0.99020732, 0.99020732, 0.99020732, 0.99020732, 0.98999162,\n",
       "        0.99047283, 0.9905115 , 0.9909139 , 0.9909139 , 0.9909139 ,\n",
       "        0.9909139 , 0.9909139 , 0.9909139 , 0.99037613, 0.99056354,\n",
       "        0.99056354, 0.98960261, 0.99074237, 0.99095681, 0.99038801,\n",
       "        0.99100291, 0.9910919 , 0.9910919 , 0.9910919 , 0.99029726,\n",
       "        0.99100529, 0.99034604, 0.99060639, 0.99086859, 0.99086859,\n",
       "        0.99086859, 0.99086859, 0.98977793, 0.99065091, 0.99090347,\n",
       "        0.99047535, 0.99047535, 0.99047535, 0.99047535, 0.9906946 ,\n",
       "        0.9910919 , 0.99165968, 0.9911317 , 0.9911317 , 0.9911317 ,\n",
       "        0.9911317 , 0.99127138, 0.99056521, 0.99073502, 0.9906987 ,\n",
       "        0.9906987 , 0.9906987 , 0.9906987 , 0.9906987 , 0.9906987 ,\n",
       "        0.99095122, 0.99161518, 0.99161518, 0.99064843, 0.99082731,\n",
       "        0.99166336, 0.99157514, 0.9917917 , 0.99082973, 0.99082973,\n",
       "        0.99082973, 0.99091791, 0.99086939, 0.99126753, 0.99104346,\n",
       "        0.99135345, 0.99135345, 0.99135345, 0.99135345, 0.99153066,\n",
       "        0.99095921, 0.99152542, 0.99113483, 0.99113483, 0.99113483,\n",
       "        0.99113483, 0.99074319, 0.99095841, 0.99099656, 0.99113561,\n",
       "        0.99113561, 0.99113561, 0.99113561, 0.99156919, 0.99117777,\n",
       "        0.99135498, 0.99144394, 0.99144394, 0.99144394, 0.99144394,\n",
       "        0.99144394, 0.99144394, 0.99095362, 0.99014518, 0.99014518,\n",
       "        0.99079417, 0.99114654, 0.99123695, 0.99075541, 0.9913212 ,\n",
       "        0.99031605, 0.99031605, 0.99031605, 0.9904007 , 0.99053072,\n",
       "        0.9909315 , 0.99140174, 0.99123695, 0.99123695, 0.99123695,\n",
       "        0.99123695, 0.99048961, 0.99127523, 0.99167291, 0.99106317,\n",
       "        0.99106317, 0.99106317, 0.99106317, 0.9911871 , 0.99092671,\n",
       "        0.99070198, 0.99105924, 0.99105924, 0.99105924, 0.99105924,\n",
       "        0.99052655, 0.99079579, 0.99132426, 0.99127446, 0.99127446,\n",
       "        0.99127446, 0.99127446, 0.99127446, 0.99127446, 0.9917603 ,\n",
       "        0.9915426 , 0.9915426 , 0.99141385, 0.99149892, 0.99079903,\n",
       "        0.99114498, 0.99140628, 0.99088066, 0.99088066, 0.99088066,\n",
       "        0.99075379, 0.99092351, 0.99057684, 0.99113874, 0.99092751,\n",
       "        0.99092751, 0.99092751, 0.99092751, 0.99166997, 0.99105845,\n",
       "        0.99123155, 0.99005369, 0.99005369, 0.99005369, 0.99005369,\n",
       "        0.99075216, 0.99167364, 0.99162331, 0.99097433, 0.99097433,\n",
       "        0.99097433, 0.99097433, 0.99109661, 0.990837  , 0.99158108,\n",
       "        0.99149218, 0.99149218, 0.99149218, 0.99149218, 0.99149218,\n",
       "        0.99149218, 0.99175449, 0.99075541, 0.99075541, 0.99119253,\n",
       "        0.99080065, 0.99132273, 0.99070771, 0.99215237, 0.99093469,\n",
       "        0.99093469, 0.99093469, 0.99136944, 0.99119253, 0.99159072,\n",
       "        0.99192873, 0.99132655, 0.99132655, 0.99132655, 0.99132655,\n",
       "        0.9915426 , 0.99193726, 0.99184411, 0.99110289, 0.99110289,\n",
       "        0.99110289, 0.99110289, 0.99088307, 0.99197955, 0.99215444,\n",
       "        0.99040408, 0.99040408, 0.99040408, 0.99040408, 0.99167291,\n",
       "        0.99185201, 0.99250309, 0.99176103, 0.99176103, 0.99176103,\n",
       "        0.99176103, 0.99176103, 0.99176103, 0.99179966, 0.99132732,\n",
       "        0.99132732, 0.99110524, 0.99111463, 0.99180545, 0.99132426,\n",
       "        0.99180761, 0.99102034, 0.99102034, 0.99102034, 0.99102271,\n",
       "        0.99163217, 0.99163438, 0.99202397, 0.99150042, 0.99150042,\n",
       "        0.99150042, 0.99150042, 0.99145826, 0.99176103, 0.99153887,\n",
       "        0.99207048, 0.99207048, 0.99207048, 0.99207048, 0.99180761,\n",
       "        0.99158776, 0.99096717, 0.99206909, 0.99206909, 0.99206909,\n",
       "        0.99206909, 0.99246729, 0.99250837, 0.99162627, 0.99229109,\n",
       "        0.99229109, 0.99229109, 0.99229109, 0.99229109, 0.99229109,\n",
       "        0.99193228, 0.99059506, 0.99059506, 0.99041505, 0.99024347,\n",
       "        0.99081036, 0.99085312, 0.99088949, 0.99054987, 0.99054987,\n",
       "        0.99054987, 0.99068541, 0.99019651, 0.99036558, 0.99114888,\n",
       "        0.99081117, 0.99081117, 0.99081117, 0.99081117, 0.9904628 ,\n",
       "        0.99023747, 0.99106553, 0.99067886, 0.99067886, 0.99067886,\n",
       "        0.99067886, 0.99063695, 0.99063036, 0.99176175, 0.99111307,\n",
       "        0.99111307, 0.99111307, 0.99111307, 0.99220573, 0.99097354,\n",
       "        0.99207467, 0.99146578, 0.99146578, 0.99146578, 0.99146578,\n",
       "        0.99146578, 0.99146578, 0.99172098, 0.99024605, 0.99024605,\n",
       "        0.99041927, 0.98989722, 0.99067804, 0.99071997, 0.99198309,\n",
       "        0.99037405, 0.99037405, 0.99037405, 0.99050466, 0.9915079 ,\n",
       "        0.99155376, 0.99119718, 0.99112166, 0.99112166, 0.99112166,\n",
       "        0.99112166, 0.99098624, 0.99045944, 0.9910235 , 0.99173118,\n",
       "        0.99173118, 0.99173118, 0.99173118, 0.99080874, 0.99058844,\n",
       "        0.99150341, 0.99159812, 0.99159812, 0.99159812, 0.99159812,\n",
       "        0.99181482, 0.9913319 , 0.99220299, 0.99155004, 0.99155004,\n",
       "        0.99155004, 0.99155004, 0.99155004, 0.99155004, 0.9919845 ,\n",
       "        0.99081601, 0.99081601, 0.99103139, 0.99055485, 0.99111854,\n",
       "        0.99116056, 0.99150192, 0.99011814, 0.99011814, 0.99011814,\n",
       "        0.99060002, 0.99107653, 0.99059175, 0.99194223, 0.99098861,\n",
       "        0.99098861, 0.99098861, 0.99098861, 0.99116367, 0.9912057 ,\n",
       "        0.99229041, 0.9906386 , 0.9906386 , 0.9906386 , 0.9906386 ,\n",
       "        0.99116445, 0.99085393, 0.99106946, 0.99216687, 0.99216687,\n",
       "        0.99216687, 0.99216687, 0.99164468, 0.99181842, 0.99172462,\n",
       "        0.99190283, 0.99190283, 0.99190283, 0.99190283, 0.99190283,\n",
       "        0.99190283, 0.99202959, 0.99038166, 0.99038166, 0.9904695 ,\n",
       "        0.99086196, 0.99129517, 0.99103297, 0.99220779, 0.99046866,\n",
       "        0.99046866, 0.99046866, 0.99077248, 0.991166  , 0.99120802,\n",
       "        0.99172681, 0.99081763, 0.99081763, 0.99081763, 0.99081763,\n",
       "        0.99064107, 0.9911201 , 0.9922972 , 0.99099257, 0.99099257,\n",
       "        0.99099257, 0.99099257, 0.99133799, 0.99094505, 0.99177118,\n",
       "        0.99125159, 0.99125159, 0.99125159, 0.99125159, 0.99164174,\n",
       "        0.99147028, 0.9928216 , 0.99207886, 0.99207886, 0.99207886,\n",
       "        0.99207886, 0.99207886, 0.99207886, 0.99207537, 0.98994865,\n",
       "        0.98994865, 0.98964367, 0.98960025, 0.98916429, 0.99020598,\n",
       "        0.99098386, 0.98981742, 0.98981742, 0.98981742, 0.98947091,\n",
       "        0.98998858, 0.98999034, 0.9908144 , 0.98934164, 0.98934164,\n",
       "        0.98934164, 0.98934164, 0.99025033, 0.98989899, 0.99129211,\n",
       "        0.98986086, 0.98986086, 0.98986086, 0.98986086, 0.98998858,\n",
       "        0.99064189, 0.99107339, 0.99073057, 0.99073057, 0.99073057,\n",
       "        0.99073057, 0.99059919, 0.99046615, 0.99159516, 0.99050967,\n",
       "        0.99050967, 0.99050967, 0.99050967, 0.99050967, 0.99050967,\n",
       "        0.99094028, 0.99047117, 0.99047117, 0.98986353, 0.98990608,\n",
       "        0.98938317, 0.99029638, 0.99124929, 0.98929918, 0.98929918,\n",
       "        0.98929918, 0.98968801, 0.99007902, 0.9902077 , 0.99081521,\n",
       "        0.98968801, 0.98968801, 0.98968801, 0.98968801, 0.98981831,\n",
       "        0.98986086, 0.99160181, 0.98929731, 0.98929731, 0.98929731,\n",
       "        0.98929731, 0.99051467, 0.99107888, 0.99103454, 0.99116445,\n",
       "        0.99116445, 0.99116445, 0.99116445, 0.99007902, 0.99099099,\n",
       "        0.99107496, 0.99099178, 0.99099178, 0.99099178, 0.99099178,\n",
       "        0.99099178, 0.99099178, 0.99199226, 0.98942936, 0.98942936,\n",
       "        0.98903989, 0.9893869 , 0.98972963, 0.99055651, 0.99125313,\n",
       "        0.98921431, 0.98921431, 0.98921431, 0.98921242, 0.99021114,\n",
       "        0.98990608, 0.99112088, 0.98925674, 0.98925674, 0.98925674,\n",
       "        0.98925674, 0.98968891, 0.99025375, 0.99077166, 0.98986353,\n",
       "        0.98986353, 0.98986353, 0.98986353, 0.98986353, 0.9904695 ,\n",
       "        0.99086036, 0.99060002, 0.99060002, 0.99060002, 0.99060002,\n",
       "        0.98994953, 0.99073301, 0.99133876, 0.99138386, 0.99138386,\n",
       "        0.99138386, 0.99138386, 0.99138386, 0.99138386, 0.99203731,\n",
       "        0.98890789, 0.98890789, 0.98912758, 0.99003818, 0.9896039 ,\n",
       "        0.98942843, 0.99051467, 0.98929918, 0.98929918, 0.98929918,\n",
       "        0.98973504, 0.98973414, 0.99003643, 0.99072813, 0.98995041,\n",
       "        0.98995041, 0.98995041, 0.98995041, 0.98951616, 0.9907322 ,\n",
       "        0.99147178, 0.98921242, 0.98921242, 0.98921242, 0.98921242,\n",
       "        0.98968982, 0.99068869, 0.99099099, 0.99047201, 0.99047201,\n",
       "        0.99047201, 0.99047201, 0.99029723, 0.99047117, 0.99238724,\n",
       "        0.99107888, 0.99107888, 0.99107888, 0.99107888, 0.99107888,\n",
       "        0.99107888, 0.99160107, 0.98627502, 0.98627502, 0.9869221 ,\n",
       "        0.9861014 , 0.98623071, 0.9865314 , 0.98808272, 0.98597334,\n",
       "        0.98597334, 0.98597334, 0.98593026, 0.98640318, 0.98687894,\n",
       "        0.98869215, 0.98571491, 0.98571491, 0.98571491, 0.98571491,\n",
       "        0.98657689, 0.98735285, 0.98895125, 0.98657454, 0.98657454,\n",
       "        0.98657454, 0.98657454, 0.98761217, 0.98696413, 0.98864881,\n",
       "        0.98752571, 0.98752571, 0.98752571, 0.98752571, 0.98709367,\n",
       "        0.98834662, 0.9893407 , 0.98856116, 0.98856116, 0.98856116,\n",
       "        0.98856116, 0.98856116, 0.98856116, 0.98981831, 0.98541357,\n",
       "        0.98541357, 0.98588718, 0.98485444, 0.9857998 , 0.9870948 ,\n",
       "        0.98864881, 0.98657571, 0.98657571, 0.98657571, 0.9854123 ,\n",
       "        0.9861014 , 0.98640318, 0.98847553, 0.98631694, 0.98631694,\n",
       "        0.98631694, 0.98631694, 0.98614571, 0.98662003, 0.98873647,\n",
       "        0.98614571, 0.98614571, 0.98614571, 0.98614571, 0.98648944,\n",
       "        0.98687779, 0.98825797, 0.98713686, 0.98713686, 0.98713686,\n",
       "        0.98713686, 0.98687664, 0.98782944, 0.98869115, 0.98826106,\n",
       "        0.98826106, 0.98826106, 0.98826106, 0.98826106, 0.98826106,\n",
       "        0.98942751, 0.98571491, 0.98571491, 0.98627382, 0.98537054,\n",
       "        0.98636125, 0.98584287, 0.9883456 , 0.98640437, 0.98640437,\n",
       "        0.98640437, 0.98541357, 0.98537054, 0.98730964, 0.98847755,\n",
       "        0.9856706 , 0.9856706 , 0.9856706 , 0.9856706 , 0.98575673,\n",
       "        0.98657571, 0.98830435, 0.98653375, 0.98653375, 0.98653375,\n",
       "        0.98653375, 0.9861014 , 0.98627502, 0.98821777, 0.98657689,\n",
       "        0.98657689, 0.98657689, 0.98657689, 0.98653258, 0.98735285,\n",
       "        0.9892558 , 0.98826106, 0.98826106, 0.98826106, 0.98826106,\n",
       "        0.98826106, 0.98826106, 0.98921147, 0.98593026, 0.98593026,\n",
       "        0.98605952, 0.98532623, 0.98571366, 0.98644631, 0.98852086,\n",
       "        0.98511242, 0.98511242, 0.98511242, 0.98494042, 0.98593026,\n",
       "        0.98657571, 0.98769864, 0.98562879, 0.98562879, 0.98562879,\n",
       "        0.98562879, 0.98554269, 0.98597334, 0.9883023 , 0.98545534,\n",
       "        0.98545534, 0.98545534, 0.98545534, 0.98610261, 0.98696527,\n",
       "        0.98821571, 0.98653375, 0.98653375, 0.98653375, 0.98653375,\n",
       "        0.98705049, 0.98683462, 0.98873548, 0.98778512, 0.98778512,\n",
       "        0.98778512, 0.98778512, 0.98778512, 0.98778512, 0.98899654]),\n",
       " 'split2_test_score': array([0.98884922, 0.98884922, 0.98888987, 0.98810258, 0.98758256,\n",
       "        0.98779789, 0.98753249, 0.98797939, 0.98797939, 0.98797939,\n",
       "        0.98824151, 0.98766194, 0.9879688 , 0.9880134 , 0.988284  ,\n",
       "        0.988284  , 0.988284  , 0.988284  , 0.98801551, 0.98814403,\n",
       "        0.98845306, 0.98749229, 0.98749229, 0.98749229, 0.98749229,\n",
       "        0.98827987, 0.98857974, 0.98779574, 0.98832548, 0.98832548,\n",
       "        0.98832548, 0.98832548, 0.98888889, 0.98757381, 0.98766085,\n",
       "        0.98858981, 0.98858981, 0.98858981, 0.98858981, 0.98858981,\n",
       "        0.98858981, 0.9885402 , 0.98810887, 0.98810887, 0.98788493,\n",
       "        0.98832753, 0.98867392, 0.98840848, 0.98796986, 0.98828503,\n",
       "        0.98828503, 0.98828503, 0.98793377, 0.98849967, 0.98898678,\n",
       "        0.98889085, 0.98854424, 0.98854424, 0.98854424, 0.98854424,\n",
       "        0.98762605, 0.98911655, 0.98862735, 0.98831621, 0.98831621,\n",
       "        0.98831621, 0.98831621, 0.98840235, 0.98770438, 0.98915248,\n",
       "        0.9889761 , 0.9889761 , 0.9889761 , 0.9889761 , 0.98841971,\n",
       "        0.98932981, 0.98898096, 0.98832239, 0.98832239, 0.98832239,\n",
       "        0.98832239, 0.98832239, 0.98832239, 0.98884332, 0.98946069,\n",
       "        0.98946069, 0.98981526, 0.98889868, 0.98876206, 0.98902939,\n",
       "        0.98876107, 0.98932981, 0.98932981, 0.98932981, 0.9895071 ,\n",
       "        0.98941799, 0.98911559, 0.98937811, 0.98942265, 0.98942265,\n",
       "        0.98942265, 0.98942265, 0.98928335, 0.98920372, 0.98941799,\n",
       "        0.98915822, 0.98915822, 0.98915822, 0.98915822, 0.98903229,\n",
       "        0.9894644 , 0.98945511, 0.98950895, 0.98950895, 0.98950895,\n",
       "        0.98950895, 0.98955533, 0.98994798, 0.98863436, 0.98959527,\n",
       "        0.98959527, 0.98959527, 0.98959527, 0.98959527, 0.98959527,\n",
       "        0.9891477 , 0.98968072, 0.98968072, 0.98945883, 0.99003615,\n",
       "        0.98981347, 0.98962976, 0.98972437, 0.98955349, 0.98955349,\n",
       "        0.98955349, 0.989907  , 0.98986159, 0.98929091, 0.98963433,\n",
       "        0.99029726, 0.99029726, 0.99029726, 0.99029726, 0.98955073,\n",
       "        0.99034264, 0.98981437, 0.98916109, 0.98916109, 0.98916109,\n",
       "        0.98916109, 0.98924826, 0.98950062, 0.98932981, 0.99047451,\n",
       "        0.99047451, 0.99047451, 0.99047451, 0.989072  , 0.98959986,\n",
       "        0.99007805, 0.99016885, 0.99016885, 0.99016885, 0.99016885,\n",
       "        0.99016885, 0.99016885, 0.9893753 , 0.9894848 , 0.9894848 ,\n",
       "        0.99057352, 0.99031946, 0.99044852, 0.98965259, 0.98991412,\n",
       "        0.99001188, 0.99001188, 0.99001188, 0.98992211, 0.98991589,\n",
       "        0.98992122, 0.99052655, 0.99018097, 0.99018097, 0.99018097,\n",
       "        0.99018097, 0.99071017, 0.99049128, 0.99069952, 0.99057352,\n",
       "        0.99057352, 0.99057352, 0.99057352, 0.98991856, 0.9904007 ,\n",
       "        0.98978604, 0.99084588, 0.99084588, 0.99084588, 0.99084588,\n",
       "        0.99009988, 0.98969889, 0.99061715, 0.99061715, 0.99061715,\n",
       "        0.99061715, 0.99061715, 0.99061715, 0.99061715, 0.99039055,\n",
       "        0.99070935, 0.99070935, 0.99049045, 0.98987765, 0.99097354,\n",
       "        0.99035794, 0.99092591, 0.99088387, 0.99088387, 0.99088387,\n",
       "        0.98975239, 0.99062046, 0.99031008, 0.99035625, 0.99089029,\n",
       "        0.99089029, 0.99089029, 0.99089029, 0.99018356, 0.99110681,\n",
       "        0.99030922, 0.99075297, 0.99075297, 0.99075297, 0.99075297,\n",
       "        0.9910148 , 0.99045189, 0.99061633, 0.99010075, 0.99010075,\n",
       "        0.99010075, 0.99010075, 0.99066491, 0.99035794, 0.99075053,\n",
       "        0.99132579, 0.99132579, 0.99132579, 0.99132579, 0.99132579,\n",
       "        0.99132579, 0.99070771, 0.99088628, 0.99088628, 0.99053572,\n",
       "        0.99032031, 0.99041168, 0.99032031, 0.99092591, 0.99019306,\n",
       "        0.99019306, 0.99019306, 0.99088949, 0.98971067, 0.99097433,\n",
       "        0.99140628, 0.99036812, 0.99036812, 0.99036812, 0.99036812,\n",
       "        0.99089269, 0.99075704, 0.99118943, 0.99097592, 0.99097592,\n",
       "        0.99097592, 0.99097592, 0.99080551, 0.99066984, 0.99075786,\n",
       "        0.99018875, 0.99018875, 0.99018875, 0.99018875, 0.99023661,\n",
       "        0.99049296, 0.99101322, 0.9907118 , 0.9907118 , 0.9907118 ,\n",
       "        0.9907118 , 0.9907118 , 0.9907118 , 0.99092511, 0.99045189,\n",
       "        0.99045189, 0.99132732, 0.99084668, 0.99128444, 0.99197955,\n",
       "        0.99180761, 0.99102587, 0.99102587, 0.99102587, 0.99084668,\n",
       "        0.99075623, 0.9918105 , 0.99198026, 0.99110837, 0.99110837,\n",
       "        0.99110837, 0.99110837, 0.99088949, 0.99084829, 0.99180472,\n",
       "        0.99145901, 0.99145901, 0.99145901, 0.99145901, 0.99172317,\n",
       "        0.99150266, 0.99145299, 0.99159146, 0.99159146, 0.99159146,\n",
       "        0.99159146, 0.99119563, 0.99145751, 0.99119176, 0.99145676,\n",
       "        0.99145676, 0.99145676, 0.99145676, 0.99145676, 0.99145676,\n",
       "        0.9917166 , 0.99058844, 0.99058844, 0.99080874, 0.99016077,\n",
       "        0.99011814, 0.99019909, 0.99136944, 0.99019823, 0.99019823,\n",
       "        0.99019823, 0.99050716, 0.99055236, 0.98980757, 0.99107025,\n",
       "        0.98933134, 0.98933134, 0.98933134, 0.98933134, 0.99055236,\n",
       "        0.9907265 , 0.99093469, 0.99050549, 0.99050549, 0.99050549,\n",
       "        0.99050549, 0.99015817, 0.99050215, 0.99154781, 0.99054904,\n",
       "        0.99054904, 0.99054904, 0.99054904, 0.9899407 , 0.9903732 ,\n",
       "        0.99045357, 0.99063283, 0.99063283, 0.99063283, 0.99063283,\n",
       "        0.99063283, 0.99063283, 0.99163732, 0.98985463, 0.98985463,\n",
       "        0.9906386 , 0.98963549, 0.98998331, 0.99050633, 0.99124312,\n",
       "        0.98916049, 0.98916049, 0.98916049, 0.99033222, 0.99094426,\n",
       "        0.99024947, 0.99124621, 0.99016163, 0.99016163, 0.99016163,\n",
       "        0.99016163, 0.99007117, 0.99120493, 0.99063119, 0.99067968,\n",
       "        0.99067968, 0.99067968, 0.99067968, 0.99028785, 0.99055402,\n",
       "        0.99146427, 0.99046363, 0.99046363, 0.99046363, 0.99046363,\n",
       "        0.98998331, 0.99111697, 0.99107261, 0.99177263, 0.99177263,\n",
       "        0.99177263, 0.99177263, 0.99177263, 0.99177263, 0.99137476,\n",
       "        0.99007466, 0.99007466, 0.99046699, 0.99068296, 0.99024605,\n",
       "        0.99063942, 0.99146653, 0.9909023 , 0.9909023 , 0.9909023 ,\n",
       "        0.99042263, 0.99042432, 0.9901138 , 0.99107104, 0.99055236,\n",
       "        0.99055236, 0.99055236, 0.99055236, 0.99033222, 0.99046447,\n",
       "        0.99181194, 0.99085875, 0.99085875, 0.99085875, 0.99085875,\n",
       "        0.99055402, 0.99085955, 0.99129058, 0.99094665, 0.99094665,\n",
       "        0.99094665, 0.99094665, 0.99055402, 0.99011554, 0.99154855,\n",
       "        0.9908991 , 0.9908991 , 0.9908991 , 0.9908991 , 0.9908991 ,\n",
       "        0.9908991 , 0.992031  , 0.9903825 , 0.9903825 , 0.99059754,\n",
       "        0.99072813, 0.9909902 , 0.99059423, 0.9915959 , 0.99037743,\n",
       "        0.99037743, 0.99037743, 0.99016336, 0.99072813, 0.99050883,\n",
       "        0.99137779, 0.9907741 , 0.9907741 , 0.9907741 , 0.9907741 ,\n",
       "        0.99029126, 0.99068459, 0.99133495, 0.99059671, 0.99059671,\n",
       "        0.99059671, 0.99059671, 0.9909007 , 0.99064024, 0.99216549,\n",
       "        0.99076842, 0.99076842, 0.99076842, 0.99076842, 0.99155599,\n",
       "        0.99107653, 0.99093788, 0.99085634, 0.99085634, 0.99085634,\n",
       "        0.99085634, 0.99085634, 0.99085634, 0.99155524, 0.98908134,\n",
       "        0.98908134, 0.98921053, 0.99011988, 0.98916334, 0.98907559,\n",
       "        0.99098703, 0.98973054, 0.98973054, 0.98973054, 0.98920674,\n",
       "        0.98942379, 0.99003293, 0.99055319, 0.98981831, 0.98981831,\n",
       "        0.98981831, 0.98981831, 0.98946999, 0.99029212, 0.99064024,\n",
       "        0.98964367, 0.98964367, 0.98964367, 0.98964367, 0.98990254,\n",
       "        0.98981473, 0.99046447, 0.99073139, 0.99073139, 0.99073139,\n",
       "        0.99073139, 0.98999122, 0.98990342, 0.99059506, 0.99046699,\n",
       "        0.99046699, 0.99046699, 0.99046699, 0.99046699, 0.99046699,\n",
       "        0.99085714, 0.98921053, 0.98921053, 0.98838687, 0.98916809,\n",
       "        0.98925203, 0.98807854, 0.99086036, 0.98864881, 0.98864881,\n",
       "        0.98864881, 0.98942751, 0.98968891, 0.98916714, 0.99077166,\n",
       "        0.98964458, 0.98964458, 0.98964458, 0.98964458, 0.98903413,\n",
       "        0.98968801, 0.99077248, 0.98995129, 0.98995129, 0.98995129,\n",
       "        0.98995129, 0.98886258, 0.98972783, 0.99107575, 0.99025204,\n",
       "        0.99025204, 0.99025204, 0.99025204, 0.98964276, 0.98908038,\n",
       "        0.99050633, 0.99094585, 0.99094585, 0.99094585, 0.99094585,\n",
       "        0.99094585, 0.99094585, 0.99125082, 0.9892558 , 0.9892558 ,\n",
       "        0.98934164, 0.98912662, 0.98947184, 0.98929449, 0.99081682,\n",
       "        0.98864782, 0.98864782, 0.98864782, 0.98964731, 0.98960025,\n",
       "        0.98903605, 0.99063942, 0.98908134, 0.98908134, 0.98908134,\n",
       "        0.98908134, 0.98899268, 0.98929543, 0.99033732, 0.98908038,\n",
       "        0.98908038, 0.98908038, 0.98908038, 0.98860549, 0.99003468,\n",
       "        0.9904695 , 0.98908038, 0.98908038, 0.98908038, 0.98908038,\n",
       "        0.98955591, 0.98951248, 0.99068459, 0.99021114, 0.99021114,\n",
       "        0.99021114, 0.99021114, 0.99021114, 0.99021114, 0.99129594,\n",
       "        0.98930106, 0.98930106, 0.98903893, 0.98860349, 0.98977756,\n",
       "        0.98964367, 0.99094585, 0.98782624, 0.98782624, 0.98782624,\n",
       "        0.98908134, 0.98873252, 0.98942658, 0.99055485, 0.98890886,\n",
       "        0.98890886, 0.98890886, 0.98890886, 0.98921336, 0.98916619,\n",
       "        0.99072894, 0.9893841 , 0.9893841 , 0.9893841 , 0.9893841 ,\n",
       "        0.98903797, 0.99016336, 0.99037997, 0.9888202 , 0.9888202 ,\n",
       "        0.9888202 , 0.9888202 , 0.9893407 , 0.98972963, 0.99068623,\n",
       "        0.98951156, 0.98951156, 0.98951156, 0.98951156, 0.98951156,\n",
       "        0.98951156, 0.99055236, 0.98558574, 0.98558574, 0.98498341,\n",
       "        0.98515543, 0.98519845, 0.98537054, 0.98782837, 0.98485311,\n",
       "        0.98485311, 0.98485311, 0.98451067, 0.98506941, 0.98588595,\n",
       "        0.98730964, 0.9849391 , 0.9849391 , 0.9849391 , 0.9849391 ,\n",
       "        0.98468252, 0.98705049, 0.9878695 , 0.98463955, 0.98463955,\n",
       "        0.98463955, 0.98463955, 0.98549965, 0.98623192, 0.98787162,\n",
       "        0.98545534, 0.98545534, 0.98545534, 0.98545534, 0.98567185,\n",
       "        0.98627502, 0.98787056, 0.98800245, 0.98800245, 0.98800245,\n",
       "        0.98800245, 0.98800245, 0.98800245, 0.98825695, 0.98442476,\n",
       "        0.98442476, 0.98494042, 0.98421007, 0.98425163, 0.9852832 ,\n",
       "        0.98700617, 0.98459659, 0.98459659, 0.98459659, 0.98463955,\n",
       "        0.98429593, 0.98584287, 0.98696185, 0.98451067, 0.98451067,\n",
       "        0.98451067, 0.98451067, 0.98451067, 0.98481145, 0.98670399,\n",
       "        0.98472416, 0.98472416, 0.98472416, 0.98472416, 0.98532751,\n",
       "        0.98593026, 0.98704709, 0.98536926, 0.98536926, 0.98536926,\n",
       "        0.98536926, 0.98571366, 0.98636125, 0.98773866, 0.98696413,\n",
       "        0.98696413, 0.98696413, 0.98696413, 0.98696413, 0.98696413,\n",
       "        0.98839094, 0.98476847, 0.98476847, 0.98519845, 0.98339508,\n",
       "        0.98390825, 0.98515543, 0.98592903, 0.98502641, 0.98502641,\n",
       "        0.98502641, 0.98494042, 0.98390965, 0.98455228, 0.98730742,\n",
       "        0.98519845, 0.98519845, 0.98519845, 0.98519845, 0.98429593,\n",
       "        0.98459524, 0.98713798, 0.98502641, 0.98502641, 0.98502641,\n",
       "        0.98502641, 0.98395256, 0.98584411, 0.98730742, 0.98545661,\n",
       "        0.98545661, 0.98545661, 0.98545661, 0.98502641, 0.9850251 ,\n",
       "        0.98752681, 0.98674831, 0.98674831, 0.98674831, 0.98674831,\n",
       "        0.98674831, 0.98674831, 0.98787162, 0.98455363, 0.98455363,\n",
       "        0.98506941, 0.98373807, 0.98403838, 0.98549965, 0.98679262,\n",
       "        0.98433887, 0.98433887, 0.98433887, 0.98360942, 0.98378096,\n",
       "        0.98429593, 0.98722324, 0.98476847, 0.98476847, 0.98476847,\n",
       "        0.98476847, 0.98459659, 0.98399546, 0.98713461, 0.98442476,\n",
       "        0.98442476, 0.98442476, 0.98442476, 0.9850251 , 0.98506941,\n",
       "        0.98674946, 0.98502641, 0.98502641, 0.98502641, 0.98502641,\n",
       "        0.98451067, 0.98536926, 0.98653258, 0.98597334, 0.98597334,\n",
       "        0.98597334, 0.98597334, 0.98597334, 0.98597334, 0.98782944]),\n",
       " 'mean_test_score': array([0.9342707 , 0.9342707 , 0.9342202 , 0.93411351, 0.93457863,\n",
       "        0.93436999, 0.93322845, 0.93412489, 0.93412489, 0.93412489,\n",
       "        0.93432704, 0.93407052, 0.93354602, 0.93410168, 0.93459892,\n",
       "        0.93459892, 0.93459892, 0.93459892, 0.93408785, 0.93485354,\n",
       "        0.93352377, 0.9336309 , 0.9336309 , 0.9336309 , 0.9336309 ,\n",
       "        0.93450348, 0.93443593, 0.933651  , 0.93302812, 0.93302812,\n",
       "        0.93302812, 0.93302812, 0.93368393, 0.93440787, 0.93300273,\n",
       "        0.93439946, 0.93439946, 0.93439946, 0.93439946, 0.93439946,\n",
       "        0.93439946, 0.93321377, 0.93441889, 0.93441889, 0.93412659,\n",
       "        0.93449064, 0.93465668, 0.93500357, 0.93486366, 0.93427292,\n",
       "        0.93427292, 0.93427292, 0.93495929, 0.93512405, 0.93462644,\n",
       "        0.93445999, 0.9350231 , 0.9350231 , 0.9350231 , 0.9350231 ,\n",
       "        0.93428897, 0.93502941, 0.93434034, 0.9341804 , 0.9341804 ,\n",
       "        0.9341804 , 0.9341804 , 0.93418631, 0.93440308, 0.9349018 ,\n",
       "        0.93504564, 0.93504564, 0.93504564, 0.93504564, 0.93521306,\n",
       "        0.93602429, 0.93514865, 0.93492672, 0.93492672, 0.93492672,\n",
       "        0.93492672, 0.93492672, 0.93492672, 0.93451318, 0.93443404,\n",
       "        0.93443404, 0.93377522, 0.93491897, 0.9347409 , 0.9348648 ,\n",
       "        0.93535299, 0.93445808, 0.93445808, 0.93445808, 0.93476939,\n",
       "        0.93456706, 0.93521753, 0.93490284, 0.93418933, 0.93418933,\n",
       "        0.93418933, 0.93418933, 0.93437878, 0.93457374, 0.93460674,\n",
       "        0.93474719, 0.93474719, 0.93474719, 0.93474719, 0.93443716,\n",
       "        0.93536673, 0.93528783, 0.93461906, 0.93461906, 0.93461906,\n",
       "        0.93461906, 0.93463401, 0.93452134, 0.93458358, 0.93447689,\n",
       "        0.93447689, 0.93447689, 0.93447689, 0.93447689, 0.93447689,\n",
       "        0.9346225 , 0.93589228, 0.93589228, 0.93488468, 0.9348569 ,\n",
       "        0.93593224, 0.93507289, 0.93476146, 0.93507046, 0.93507046,\n",
       "        0.93507046, 0.9355317 , 0.93568363, 0.93522476, 0.93542155,\n",
       "        0.93527666, 0.93527666, 0.93527666, 0.93527666, 0.93480073,\n",
       "        0.93579853, 0.93599429, 0.93526561, 0.93526561, 0.93526561,\n",
       "        0.93526561, 0.93513163, 0.93510397, 0.93492908, 0.93622072,\n",
       "        0.93622072, 0.93622072, 0.93622072, 0.93514429, 0.93563812,\n",
       "        0.93485658, 0.93522317, 0.93522317, 0.93522317, 0.93522317,\n",
       "        0.93522317, 0.93522317, 0.9355089 , 0.93570289, 0.93570289,\n",
       "        0.93554961, 0.93592033, 0.93586533, 0.93534372, 0.93563381,\n",
       "        0.93511321, 0.93511321, 0.93511321, 0.93622391, 0.93589385,\n",
       "        0.9354044 , 0.93565274, 0.93594499, 0.93594499, 0.93594499,\n",
       "        0.93594499, 0.93604928, 0.93549076, 0.93659673, 0.93634313,\n",
       "        0.93634313, 0.93634313, 0.93634313, 0.93613983, 0.93564414,\n",
       "        0.93464385, 0.93581633, 0.93581633, 0.93581633, 0.93581633,\n",
       "        0.93515761, 0.93559656, 0.93593028, 0.93591368, 0.93591368,\n",
       "        0.93591368, 0.93591368, 0.93591368, 0.93591368, 0.93600009,\n",
       "        0.93602551, 0.93602551, 0.93565299, 0.93545061, 0.93571101,\n",
       "        0.93568832, 0.93640043, 0.93654219, 0.93654219, 0.93654219,\n",
       "        0.93598062, 0.93577743, 0.93544223, 0.93555126, 0.93644411,\n",
       "        0.93644411, 0.93644411, 0.93644411, 0.93577876, 0.93579508,\n",
       "        0.93557866, 0.93559275, 0.93559275, 0.93559275, 0.93559275,\n",
       "        0.93636624, 0.93621553, 0.93633491, 0.93620252, 0.93620252,\n",
       "        0.93620252, 0.93620252, 0.93669753, 0.93575687, 0.93607467,\n",
       "        0.93693988, 0.93693988, 0.93693988, 0.93693988, 0.93693988,\n",
       "        0.93693988, 0.93700379, 0.93490567, 0.93490567, 0.9365301 ,\n",
       "        0.93571184, 0.93573905, 0.9355994 , 0.93507735, 0.93573447,\n",
       "        0.93573447, 0.93573447, 0.93566921, 0.93564529, 0.93647805,\n",
       "        0.93570119, 0.93610658, 0.93610658, 0.93610658, 0.93610658,\n",
       "        0.93648144, 0.93563063, 0.93579886, 0.93556836, 0.93556836,\n",
       "        0.93556836, 0.93556836, 0.93523411, 0.93573815, 0.93553985,\n",
       "        0.93561722, 0.93561722, 0.93561722, 0.93561722, 0.93583817,\n",
       "        0.93565099, 0.93584335, 0.93557722, 0.93557722, 0.93557722,\n",
       "        0.93557722, 0.93557722, 0.93557722, 0.9355039 , 0.93595765,\n",
       "        0.93595765, 0.93629151, 0.9368917 , 0.93674029, 0.93630899,\n",
       "        0.93705759, 0.93553709, 0.93553709, 0.93553709, 0.93543733,\n",
       "        0.93614036, 0.93620729, 0.93682142, 0.93676272, 0.93676272,\n",
       "        0.93676272, 0.93676272, 0.9364989 , 0.93726976, 0.93582053,\n",
       "        0.93675054, 0.93675054, 0.93675054, 0.93675054, 0.93668996,\n",
       "        0.93684802, 0.93600839, 0.93650936, 0.93650936, 0.93650936,\n",
       "        0.93650936, 0.93695162, 0.9364972 , 0.93630392, 0.93636338,\n",
       "        0.93636338, 0.93636338, 0.93636338, 0.93636338, 0.93636338,\n",
       "        0.93629569, 0.93604985, 0.93604985, 0.93566243, 0.93614125,\n",
       "        0.93590988, 0.93604074, 0.93589957, 0.93506966, 0.93506966,\n",
       "        0.93506966, 0.93570707, 0.93596594, 0.93529185, 0.93592706,\n",
       "        0.93653436, 0.93653436, 0.93653436, 0.93653436, 0.935709  ,\n",
       "        0.9348025 , 0.9354319 , 0.93510689, 0.93510689, 0.93510689,\n",
       "        0.93510689, 0.93550745, 0.9356546 , 0.93687446, 0.93553147,\n",
       "        0.93553147, 0.93553147, 0.93553147, 0.93531112, 0.93583988,\n",
       "        0.93554054, 0.93635489, 0.93635489, 0.93635489, 0.93635489,\n",
       "        0.93635489, 0.93635489, 0.93630678, 0.93629175, 0.93629175,\n",
       "        0.93555429, 0.93511305, 0.93544853, 0.93707768, 0.93692792,\n",
       "        0.93565674, 0.93565674, 0.93565674, 0.93600362, 0.93665557,\n",
       "        0.93593098, 0.935955  , 0.93617872, 0.93617872, 0.93617872,\n",
       "        0.93617872, 0.93562129, 0.93620415, 0.93634315, 0.93629631,\n",
       "        0.93629631, 0.93629631, 0.93629631, 0.93615712, 0.93622498,\n",
       "        0.9365776 , 0.9366126 , 0.9366126 , 0.9366126 , 0.9366126 ,\n",
       "        0.93626072, 0.93696475, 0.9371008 , 0.93710215, 0.93710215,\n",
       "        0.93710215, 0.93710215, 0.93710215, 0.93710215, 0.93663279,\n",
       "        0.93545781, 0.93545781, 0.93595147, 0.93589928, 0.9358805 ,\n",
       "        0.93601961, 0.93680138, 0.93578011, 0.93578011, 0.93578011,\n",
       "        0.93534479, 0.935443  , 0.93533496, 0.93643006, 0.9359393 ,\n",
       "        0.9359393 , 0.9359393 , 0.9359393 , 0.93649323, 0.9360434 ,\n",
       "        0.93659553, 0.93580866, 0.93580866, 0.93580866, 0.93580866,\n",
       "        0.93592308, 0.93568526, 0.93581922, 0.93623345, 0.93623345,\n",
       "        0.93623345, 0.93623345, 0.93605073, 0.93630834, 0.9362784 ,\n",
       "        0.93599298, 0.93599298, 0.93599298, 0.93599298, 0.93599298,\n",
       "        0.93599298, 0.93659594, 0.93553786, 0.93553786, 0.93580167,\n",
       "        0.93661172, 0.93629516, 0.93586023, 0.93755228, 0.93559986,\n",
       "        0.93559986, 0.93559986, 0.9359613 , 0.93659135, 0.93591047,\n",
       "        0.93647483, 0.9361536 , 0.9361536 , 0.9361536 , 0.9361536 ,\n",
       "        0.93567536, 0.93664269, 0.93645312, 0.93613246, 0.93613246,\n",
       "        0.93613246, 0.93613246, 0.93598864, 0.93580553, 0.93643238,\n",
       "        0.93659272, 0.93659272, 0.93659272, 0.93659272, 0.93661361,\n",
       "        0.93588755, 0.93741595, 0.93634298, 0.93634298, 0.93634298,\n",
       "        0.93634298, 0.93634298, 0.93634298, 0.93683923, 0.93567722,\n",
       "        0.93567722, 0.93532839, 0.93545441, 0.9350859 , 0.93555809,\n",
       "        0.93604793, 0.93559193, 0.93559193, 0.93559193, 0.93551323,\n",
       "        0.93559571, 0.93633265, 0.93591389, 0.93570862, 0.93570862,\n",
       "        0.93570862, 0.93570862, 0.93522235, 0.93640885, 0.93653127,\n",
       "        0.93554517, 0.93554517, 0.93554517, 0.93554517, 0.9353607 ,\n",
       "        0.93581356, 0.93603998, 0.93619764, 0.93619764, 0.93619764,\n",
       "        0.93619764, 0.9363858 , 0.93551415, 0.9359642 , 0.9359056 ,\n",
       "        0.9359056 , 0.9359056 , 0.9359056 , 0.9359056 , 0.9359056 ,\n",
       "        0.93627482, 0.93462643, 0.93462643, 0.93489746, 0.93518409,\n",
       "        0.93515377, 0.93504667, 0.93679085, 0.93563498, 0.93563498,\n",
       "        0.93563498, 0.93517752, 0.93591724, 0.93528431, 0.93645431,\n",
       "        0.93554282, 0.93554282, 0.93554282, 0.93554282, 0.93589001,\n",
       "        0.93605295, 0.93684094, 0.93552081, 0.93552081, 0.93552081,\n",
       "        0.93552081, 0.93549675, 0.93632437, 0.93646038, 0.93634498,\n",
       "        0.93634498, 0.93634498, 0.93634498, 0.93566421, 0.93579507,\n",
       "        0.93622908, 0.93604287, 0.93604287, 0.93604287, 0.93604287,\n",
       "        0.93604287, 0.93604287, 0.93669573, 0.93561718, 0.93561718,\n",
       "        0.93502254, 0.93555997, 0.93574871, 0.93566066, 0.93609527,\n",
       "        0.93513392, 0.93513392, 0.93513392, 0.93516761, 0.93551117,\n",
       "        0.93543299, 0.93613446, 0.9352639 , 0.9352639 , 0.9352639 ,\n",
       "        0.9352639 , 0.93546798, 0.93587057, 0.93561207, 0.93529733,\n",
       "        0.93529733, 0.93529733, 0.93529733, 0.93515935, 0.93603491,\n",
       "        0.93611297, 0.93580689, 0.93580689, 0.93580689, 0.93580689,\n",
       "        0.93551916, 0.93579216, 0.93627482, 0.93632923, 0.93632923,\n",
       "        0.93632923, 0.93632923, 0.93632923, 0.93632923, 0.93646963,\n",
       "        0.9348226 , 0.9348226 , 0.93495687, 0.93508891, 0.93596501,\n",
       "        0.93576645, 0.93603454, 0.93422915, 0.93422915, 0.93422915,\n",
       "        0.9351795 , 0.93523985, 0.93626148, 0.93569648, 0.93512678,\n",
       "        0.93512678, 0.93512678, 0.93512678, 0.93556515, 0.93557483,\n",
       "        0.93590054, 0.93505352, 0.93505352, 0.93505352, 0.93505352,\n",
       "        0.93534721, 0.93558148, 0.93529769, 0.93573838, 0.93573838,\n",
       "        0.93573838, 0.93573838, 0.93550834, 0.93633947, 0.93691164,\n",
       "        0.93590115, 0.93590115, 0.93590115, 0.93590115, 0.93590115,\n",
       "        0.93590115, 0.93652971, 0.93248859, 0.93248859, 0.93236691,\n",
       "        0.93213029, 0.93226927, 0.93281368, 0.93464354, 0.93190527,\n",
       "        0.93190527, 0.93190527, 0.93161353, 0.93226943, 0.9326473 ,\n",
       "        0.93385461, 0.93171106, 0.93171106, 0.93171106, 0.93171106,\n",
       "        0.93261984, 0.93332179, 0.93410116, 0.93242765, 0.93242765,\n",
       "        0.93242765, 0.93242765, 0.93270784, 0.93342202, 0.93453015,\n",
       "        0.93231117, 0.93231117, 0.93231117, 0.93231117, 0.93261887,\n",
       "        0.93340061, 0.93448174, 0.93434723, 0.93434723, 0.93434723,\n",
       "        0.93434723, 0.93434723, 0.93434723, 0.93442349, 0.93179407,\n",
       "        0.93179407, 0.93164032, 0.93160329, 0.93199335, 0.93307403,\n",
       "        0.93430262, 0.93211644, 0.93211644, 0.93211644, 0.93168786,\n",
       "        0.9322044 , 0.93259664, 0.93370116, 0.93220531, 0.93220531,\n",
       "        0.93220531, 0.93220531, 0.93206675, 0.93194371, 0.93370824,\n",
       "        0.93194014, 0.93194014, 0.93194014, 0.93194014, 0.93248003,\n",
       "        0.93285718, 0.93364878, 0.93280554, 0.93280554, 0.93280554,\n",
       "        0.93280554, 0.93273177, 0.93359092, 0.93440431, 0.9340171 ,\n",
       "        0.9340171 , 0.9340171 , 0.9340171 , 0.9340171 , 0.9340171 ,\n",
       "        0.93482051, 0.93195401, 0.93195401, 0.93185521, 0.93133459,\n",
       "        0.9314604 , 0.93240472, 0.93292006, 0.93260993, 0.93260993,\n",
       "        0.93260993, 0.9317621 , 0.93100194, 0.93203415, 0.93347042,\n",
       "        0.93199496, 0.93199496, 0.93199496, 0.93199496, 0.93175754,\n",
       "        0.93214244, 0.933776  , 0.93231294, 0.93231294, 0.93231294,\n",
       "        0.93231294, 0.93168248, 0.93247282, 0.93324703, 0.93226074,\n",
       "        0.93226074, 0.93226074, 0.93226074, 0.93202094, 0.93255909,\n",
       "        0.93399261, 0.93345055, 0.93345055, 0.93345055, 0.93345055,\n",
       "        0.93345055, 0.93345055, 0.93404592, 0.93186658, 0.93186658,\n",
       "        0.931898  , 0.93145454, 0.9315736 , 0.93221724, 0.93360479,\n",
       "        0.93133878, 0.93133878, 0.93133878, 0.93095664, 0.93156824,\n",
       "        0.93173668, 0.9335497 , 0.93191925, 0.93191925, 0.93191925,\n",
       "        0.93191925, 0.93130874, 0.9315521 , 0.93375607, 0.93135923,\n",
       "        0.93135923, 0.93135923, 0.93135923, 0.93204648, 0.93294759,\n",
       "        0.93388375, 0.93214376, 0.93214376, 0.93214376, 0.93214376,\n",
       "        0.93194   , 0.93271912, 0.93419396, 0.93330442, 0.93330442,\n",
       "        0.93330442, 0.93330442, 0.93330442, 0.93330442, 0.93396629]),\n",
       " 'std_test_score': array([0.07783435, 0.07783435, 0.07828086, 0.07716092, 0.07638715,\n",
       "        0.07639655, 0.07828974, 0.07727422, 0.07727422, 0.07727422,\n",
       "        0.07776569, 0.07728115, 0.07817841, 0.07754431, 0.07716008,\n",
       "        0.07716008, 0.07716008, 0.07716008, 0.0770128 , 0.07692281,\n",
       "        0.07795577, 0.0778814 , 0.0778814 , 0.0778814 , 0.0778814 ,\n",
       "        0.07745234, 0.07750627, 0.07793673, 0.07897075, 0.07897075,\n",
       "        0.07897075, 0.07897075, 0.07875152, 0.0774959 , 0.0786946 ,\n",
       "        0.07822017, 0.07822017, 0.07822017, 0.07822017, 0.07822017,\n",
       "        0.07822017, 0.07920297, 0.07707554, 0.07707554, 0.07773778,\n",
       "        0.07706925, 0.07741606, 0.07649506, 0.07647167, 0.07793977,\n",
       "        0.07793977, 0.07793977, 0.07638011, 0.07710168, 0.07733677,\n",
       "        0.07809996, 0.07681155, 0.07681155, 0.07681155, 0.07681155,\n",
       "        0.07723441, 0.07655443, 0.07820337, 0.07749872, 0.07749872,\n",
       "        0.07749872, 0.07749872, 0.07764585, 0.07693709, 0.07750196,\n",
       "        0.07714144, 0.07714144, 0.07714144, 0.07714144, 0.07635977,\n",
       "        0.07619505, 0.07721517, 0.07735259, 0.07735259, 0.07735259,\n",
       "        0.07735259, 0.07735259, 0.07735259, 0.07792079, 0.07860056,\n",
       "        0.07860056, 0.07910226, 0.07764618, 0.07795453, 0.07756296,\n",
       "        0.07712108, 0.07884961, 0.07884961, 0.07884961, 0.0779702 ,\n",
       "        0.07869599, 0.07709506, 0.07790981, 0.07913635, 0.07913635,\n",
       "        0.07913635, 0.07913635, 0.07799678, 0.078284  , 0.07856755,\n",
       "        0.07788202, 0.07788202, 0.07788202, 0.07788202, 0.07838753,\n",
       "        0.07765933, 0.07816814, 0.07877627, 0.07877627, 0.07877627,\n",
       "        0.07877627, 0.07888702, 0.07882195, 0.07792946, 0.07873069,\n",
       "        0.07873069, 0.07873069, 0.07873069, 0.07873069, 0.07873069,\n",
       "        0.07838902, 0.07744024, 0.07744024, 0.07802219, 0.07859533,\n",
       "        0.07751131, 0.07853468, 0.07919562, 0.07795482, 0.07795482,\n",
       "        0.07795482, 0.07761421, 0.07733293, 0.07786294, 0.07766699,\n",
       "        0.07855891, 0.07855891, 0.07855891, 0.07855891, 0.07883235,\n",
       "        0.07757341, 0.07732613, 0.07761954, 0.07761954, 0.07761954,\n",
       "        0.07761954, 0.07759195, 0.07796157, 0.07811578, 0.07719439,\n",
       "        0.07719439, 0.07719439, 0.07719439, 0.07803774, 0.07743186,\n",
       "        0.0789996 , 0.07860828, 0.07860828, 0.07860828, 0.07860828,\n",
       "        0.07860828, 0.07860828, 0.07729732, 0.07652654, 0.07652654,\n",
       "        0.07797164, 0.07751756, 0.07775046, 0.07758547, 0.07776103,\n",
       "        0.07785362, 0.07785362, 0.07785362, 0.07627939, 0.07683387,\n",
       "        0.0778139 , 0.07822295, 0.07744915, 0.07744915, 0.07744915,\n",
       "        0.07744915, 0.07714626, 0.07833748, 0.07720221, 0.07703985,\n",
       "        0.07703985, 0.07703985, 0.07703985, 0.07695334, 0.07780972,\n",
       "        0.07863139, 0.07797445, 0.07797445, 0.07797445, 0.07797445,\n",
       "        0.078002  , 0.07728918, 0.07783946, 0.07782765, 0.07782765,\n",
       "        0.07782765, 0.07782765, 0.07782765, 0.07782765, 0.07789029,\n",
       "        0.07792457, 0.07792457, 0.07820573, 0.07812067, 0.07802965,\n",
       "        0.07787171, 0.0774506 , 0.07684847, 0.07684847, 0.07684847,\n",
       "        0.07675394, 0.07777414, 0.07778355, 0.07805991, 0.07702484,\n",
       "        0.07702484, 0.07702484, 0.07702484, 0.07799342, 0.07818841,\n",
       "        0.07805379, 0.07751439, 0.07751439, 0.07751439, 0.07751439,\n",
       "        0.07709909, 0.07756731, 0.07747865, 0.07684216, 0.07684216,\n",
       "        0.07684216, 0.07684216, 0.07662686, 0.07755658, 0.07791137,\n",
       "        0.07703098, 0.07703098, 0.07703098, 0.07703098, 0.07703098,\n",
       "        0.07703098, 0.07669018, 0.07907602, 0.07907602, 0.07684039,\n",
       "        0.07756793, 0.07796387, 0.07766114, 0.07985059, 0.07754109,\n",
       "        0.07754109, 0.07754109, 0.07843288, 0.07751019, 0.07750565,\n",
       "        0.0791486 , 0.07741611, 0.07741611, 0.07741611, 0.07741611,\n",
       "        0.07740913, 0.07879654, 0.07879747, 0.07844792, 0.07844792,\n",
       "        0.07844792, 0.07844792, 0.07864467, 0.07861306, 0.07907964,\n",
       "        0.0773281 , 0.0773281 , 0.0773281 , 0.0773281 , 0.07794883,\n",
       "        0.07852121, 0.0790778 , 0.07871515, 0.07871515, 0.07871515,\n",
       "        0.07871515, 0.07871515, 0.07871515, 0.07899663, 0.07768634,\n",
       "        0.07768634, 0.0776754 , 0.07649341, 0.07750578, 0.07826717,\n",
       "        0.07742823, 0.07846907, 0.07846907, 0.07846907, 0.07848516,\n",
       "        0.07785871, 0.0785103 , 0.07803729, 0.07713375, 0.07713375,\n",
       "        0.07713375, 0.07713375, 0.07732244, 0.0764178 , 0.0789857 ,\n",
       "        0.07780224, 0.07780224, 0.07780224, 0.07780224, 0.07788843,\n",
       "        0.07735352, 0.07806724, 0.07823583, 0.07823583, 0.07823583,\n",
       "        0.07823583, 0.07761355, 0.07846986, 0.07793057, 0.0785045 ,\n",
       "        0.0785045 , 0.0785045 , 0.0785045 , 0.0785045 , 0.0785045 ,\n",
       "        0.07852957, 0.07713389, 0.07713389, 0.07771045, 0.07645362,\n",
       "        0.07715206, 0.0770544 , 0.07810711, 0.07821235, 0.07821235,\n",
       "        0.07821235, 0.07762512, 0.07694537, 0.07749178, 0.07803986,\n",
       "        0.07571501, 0.07571501, 0.07571501, 0.07571501, 0.07749691,\n",
       "        0.07874294, 0.07858534, 0.07846808, 0.07846808, 0.07846808,\n",
       "        0.07846808, 0.07762659, 0.07765682, 0.07747112, 0.07820576,\n",
       "        0.07820576, 0.07820576, 0.07820576, 0.07886493, 0.07754666,\n",
       "        0.07880783, 0.07735033, 0.07735033, 0.07735033, 0.07735033,\n",
       "        0.07735033, 0.07735033, 0.07830837, 0.07602628, 0.07602628,\n",
       "        0.07774594, 0.07729151, 0.07761558, 0.07571064, 0.07733712,\n",
       "        0.07652544, 0.07652544, 0.07652544, 0.07695421, 0.0771747 ,\n",
       "        0.07774205, 0.07815891, 0.0770232 , 0.0770232 , 0.0770232 ,\n",
       "        0.0770232 , 0.07765171, 0.07725631, 0.07705245, 0.0776544 ,\n",
       "        0.0776544 , 0.0776544 , 0.0776544 , 0.07692103, 0.07685721,\n",
       "        0.07764916, 0.07696046, 0.07696046, 0.07696046, 0.07696046,\n",
       "        0.0772739 , 0.07673484, 0.07712834, 0.07715838, 0.07715838,\n",
       "        0.07715838, 0.07715838, 0.07715838, 0.07715838, 0.07784839,\n",
       "        0.0777647 , 0.0777647 , 0.07749602, 0.07738525, 0.07750226,\n",
       "        0.07761287, 0.07733322, 0.07740072, 0.07740072, 0.07740072,\n",
       "        0.0780173 , 0.07821696, 0.07780719, 0.07789085, 0.07754322,\n",
       "        0.07754322, 0.07754322, 0.07754322, 0.07672851, 0.07748773,\n",
       "        0.07842636, 0.07769697, 0.07769697, 0.07769697, 0.07769697,\n",
       "        0.07769185, 0.07802426, 0.07829204, 0.07824056, 0.07824056,\n",
       "        0.07824056, 0.07824056, 0.07785178, 0.07730212, 0.07828833,\n",
       "        0.0783598 , 0.0783598 , 0.0783598 , 0.0783598 , 0.0783598 ,\n",
       "        0.0783598 , 0.07839602, 0.07756144, 0.07756144, 0.07740255,\n",
       "        0.07662681, 0.07756621, 0.07771601, 0.0768623 , 0.0775317 ,\n",
       "        0.0775317 , 0.0775317 , 0.0770844 , 0.0768708 , 0.07770866,\n",
       "        0.07789143, 0.07727583, 0.07727583, 0.07727583, 0.07727583,\n",
       "        0.07748603, 0.07673495, 0.07829602, 0.07730417, 0.07730417,\n",
       "        0.07730417, 0.07730417, 0.0779668 , 0.07776363, 0.07853987,\n",
       "        0.07695791, 0.07695791, 0.07695791, 0.07695791, 0.0777609 ,\n",
       "        0.07832759, 0.07702727, 0.07795958, 0.07795958, 0.07795958,\n",
       "        0.07795958, 0.07795958, 0.07795958, 0.0777482 , 0.07613894,\n",
       "        0.07613894, 0.07650733, 0.07694151, 0.07647772, 0.07648587,\n",
       "        0.07769338, 0.07662499, 0.07662499, 0.07662499, 0.07612096,\n",
       "        0.07652411, 0.07591355, 0.07745641, 0.07618584, 0.07618584,\n",
       "        0.07618584, 0.07618584, 0.07727019, 0.07592464, 0.07698304,\n",
       "        0.07666046, 0.07666046, 0.07666046, 0.07666046, 0.07719466,\n",
       "        0.07695483, 0.07739882, 0.07712178, 0.07712178, 0.07712178,\n",
       "        0.07712178, 0.07623982, 0.07731629, 0.07796794, 0.07719164,\n",
       "        0.07719164, 0.07719164, 0.07719164, 0.07719164, 0.07719164,\n",
       "        0.07724986, 0.07808668, 0.07808668, 0.07669197, 0.07686734,\n",
       "        0.07659925, 0.07657199, 0.07674101, 0.07543324, 0.07543324,\n",
       "        0.07543324, 0.07690534, 0.07632064, 0.07693879, 0.07684714,\n",
       "        0.07654215, 0.07654215, 0.07654215, 0.07654215, 0.0757123 ,\n",
       "        0.07597368, 0.07685788, 0.07651436, 0.07651436, 0.07651436,\n",
       "        0.07651436, 0.07664185, 0.07648123, 0.07720866, 0.07688217,\n",
       "        0.07688217, 0.07688217, 0.07688217, 0.07664589, 0.07671179,\n",
       "        0.07716205, 0.07767702, 0.07767702, 0.07767702, 0.07767702,\n",
       "        0.07767702, 0.07767702, 0.07767742, 0.07597922, 0.07597922,\n",
       "        0.07660554, 0.07593881, 0.07615834, 0.0767438 , 0.07769668,\n",
       "        0.07608101, 0.07608101, 0.07608101, 0.07673862, 0.07692588,\n",
       "        0.07642221, 0.07742234, 0.07623341, 0.07623341, 0.07623341,\n",
       "        0.07623341, 0.07618819, 0.0762328 , 0.07770052, 0.07661516,\n",
       "        0.07661516, 0.07661516, 0.07661516, 0.07647554, 0.07667488,\n",
       "        0.07714829, 0.07641716, 0.07641716, 0.07641716, 0.07641716,\n",
       "        0.07669801, 0.07683667, 0.07741006, 0.07703125, 0.07703125,\n",
       "        0.07703125, 0.07703125, 0.07703125, 0.07703125, 0.07806092,\n",
       "        0.07676633, 0.07676633, 0.07654628, 0.07669776, 0.07597967,\n",
       "        0.07604176, 0.07735163, 0.07684161, 0.07684161, 0.07684161,\n",
       "        0.07669141, 0.07635941, 0.07561844, 0.07770401, 0.07679702,\n",
       "        0.07679702, 0.07679702, 0.07679702, 0.07608424, 0.07689962,\n",
       "        0.07806492, 0.07671368, 0.07671368, 0.07671368, 0.07671368,\n",
       "        0.0763916 , 0.07756219, 0.07833056, 0.07624002, 0.07624002,\n",
       "        0.07624002, 0.07624002, 0.07680782, 0.07603004, 0.07725467,\n",
       "        0.0769275 , 0.0769275 , 0.0769275 , 0.0769275 , 0.0769275 ,\n",
       "        0.0769275 , 0.0771423 , 0.07557864, 0.07557864, 0.07578597,\n",
       "        0.07565875, 0.07558426, 0.07514897, 0.07539463, 0.07567306,\n",
       "        0.07567306, 0.07567306, 0.07581388, 0.07561553, 0.07599405,\n",
       "        0.07657649, 0.07582506, 0.07582506, 0.07582506, 0.07582506,\n",
       "        0.07497126, 0.07619776, 0.07680609, 0.07521117, 0.07521117,\n",
       "        0.07521117, 0.07521117, 0.07615755, 0.07520282, 0.07598645,\n",
       "        0.07662584, 0.07662584, 0.07662584, 0.07662584, 0.07603583,\n",
       "        0.07624524, 0.0765451 , 0.07627535, 0.07627535, 0.07627535,\n",
       "        0.07627535, 0.07627535, 0.07627535, 0.07723869, 0.07513132,\n",
       "        0.07513132, 0.07604816, 0.07485332, 0.07500175, 0.07511955,\n",
       "        0.07569857, 0.07562191, 0.07562191, 0.07562191, 0.07543208,\n",
       "        0.07494884, 0.07569808, 0.07639482, 0.07525179, 0.07525179,\n",
       "        0.07525179, 0.07525179, 0.07532601, 0.07604872, 0.076389  ,\n",
       "        0.0756553 , 0.0756553 , 0.0756553 , 0.0756553 , 0.07556072,\n",
       "        0.07572766, 0.07637443, 0.07558965, 0.07558965, 0.07558965,\n",
       "        0.07558965, 0.07575155, 0.07566905, 0.07610067, 0.07579733,\n",
       "        0.07579733, 0.07579733, 0.07579733, 0.07579733, 0.07579733,\n",
       "        0.07649416, 0.07536115, 0.07536115, 0.07620039, 0.07502584,\n",
       "        0.0759136 , 0.07508739, 0.07668113, 0.07510457, 0.07510457,\n",
       "        0.07510457, 0.07554032, 0.07585815, 0.07622991, 0.07696591,\n",
       "        0.0755752 , 0.0755752 , 0.0755752 , 0.0755752 , 0.0753358 ,\n",
       "        0.07558419, 0.07629148, 0.07561646, 0.07561646, 0.07561646,\n",
       "        0.07561646, 0.07544561, 0.07578331, 0.07709755, 0.07602386,\n",
       "        0.07602386, 0.07602386, 0.07602386, 0.07602856, 0.07585006,\n",
       "        0.07693461, 0.07644658, 0.07644658, 0.07644658, 0.07644658,\n",
       "        0.07644658, 0.07644658, 0.07707039, 0.07548626, 0.07548626,\n",
       "        0.07589693, 0.07506587, 0.07538411, 0.07602308, 0.07644425,\n",
       "        0.07550109, 0.07550109, 0.07550109, 0.07540538, 0.07536483,\n",
       "        0.07594776, 0.07624225, 0.07534925, 0.07534925, 0.07534925,\n",
       "        0.07534925, 0.07603038, 0.075569  , 0.07631583, 0.07577589,\n",
       "        0.07577589, 0.07577589, 0.07577589, 0.07568628, 0.07505595,\n",
       "        0.07580256, 0.07585571, 0.07585571, 0.07585571, 0.07585571,\n",
       "        0.07614913, 0.07549708, 0.07558102, 0.07576983, 0.07576983,\n",
       "        0.07576983, 0.07576983, 0.07576983, 0.07576983, 0.07700074]),\n",
       " 'rank_test_score': array([647, 647, 652, 667, 597, 633, 717, 664, 664, 664, 641, 671, 698,\n",
       "        668, 592, 592, 592, 592, 670, 566, 699, 691, 691, 691, 691, 603,\n",
       "        617, 689, 720, 720, 720, 720, 688, 623, 724, 626, 626, 626, 626,\n",
       "        626, 626, 718, 621, 621, 663, 604, 579, 545, 563, 644, 644, 644,\n",
       "        546, 510, 583, 612, 540, 540, 540, 540, 643, 539, 640, 659, 659,\n",
       "        659, 659, 658, 625, 559, 535, 535, 535, 535, 492, 216, 500, 549,\n",
       "        549, 549, 549, 549, 549, 602, 618, 618, 684, 555, 578, 562, 454,\n",
       "        613, 613, 613, 572, 599, 491, 558, 654, 654, 654, 654, 632, 598,\n",
       "        591, 574, 574, 574, 574, 616, 452, 467, 587, 587, 587, 587, 582,\n",
       "        601, 596, 606, 606, 606, 606, 606, 606, 586, 278, 278, 561, 564,\n",
       "        246, 523, 573, 524, 524, 524, 420, 342, 483, 450, 469, 469, 469,\n",
       "        469, 571, 307, 221, 473, 473, 473, 473, 505, 519, 548, 158, 158,\n",
       "        158, 158, 501, 359, 565, 484, 484, 484, 484, 484, 484, 433, 336,\n",
       "        336, 404, 251, 284, 457, 363, 511, 511, 511, 157, 277, 451, 355,\n",
       "        238, 238, 238, 238, 201, 438,  53, 113, 113, 113, 113, 184, 358,\n",
       "        580, 291, 291, 291, 291, 498, 377, 248, 254, 254, 254, 254, 254,\n",
       "        254, 220, 214, 214, 354, 443, 329, 340,  93,  62,  62,  62, 229,\n",
       "        315, 446, 403,  86,  86,  86,  86, 314, 308, 387, 379, 379, 379,\n",
       "        379,  95, 162, 124, 165, 165, 165, 165,  41, 317, 196,  16,  16,\n",
       "         16,  16,  16,  16,  13, 556, 556,  70, 328, 319, 376, 522, 325,\n",
       "        325, 325, 346, 357,  80, 338, 191, 191, 191, 191,  79, 364, 306,\n",
       "        395, 395, 395, 395, 482, 324, 414, 366, 366, 366, 366, 288, 356,\n",
       "        286, 388, 388, 388, 388, 388, 388, 436, 234, 234, 145,  24,  40,\n",
       "        133,  12, 417, 417, 417, 447, 183, 163,  29,  32,  32,  32,  32,\n",
       "         76,   3, 289,  36,  36,  36,  36,  43,  26, 218,  72,  72,  72,\n",
       "         72,  15,  77, 136,  96,  96,  96,  96,  96,  96, 141, 199, 199,\n",
       "        348, 182, 261, 210, 275, 527, 527, 527, 335, 230, 466, 249,  65,\n",
       "         65,  65,  65, 330, 570, 449, 515, 515, 515, 515, 435, 353,  25,\n",
       "        421, 421, 421, 421, 460, 287, 413, 102, 102, 102, 102, 102, 102,\n",
       "        135, 143, 143, 402, 514, 444,  11,  22, 350, 350, 350, 219,  44,\n",
       "        247, 236, 173, 173, 173, 173, 365, 164, 112, 137, 137, 137, 137,\n",
       "        177, 156,  61,  48,  48,  48,  48, 150,  14,  10,   4,   4,   4,\n",
       "          4,   4,   4,  46, 440, 440, 237, 276, 282, 217,  30, 311, 311,\n",
       "        311, 456, 445, 458,  91, 242, 242, 242, 242,  78, 203,  55, 296,\n",
       "        296, 296, 296, 250, 341, 290, 151, 151, 151, 151, 198, 134, 146,\n",
       "        222, 222, 222, 222, 222, 222,  54, 415, 415, 305,  52, 142, 285,\n",
       "          1, 373, 373, 373, 233,  60, 260,  81, 178, 178, 178, 178, 345,\n",
       "         45,  85, 186, 186, 186, 186, 228, 304,  90,  56,  56,  56,  56,\n",
       "         47, 281,   2, 117, 117, 117, 117, 117, 117,  28, 343, 343, 459,\n",
       "        442, 521, 401, 202, 383, 383, 383, 431, 378, 125, 253, 331, 331,\n",
       "        331, 331, 490,  92,  69, 405, 405, 405, 405, 453, 295, 211, 169,\n",
       "        169, 169, 169,  94, 430, 232, 262, 262, 262, 262, 262, 262, 148,\n",
       "        584, 584, 560, 493, 499, 534,  31, 360, 360, 360, 495, 252, 468,\n",
       "         84, 409, 409, 409, 409, 280, 197,  27, 425, 425, 425, 425, 437,\n",
       "        132,  83, 108, 108, 108, 108, 347, 309, 155, 204, 204, 204, 204,\n",
       "        204, 204,  42, 370, 370, 544, 400, 318, 349, 195, 502, 502, 502,\n",
       "        496, 432, 448, 185, 477, 477, 477, 477, 439, 283, 372, 462, 462,\n",
       "        462, 462, 497, 212, 190, 300, 300, 300, 300, 429, 310, 147, 126,\n",
       "        126, 126, 126, 126, 126,  82, 567, 567, 547, 520, 231, 316, 213,\n",
       "        649, 649, 649, 494, 481, 149, 339, 506, 506, 506, 506, 399, 394,\n",
       "        274, 530, 530, 530, 530, 455, 386, 461, 320, 320, 320, 320, 434,\n",
       "        123,  23, 268, 268, 268, 268, 268, 268,  71, 744, 744, 753, 779,\n",
       "        763, 728, 581, 804, 804, 804, 823, 762, 736, 682, 816, 816, 816,\n",
       "        816, 737, 709, 669, 748, 748, 748, 748, 735, 707, 600, 758, 758,\n",
       "        758, 758, 738, 708, 605, 634, 634, 634, 634, 634, 634, 620, 811,\n",
       "        811, 822, 824, 791, 719, 642, 780, 780, 780, 820, 773, 742, 687,\n",
       "        769, 769, 769, 769, 783, 794, 686, 795, 795, 795, 795, 746, 727,\n",
       "        690, 729, 729, 729, 729, 733, 696, 624, 673, 673, 673, 673, 673,\n",
       "        673, 569, 792, 792, 810, 837, 828, 752, 726, 739, 739, 739, 813,\n",
       "        839, 785, 700, 787, 787, 787, 787, 814, 778, 683, 754, 754, 754,\n",
       "        754, 821, 747, 716, 764, 764, 764, 764, 786, 743, 679, 701, 701,\n",
       "        701, 701, 701, 701, 672, 808, 808, 807, 829, 825, 768, 695, 834,\n",
       "        834, 834, 840, 826, 815, 697, 800, 800, 800, 800, 838, 827, 685,\n",
       "        830, 830, 830, 830, 784, 725, 681, 774, 774, 774, 774, 799, 734,\n",
       "        653, 710, 710, 710, 710, 710, 710, 680])}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gbt_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pv_GKI0wJVor"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.05%\n",
      "Balanced Accuracy: 67.7%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     12533\n",
      "           1       0.86      0.36      0.51      1169\n",
      "\n",
      "    accuracy                           0.94     13702\n",
      "   macro avg       0.90      0.68      0.74     13702\n",
      "weighted avg       0.94      0.94      0.93     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12467</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>749</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1\n",
       "is_promoted            \n",
       "0            12467   66\n",
       "1              749  420"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_gbt_cv.predict(X_val)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IecquLK0JaDo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 750 candidates, totalling 2250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   50.8s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  3.8min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:  9.7min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 18.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1226 tasks      | elapsed: 32.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1776 tasks      | elapsed: 52.8min\n",
      "[Parallel(n_jobs=-1)]: Done 2250 out of 2250 | elapsed: 73.5min finished\n"
     ]
    }
   ],
   "source": [
    "grid_values = {'n_estimators': [500],'min_samples_split':[2,5,10,350,500],'min_samples_leaf':[1,2,3,5,10,20],'max_depth':[4,5,6,7,8], 'max_features':[7,8,9,10,12]}\n",
    "grid_clf_acc2 = GridSearchCV(clf, param_grid = grid_values,scoring = 'f1',cv=3,n_jobs=-1,verbose=1)\n",
    "model_gbt_cv2 = grid_clf_acc2.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 6,\n",
       " 'max_features': 9,\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 350,\n",
       " 'n_estimators': 500}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gbt_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([21.16524736, 21.29542263, 21.29542613, 20.89781618, 21.54744713,\n",
       "        21.19167113, 21.46898937, 21.4514161 , 21.81717483, 22.2436409 ,\n",
       "        22.05980905, 21.90868123, 21.35167209, 20.97541746, 21.53588788,\n",
       "        21.30393871, 20.80901734, 20.97769181, 20.77641749, 20.72436889,\n",
       "        20.26428866, 20.35482939, 20.49092261, 20.71826951, 20.53915381,\n",
       "        20.48204001, 20.47978131, 20.27532307, 20.44683305, 20.65889692,\n",
       "        20.70733364, 21.07297556, 20.27908071, 20.25605734, 20.3353107 ,\n",
       "        20.43165731, 20.08964507, 20.35605597, 20.22920903, 20.53932858,\n",
       "        19.81878408, 20.15768361, 22.49383616, 22.73071615, 22.23091364,\n",
       "        22.3905623 , 22.34957671, 22.28369768, 22.22800962, 22.23434718,\n",
       "        22.27615937, 22.45166286, 22.40662964, 22.0289185 , 22.11043795,\n",
       "        22.26733128, 22.46276736, 22.46023575, 22.64063533, 22.5691967 ,\n",
       "        22.21849656, 22.37733364, 22.17658798, 22.51501179, 22.10801593,\n",
       "        22.55933825, 22.46194442, 22.34223294, 22.10862589, 22.43980296,\n",
       "        22.12701495, 22.53679331, 22.43373672, 22.70433346, 22.47235099,\n",
       "        22.40376051, 22.01650389, 22.30082138, 22.13568791, 22.14298399,\n",
       "        22.31380963, 22.18397347, 22.05373216, 22.0440313 , 24.59557263,\n",
       "        24.49598463, 24.03911257, 24.25268563, 24.25205406, 23.97353752,\n",
       "        23.7964917 , 24.53111418, 24.34999998, 24.2041978 , 24.27420497,\n",
       "        24.06601516, 24.04545911, 23.92968114, 24.28837276, 24.32644169,\n",
       "        24.09618465, 24.29562028, 24.63391574, 24.48153559, 23.83990963,\n",
       "        24.0658764 , 24.1019609 , 24.16352272, 24.05686442, 24.10279846,\n",
       "        24.2187504 , 23.93136819, 24.33603422, 24.24916132, 24.14363686,\n",
       "        24.35908659, 23.9692022 , 24.08000485, 24.19478067, 23.82993078,\n",
       "        24.193741  , 24.23162897, 24.30555916, 23.98139493, 24.2176764 ,\n",
       "        23.87957255, 26.5059251 , 26.07527502, 26.06555525, 26.23603749,\n",
       "        26.56038396, 25.96025896, 26.15871628, 26.16550557, 26.02554552,\n",
       "        26.12167668, 26.20231477, 26.27676225, 25.88068215, 25.87289135,\n",
       "        26.01152372, 26.09535003, 26.20745929, 26.06432056, 26.05858421,\n",
       "        25.97451337, 26.16869505, 26.2358315 , 26.58013225, 26.3282028 ,\n",
       "        26.11471089, 26.51135429, 25.95639459, 25.63931243, 26.175373  ,\n",
       "        26.08613777, 25.8514607 , 25.91426269, 26.25187135, 26.05725996,\n",
       "        25.68330423, 25.9575181 , 26.02000419, 26.09810909, 25.95518335,\n",
       "        26.23279532, 26.4797438 , 26.65191634, 25.24487011, 25.17604097,\n",
       "        24.75747196, 24.67936325, 24.6640106 , 24.41711879, 23.98270615,\n",
       "        24.92102957, 24.72413603, 24.8450036 , 24.63764278, 24.62385853,\n",
       "        24.45072961, 24.03584234, 24.73880402, 24.6711301 , 24.97588754,\n",
       "        24.8113296 , 24.75921575, 24.41003704, 24.37138112, 24.59880201,\n",
       "        24.57108386, 24.78809325, 24.70329563, 24.59320362, 24.49168897,\n",
       "        23.96172301, 24.56473541, 24.59059985, 24.46847296, 24.57019838,\n",
       "        24.54431923, 24.46915547, 24.17499924, 24.2051359 , 24.45057138,\n",
       "        24.32785114, 24.27167678, 24.29173223, 24.43110021, 23.90797544,\n",
       "        27.3353885 , 27.38038937, 27.49129955, 27.16397238, 27.06626678,\n",
       "        26.96949013, 26.49569122, 27.24592916, 27.31287018, 27.24627097,\n",
       "        27.3018558 , 27.16309524, 27.15496937, 26.6390121 , 27.39979188,\n",
       "        27.43051895, 27.2580022 , 27.28444815, 27.16835713, 26.98361238,\n",
       "        26.47242244, 27.10886614, 27.28507932, 27.18114551, 27.19429946,\n",
       "        27.12481149, 26.89380964, 26.80433734, 26.91711346, 27.00610034,\n",
       "        27.05682715, 27.07920933, 26.97382998, 26.87724233, 26.64045056,\n",
       "        26.89228153, 26.73004945, 26.6961635 , 26.72520073, 26.86455663,\n",
       "        26.83940522, 26.3606267 , 30.13114635, 30.47374662, 30.26336177,\n",
       "        30.24444254, 29.79894114, 29.65493751, 29.18009774, 29.76299977,\n",
       "        29.7395107 , 29.85040466, 29.73541387, 29.5955685 , 29.26113009,\n",
       "        28.96887596, 29.63248507, 29.78870281, 29.70805939, 29.75606831,\n",
       "        29.43319607, 29.56285866, 29.24098802, 29.82519023, 29.51738866,\n",
       "        29.7771546 , 29.49907565, 29.55920029, 29.5276316 , 29.19020955,\n",
       "        30.52528564, 30.01864012, 30.01779103, 29.90520692, 29.54019451,\n",
       "        29.24798322, 29.25427381, 29.6311299 , 29.41674407, 29.50832097,\n",
       "        29.16417241, 29.40350262, 29.30714679, 29.15682316, 32.82544351,\n",
       "        32.97537057, 33.04220549, 32.64816451, 32.08834251, 31.8695004 ,\n",
       "        31.3344388 , 32.35871506, 32.23040605, 32.26184646, 31.99702668,\n",
       "        31.85830148, 31.70638625, 31.26744684, 31.99315302, 32.15138737,\n",
       "        31.94223809, 32.23634553, 31.86380577, 31.99843923, 31.3048195 ,\n",
       "        32.08069944, 32.06321081, 32.17597183, 32.07629538, 32.061553  ,\n",
       "        31.72165799, 31.21405435, 31.72383849, 32.03103177, 32.0096217 ,\n",
       "        32.10986487, 32.01739875, 31.90819232, 31.63524175, 32.08194908,\n",
       "        31.56249897, 32.09246445, 31.61711327, 31.93440398, 32.11639349,\n",
       "        32.66147137, 30.40455445, 31.01178749, 30.20417643, 29.71006576,\n",
       "        28.99021546, 29.27560488, 28.08362937, 29.49404136, 29.42439628,\n",
       "        29.9745295 , 29.71953654, 29.56128438, 28.62849148, 28.46051105,\n",
       "        29.68155964, 29.79259451, 29.51835966, 29.67329208, 29.21971973,\n",
       "        29.17439747, 28.16494028, 29.54731623, 29.24035756, 29.57169938,\n",
       "        29.18192633, 29.12953536, 28.93424265, 28.6565392 , 29.0222129 ,\n",
       "        29.19996436, 29.20853146, 29.34073639, 29.10212127, 28.88867458,\n",
       "        28.51448846, 29.24093755, 29.31302444, 29.33504725, 28.92330011,\n",
       "        28.71141958, 29.12537599, 28.95109518, 34.76419226, 34.74519626,\n",
       "        33.80919623, 33.74486192, 32.3395075 , 32.10693518, 32.48019799,\n",
       "        34.59454934, 34.37693755, 34.19795712, 33.53091025, 32.06471372,\n",
       "        31.87841201, 31.36352078, 33.02848562, 33.0691181 , 33.18944128,\n",
       "        33.42252477, 32.8764499 , 32.57216525, 31.67951186, 32.77090089,\n",
       "        32.85775932, 32.92052396, 32.23037489, 32.20451625, 31.94859258,\n",
       "        31.71217704, 32.30158361, 32.36269601, 32.30430547, 32.50299629,\n",
       "        32.0442911 , 32.39513461, 31.44990889, 31.91743128, 31.87782995,\n",
       "        32.03146895, 31.95345291, 32.39509654, 32.75634543, 32.064243  ,\n",
       "        36.74468279, 36.29558396, 36.23768997, 36.05721943, 35.56842907,\n",
       "        34.82795564, 33.94208137, 36.08625054, 36.06153274, 35.65253425,\n",
       "        35.82375733, 35.06079714, 35.17721836, 33.95166294, 35.75455602,\n",
       "        35.70532584, 36.71411975, 36.59810154, 35.7492195 , 35.46699421,\n",
       "        34.02245712, 35.56250803, 35.0072902 , 35.47512921, 35.33297523,\n",
       "        35.08907914, 34.63828103, 34.44967357, 35.48574106, 35.36652303,\n",
       "        35.0663112 , 35.13763126, 35.25575137, 34.99578746, 34.82239453,\n",
       "        35.47920648, 35.50390069, 35.95304092, 34.77838214, 34.86117148,\n",
       "        34.70059919, 34.14029129, 38.99111271, 38.90843256, 39.21074001,\n",
       "        39.32043099, 38.74525921, 38.31288362, 36.93020344, 38.6368773 ,\n",
       "        38.53562673, 38.63144565, 38.42380929, 38.08156959, 37.58191744,\n",
       "        37.10702236, 38.33765817, 38.54127574, 38.65048997, 38.75211549,\n",
       "        37.90405035, 37.83852037, 37.04472589, 38.76459575, 38.52599223,\n",
       "        38.97200648, 38.66196354, 38.30011956, 39.83956146, 38.59442806,\n",
       "        41.01017427, 39.98005859, 39.74841078, 39.21411149, 38.24822537,\n",
       "        37.67457509, 37.35067042, 37.66140238, 37.36687016, 37.8290987 ,\n",
       "        37.83530545, 37.95876773, 37.58226728, 37.05451012, 35.99305288,\n",
       "        35.75192761, 35.5256993 , 35.20703069, 34.47903323, 33.887947  ,\n",
       "        32.64325507, 35.59921344, 35.44361488, 35.53204513, 35.17479396,\n",
       "        34.49977183, 33.96295309, 32.86161208, 35.38104137, 35.04120612,\n",
       "        34.95601384, 35.17717338, 34.09298929, 33.92040706, 32.6426026 ,\n",
       "        34.63740389, 34.57009594, 34.48896329, 34.62564874, 34.38594222,\n",
       "        33.45821889, 32.58070779, 34.07650407, 34.10916996, 34.0148108 ,\n",
       "        34.02835759, 33.96744188, 33.67875417, 32.59820437, 33.22401396,\n",
       "        33.30772209, 33.16056808, 33.14686894, 33.17204833, 33.28502917,\n",
       "        32.12816223, 39.55319341, 39.6743052 , 39.74490786, 39.68917155,\n",
       "        38.40012662, 37.9059635 , 35.68498206, 38.99686472, 39.00906388,\n",
       "        39.46832132, 39.02381579, 38.4049747 , 37.77679634, 36.0901955 ,\n",
       "        38.46957429, 38.75046062, 38.53454995, 38.57872931, 37.69502775,\n",
       "        37.30458053, 36.00739153, 38.27616882, 38.08998076, 38.11165611,\n",
       "        38.1286788 , 37.78892104, 37.19286283, 36.08409413, 37.69783298,\n",
       "        37.77944875, 37.54088171, 38.02108947, 37.52130683, 37.37915683,\n",
       "        35.92245166, 36.97788326, 36.99904172, 36.83901103, 36.83244912,\n",
       "        36.93908493, 36.82032712, 35.93336622, 43.26242924, 43.26723822,\n",
       "        42.94837205, 42.45836004, 41.14711388, 40.74298247, 39.51334683,\n",
       "        42.57432946, 42.48667137, 42.4460748 , 42.39254101, 41.22319134,\n",
       "        40.89714281, 39.56653611, 42.20089761, 42.37769612, 42.34374976,\n",
       "        42.32555437, 40.90986649, 40.54861601, 39.38812272, 41.48797425,\n",
       "        41.36857017, 41.08741752, 41.44378312, 41.07812198, 40.6070466 ,\n",
       "        39.49352535, 41.06738011, 41.10287293, 41.03898549, 40.85211364,\n",
       "        40.9947106 , 40.56184618, 39.19960157, 40.24514945, 40.23258766,\n",
       "        40.14054608, 40.2090439 , 40.14229361, 39.93242764, 38.94594765,\n",
       "        46.46302327, 46.10736855, 46.47230419, 46.2846663 , 45.41278919,\n",
       "        44.76722225, 42.68913349, 46.10576455, 45.86300476, 45.77185225,\n",
       "        45.66831382, 44.36529684, 43.94890308, 42.59293103, 45.70325184,\n",
       "        45.2861584 , 45.36286124, 45.43289383, 44.4625806 , 43.95031945,\n",
       "        42.50324281, 44.95481499, 44.71400825, 44.90182257, 45.14257073,\n",
       "        44.42134134, 43.62498236, 43.06937011, 44.34479356, 44.56244675,\n",
       "        44.24353123, 44.71560311, 44.17714341, 44.05667909, 42.30172857,\n",
       "        43.88576969, 43.46213587, 43.64276425, 43.44171604, 43.58333723,\n",
       "        43.13443955, 41.72447578, 60.70405364, 60.8236649 , 60.42656144,\n",
       "        57.16747069, 51.54371929, 48.92423765, 44.68245212, 58.29222027,\n",
       "        57.68476184, 57.29536335, 57.08713595, 52.09659378, 49.66021808,\n",
       "        46.9523836 , 55.79025157, 55.60027647, 55.27649411, 55.15117717,\n",
       "        50.89208714, 48.78143676, 45.15234987, 52.05251376, 51.91341416,\n",
       "        51.77777759, 51.87647033, 49.84324185, 48.27747242, 45.22633338,\n",
       "        49.25929062, 49.2570378 , 49.22052081, 49.27958083, 49.28924227,\n",
       "        47.95049874, 44.91915298, 46.433508  , 46.8167034 , 46.64783247,\n",
       "        46.36564008, 46.32563607, 45.79503989, 43.41096711, 66.92407521,\n",
       "        66.89986809, 65.59618648, 62.50456039, 56.72627211, 54.56290118,\n",
       "        50.52135189, 65.16328812, 64.61335373, 63.86203273, 62.66062323,\n",
       "        55.81132849, 53.79722794, 50.12081734, 61.38544432, 61.1838901 ,\n",
       "        61.38958851, 61.3138353 , 56.28453167, 54.48171552, 50.90955162,\n",
       "        58.12856881, 57.7689991 , 57.77050535, 57.89796042, 55.71651141,\n",
       "        53.66691494, 50.38969326, 55.05167866, 54.9668866 , 54.97114189,\n",
       "        55.01688178, 54.73011947, 53.30225849, 50.07709225, 51.9480118 ,\n",
       "        52.42708643, 52.35459057, 52.52620554, 52.44573712, 51.41134914,\n",
       "        48.58130773, 72.36642249, 72.2310334 , 70.98984083, 67.71805509,\n",
       "        61.35737363, 58.65099629, 54.41348044, 69.31286502, 68.96373415,\n",
       "        68.88294498, 67.27678863, 60.97911588, 58.9050281 , 54.87910088,\n",
       "        66.6395336 , 66.82790399, 66.29820037, 66.25627128, 61.24438596,\n",
       "        59.11371962, 52.81570244, 60.43676313, 59.58005301, 59.86805169,\n",
       "        62.45168749, 60.0281918 , 58.84132735, 55.08220283, 60.25914391,\n",
       "        60.36963582, 60.52335509, 60.098159  , 60.13676802, 58.25413219,\n",
       "        55.13630223, 57.18127672, 57.0549039 , 57.11529922, 57.47928365,\n",
       "        57.34730331, 58.46588413, 56.09437998, 79.98688889, 80.38392528,\n",
       "        77.17364661, 73.69907896, 66.44076761, 63.4305288 , 59.5461634 ,\n",
       "        74.76502419, 74.25790564, 75.24026219, 72.97879958, 66.56907598,\n",
       "        63.90440408, 59.96017623, 71.84502141, 71.61042658, 72.89220166,\n",
       "        72.6291062 , 67.04006441, 64.50536656, 59.6700894 , 68.68604279,\n",
       "        68.08070215, 68.34853959, 68.39629618, 66.03014183, 64.08179577,\n",
       "        60.35636306, 66.30311497, 66.42563208, 66.51763503, 66.55963437,\n",
       "        64.78510276, 63.06923525, 59.56757808, 62.36294476, 62.7881693 ,\n",
       "        62.4800779 , 62.38654804, 62.2435325 , 51.82768599, 46.53320726]),\n",
       " 'std_fit_time': array([3.62832021e-01, 2.04593810e-01, 2.77355075e-01, 3.51278467e-01,\n",
       "        1.12389801e-01, 2.83146978e-01, 4.02489325e-01, 4.33769489e-01,\n",
       "        2.32901154e-01, 1.18442956e-01, 1.73683843e-01, 5.66527592e-01,\n",
       "        5.81935522e-01, 4.51543408e-01, 5.10187723e-02, 4.43319202e-01,\n",
       "        6.45428009e-02, 4.46987102e-01, 4.91582590e-01, 1.40725523e-03,\n",
       "        2.95574588e-01, 2.91504605e-01, 1.54674723e-01, 3.57049261e-01,\n",
       "        1.61395438e-01, 3.02756687e-01, 3.22547713e-01, 3.13178125e-01,\n",
       "        6.76554636e-02, 4.69161652e-01, 3.52743638e-01, 1.17433708e-01,\n",
       "        3.74770075e-01, 4.17237614e-01, 3.57509820e-01, 3.37134965e-01,\n",
       "        1.51376179e-01, 3.77497081e-01, 2.24922959e-01, 2.60458310e-01,\n",
       "        3.05815298e-01, 1.44867330e-01, 2.53282770e-01, 3.00751796e-01,\n",
       "        3.20755318e-01, 2.68658660e-01, 2.52888876e-01, 2.73657479e-01,\n",
       "        1.54025077e-01, 3.29902005e-01, 4.24301736e-01, 4.87189541e-01,\n",
       "        3.45605879e-01, 2.84609005e-01, 1.44865393e-01, 7.02600697e-02,\n",
       "        4.38425408e-01, 6.30772145e-01, 2.58367365e-01, 2.67557130e-01,\n",
       "        5.98657814e-01, 4.14676106e-01, 8.49247292e-02, 4.14675145e-01,\n",
       "        2.89592706e-01, 3.05957768e-01, 8.36416409e-02, 2.19935981e-01,\n",
       "        1.91333139e-01, 2.97672035e-01, 2.50746977e-01, 4.11290352e-01,\n",
       "        5.41695106e-01, 2.35025777e-01, 5.32743731e-01, 1.03613167e-01,\n",
       "        1.86641806e-01, 3.09889863e-01, 4.15731078e-01, 3.80581522e-01,\n",
       "        3.24764766e-01, 2.01288072e-01, 4.19848360e-01, 3.95271459e-01,\n",
       "        2.28640091e-01, 3.90845006e-01, 2.85591397e-01, 2.75368412e-01,\n",
       "        5.05436977e-01, 4.62937581e-01, 4.33909710e-01, 4.04952887e-01,\n",
       "        2.88323992e-01, 2.48746839e-01, 3.24876287e-01, 3.16129864e-01,\n",
       "        5.85470591e-01, 3.34775533e-01, 3.70963998e-01, 4.97433939e-01,\n",
       "        3.04780788e-01, 6.21326335e-01, 5.26042749e-01, 3.87629589e-01,\n",
       "        1.72628388e-01, 3.34313264e-01, 4.64105203e-01, 4.59349179e-01,\n",
       "        3.37938207e-01, 3.96481604e-01, 7.69949887e-02, 2.64595422e-01,\n",
       "        9.29437558e-01, 1.76889529e-01, 4.20548469e-01, 4.24650216e-01,\n",
       "        3.00191440e-01, 1.85856810e-01, 6.31723365e-01, 4.62251152e-01,\n",
       "        4.25359442e-01, 2.26943203e-01, 1.02961408e-01, 3.92160914e-01,\n",
       "        1.56160235e-01, 1.86230115e-01, 2.10052088e-01, 5.19612717e-01,\n",
       "        3.87889292e-01, 4.29956649e-01, 3.06833028e-01, 2.74780834e-01,\n",
       "        2.01091669e-01, 4.44011261e-01, 3.67594953e-01, 3.78314343e-01,\n",
       "        3.19285384e-01, 6.33821994e-01, 3.53702298e-01, 2.43455456e-01,\n",
       "        3.49819415e-01, 5.54866831e-01, 2.48963334e-01, 3.12074862e-01,\n",
       "        4.95209914e-01, 3.14900435e-01, 4.33612564e-01, 4.71712346e-01,\n",
       "        1.50285247e-01, 3.66468256e-01, 3.99763027e-01, 4.97452429e-01,\n",
       "        2.73328658e-01, 3.57421715e-01, 6.29306788e-01, 4.02766005e-01,\n",
       "        3.55549893e-01, 3.54007313e-01, 2.42280236e-01, 4.37899961e-01,\n",
       "        3.57152779e-01, 4.97107530e-01, 3.92919789e-01, 5.32652739e-01,\n",
       "        4.12183240e-01, 3.21177192e-01, 5.43293048e-01, 3.76426607e-01,\n",
       "        3.48747403e-01, 1.55451341e-01, 5.01993298e-01, 4.41839406e-01,\n",
       "        3.38020850e-01, 5.41339917e-01, 3.52161551e-01, 4.96840092e-01,\n",
       "        3.37853973e-01, 3.20354884e-01, 3.45833643e-01, 3.75353888e-01,\n",
       "        1.21672226e-01, 3.69006927e-01, 2.98638681e-01, 3.20746750e-01,\n",
       "        4.85683719e-01, 3.83280226e-01, 2.02475689e-01, 2.58784558e-01,\n",
       "        5.09425318e-01, 2.63988130e-01, 3.31584984e-01, 1.47945162e-01,\n",
       "        1.36381440e-01, 4.27680452e-01, 3.68648585e-01, 3.31706587e-01,\n",
       "        2.68761330e-01, 2.00185997e-01, 4.04642593e-01, 2.30953234e-01,\n",
       "        4.27090027e-01, 4.63205832e-01, 4.96372705e-01, 3.81988955e-01,\n",
       "        2.08803467e-01, 2.86470476e-01, 2.80103667e-01, 3.66198680e-01,\n",
       "        4.04616308e-01, 2.29761043e-01, 3.32175844e-01, 4.78936469e-01,\n",
       "        4.44667699e-01, 4.33599763e-01, 4.15055451e-01, 2.99062201e-01,\n",
       "        3.68418276e-01, 4.08222014e-01, 3.43195694e-01, 3.19755907e-01,\n",
       "        5.06954975e-01, 4.97066394e-01, 3.80938547e-01, 4.08044036e-01,\n",
       "        4.31949995e-01, 2.78152522e-01, 5.30357458e-01, 4.52614619e-01,\n",
       "        1.68149124e-01, 5.72057050e-01, 5.30409204e-01, 5.79292038e-01,\n",
       "        2.69668141e-01, 2.42001848e-01, 5.26762364e-01, 3.38982949e-01,\n",
       "        4.51869073e-01, 2.71611116e-01, 4.93492980e-01, 2.94836675e-01,\n",
       "        4.69757568e-01, 5.82079081e-01, 1.89649732e-01, 6.35677159e-01,\n",
       "        2.25276897e-01, 6.65028136e-01, 4.12710327e-01, 2.47778234e-01,\n",
       "        4.91734937e-01, 2.83448010e-01, 4.86536829e-01, 3.03618925e-01,\n",
       "        3.74838864e-01, 1.89082457e-01, 3.34859937e-01, 6.31026655e-01,\n",
       "        3.78761849e-01, 4.03609542e-01, 5.25624896e-01, 3.83563786e-01,\n",
       "        4.10537354e-01, 2.93604980e-01, 5.80912812e-01, 4.08750610e-01,\n",
       "        3.42882087e-01, 4.26283759e-01, 2.96484713e-01, 5.15004777e-01,\n",
       "        5.10758786e-01, 3.82392705e-01, 4.80133048e-01, 6.50914098e-01,\n",
       "        3.41527130e-01, 8.08824799e-01, 6.85941358e-01, 3.77221003e-01,\n",
       "        5.80014251e-01, 5.66673628e-01, 4.83072029e-01, 2.65594652e-01,\n",
       "        7.76603316e-01, 1.59606657e-01, 7.97012624e-01, 3.91474047e-01,\n",
       "        5.00448127e-01, 4.42536126e-01, 5.70479742e-01, 3.79013653e-01,\n",
       "        5.90440162e-01, 6.63186208e-01, 3.74164773e-01, 4.58939239e-01,\n",
       "        3.28998965e-01, 7.79312725e-02, 6.63459256e-01, 4.84617484e-01,\n",
       "        8.69954170e-01, 4.08923493e-01, 3.33364180e-01, 6.79248442e-01,\n",
       "        4.31747515e-01, 5.75137122e-01, 5.88037810e-01, 5.82657209e-01,\n",
       "        5.92609979e-01, 5.96371347e-01, 4.37987119e-01, 6.03978752e-01,\n",
       "        6.03298348e-01, 6.73853260e-01, 3.99870145e-01, 6.44116383e-01,\n",
       "        5.09589047e-01, 3.77301313e-01, 5.84023058e-01, 5.24606579e-01,\n",
       "        5.13300770e-01, 5.93108019e-01, 4.55461320e-01, 5.34026593e-01,\n",
       "        6.64709672e-01, 6.59832316e-01, 7.46388123e-01, 6.05891528e-01,\n",
       "        4.82720391e-01, 5.05437852e-01, 5.12946583e-01, 6.53716637e-01,\n",
       "        5.88392642e-01, 5.10095007e-01, 5.35701294e-01, 7.71670423e-01,\n",
       "        6.25725403e-01, 4.76143167e-01, 4.85534190e-01, 4.82140628e-01,\n",
       "        4.16111418e-01, 6.69032086e-01, 5.95470758e-01, 1.67021003e-01,\n",
       "        4.80339597e-01, 4.64839017e-01, 7.17093496e-02, 9.03232653e-01,\n",
       "        4.02363428e-01, 3.40392588e-01, 1.24276504e-01, 4.70291001e-01,\n",
       "        4.12900990e-01, 5.31259949e-01, 1.02705738e-01, 4.41841035e-01,\n",
       "        4.85616458e-01, 1.48434922e-01, 1.59130602e-01, 4.88918988e-01,\n",
       "        2.63844753e-01, 6.47231284e-01, 2.34502666e-01, 5.06404498e-01,\n",
       "        4.05226112e-01, 3.82471537e-02, 5.92171238e-01, 3.66302010e-01,\n",
       "        4.19968250e-01, 2.84108232e-01, 2.41645086e-01, 3.07780210e-01,\n",
       "        2.11258044e-01, 1.47423654e-01, 1.31060537e-01, 2.00243797e-01,\n",
       "        6.97325106e-01, 1.74754150e-01, 6.45054747e-01, 4.94383049e-01,\n",
       "        3.43777252e-01, 3.78868567e-01, 1.29028506e-01, 6.77688518e-01,\n",
       "        2.23152306e-01, 2.88651775e-01, 3.26717316e-01, 3.26864070e-01,\n",
       "        6.47622843e-01, 6.79878604e-01, 5.49820703e-01, 8.58588647e-01,\n",
       "        4.91346446e-01, 4.92093517e-01, 3.12337151e-01, 5.31177355e-01,\n",
       "        6.02966223e-01, 6.97603729e-01, 5.43699562e-01, 5.71364442e-01,\n",
       "        5.82309714e-01, 4.86890384e-01, 6.25255758e-01, 5.67190948e-01,\n",
       "        7.53015996e-01, 3.94023927e-01, 7.87508375e-01, 5.62669520e-01,\n",
       "        2.85021738e-01, 4.84251614e-01, 8.32340929e-01, 4.47418237e-01,\n",
       "        4.87560289e-01, 6.34292144e-01, 4.59126809e-01, 6.94868880e-01,\n",
       "        4.21573852e-01, 4.36290881e-01, 6.85125629e-01, 7.02592655e-01,\n",
       "        5.50546550e-01, 6.18888452e-01, 7.61974121e-01, 5.64997061e-02,\n",
       "        5.80913438e-01, 6.22126881e-01, 7.99258681e-01, 5.45326834e-01,\n",
       "        6.53481834e-01, 5.06821062e-01, 8.98998850e-01, 4.72440957e-01,\n",
       "        6.74614107e-01, 8.28350045e-01, 9.39078753e-01, 6.99424441e-01,\n",
       "        3.26270511e-01, 3.90785501e-01, 9.24495683e-01, 6.93192963e-01,\n",
       "        8.41927769e-01, 1.09994690e+00, 6.76484331e-01, 5.01709003e-01,\n",
       "        4.52064915e-01, 2.68872190e-01, 6.09903477e-01, 5.33155493e-01,\n",
       "        6.38800163e-01, 5.18733226e-01, 6.10690844e-01, 4.62231198e-01,\n",
       "        1.70280977e-01, 6.85791204e-01, 7.86968724e-01, 4.18475537e-01,\n",
       "        2.28273123e-01, 4.71866596e-01, 3.64856491e-01, 1.14634662e+00,\n",
       "        5.71857859e-01, 1.13903455e+00, 6.22054295e-01, 6.99037587e-01,\n",
       "        6.37779429e-01, 4.13685089e-01, 7.55310116e-01, 4.45318396e-01,\n",
       "        4.13170775e-01, 7.64966517e-01, 5.24190034e-01, 5.49203253e-01,\n",
       "        5.38183627e-01, 5.74227958e-01, 5.00594535e-01, 8.70865953e-01,\n",
       "        7.12412627e-01, 7.31505710e-01, 9.26981319e-01, 7.10541523e-01,\n",
       "        7.55012413e-01, 6.34110767e-01, 7.40717914e-01, 6.47288026e-01,\n",
       "        8.49390688e-01, 1.18113041e+00, 6.88790702e-01, 9.44486273e-01,\n",
       "        5.59232910e-01, 5.02826416e-01, 7.63168408e-01, 8.50143900e-01,\n",
       "        4.12768964e-01, 6.13717463e-01, 1.12307171e+00, 5.40986696e-01,\n",
       "        1.04497710e+00, 5.85495281e-01, 1.16027075e+00, 7.52200521e-01,\n",
       "        8.65311724e-01, 5.28420178e-01, 6.25105800e-01, 4.57844503e-01,\n",
       "        6.14252122e-01, 5.73182959e-01, 4.99514670e-01, 9.27922858e-01,\n",
       "        7.40193314e-01, 3.84832673e-01, 5.96933533e-01, 6.52426875e-01,\n",
       "        7.21534698e-01, 8.80391699e-01, 6.27030085e-01, 5.02278354e-01,\n",
       "        8.01251899e-01, 5.15619832e-01, 4.90188367e-01, 8.40805372e-01,\n",
       "        5.87851093e-01, 2.69283517e-01, 6.80403054e-01, 4.62411995e-01,\n",
       "        6.36789485e-01, 6.19183595e-01, 5.66675289e-01, 4.66116696e-01,\n",
       "        6.16090299e-01, 5.53788529e-01, 6.39361978e-01, 6.23290359e-01,\n",
       "        6.53898406e-01, 6.99197055e-01, 5.60634025e-01, 4.83303171e-01,\n",
       "        4.57767888e-01, 3.07790543e-01, 4.79678444e-01, 4.29086924e-01,\n",
       "        3.98644467e-01, 7.34863030e-01, 5.94066516e-01, 4.65217501e-01,\n",
       "        7.46235555e-01, 2.63140513e-01, 2.43445838e-01, 3.05923046e-01,\n",
       "        2.58833768e-01, 3.90064819e-01, 8.13785812e-01, 1.05269887e+00,\n",
       "        1.00165680e+00, 8.58586080e-01, 4.76676735e-01, 5.23326045e-01,\n",
       "        4.77961199e-01, 4.79377074e-01, 6.82440835e-01, 1.03284234e+00,\n",
       "        7.83712121e-01, 6.21232893e-01, 1.02424622e+00, 2.28287906e-01,\n",
       "        5.10741898e-01, 7.59485297e-01, 5.45542884e-01, 3.18128576e-01,\n",
       "        7.97117094e-01, 8.26183448e-01, 8.02194433e-01, 3.17966941e-01,\n",
       "        3.84784301e-01, 8.07119940e-01, 3.92920854e-01, 3.17422700e-01,\n",
       "        4.03007839e-01, 6.77814230e-01, 7.77070632e-01, 8.77086448e-01,\n",
       "        8.38790942e-01, 6.96624915e-01, 4.99270417e-01, 6.25279712e-01,\n",
       "        5.19284640e-01, 5.45230747e-01, 6.58513116e-01, 6.81025902e-01,\n",
       "        3.70937594e-01, 8.01827868e-01, 6.55846937e-01, 7.27067042e-01,\n",
       "        7.76267623e-01, 7.20721073e-01, 7.64261734e-01, 8.87610513e-01,\n",
       "        8.51387657e-01, 8.03215276e-01, 8.17463125e-01, 7.69445084e-01,\n",
       "        8.36419411e-01, 7.01452587e-01, 7.50677427e-01, 7.99219777e-01,\n",
       "        9.55357176e-01, 7.76653694e-01, 9.53662177e-01, 9.06897950e-01,\n",
       "        1.02031541e+00, 1.16240594e+00, 5.85063941e-01, 5.10403579e-01,\n",
       "        6.08983162e-01, 8.35876454e-01, 4.86076480e-01, 1.29268766e+00,\n",
       "        7.58429348e-01, 7.52207123e-01, 8.27892883e-01, 6.53893819e-01,\n",
       "        6.70130630e-01, 6.92959496e-01, 6.80960430e-01, 5.08854145e-01,\n",
       "        8.15326252e-01, 7.42131613e-01, 7.32058234e-01, 8.63171974e-01,\n",
       "        6.54860429e-01, 6.55847880e-01, 7.59345493e-01, 7.76187916e-01,\n",
       "        8.37942536e-01, 8.76370962e-01, 1.10378853e+00, 9.66093003e-01,\n",
       "        1.15977051e+00, 7.80507900e-01, 1.35537095e+00, 1.28293708e+00,\n",
       "        1.27185421e+00, 1.19595913e+00, 6.46765413e-01, 1.05521329e+00,\n",
       "        7.39322604e-01, 7.89601017e-01, 9.14122260e-01, 5.68383921e-01,\n",
       "        9.23017898e-01, 1.24731458e+00, 7.76544826e-01, 7.17058336e-01,\n",
       "        5.18449251e-01, 8.65356225e-01, 9.31461256e-01, 1.01078035e+00,\n",
       "        9.63804968e-01, 1.02526964e+00, 1.12607167e+00, 4.34246179e-01,\n",
       "        7.58919598e-01, 6.56890295e-01, 8.98463763e-01, 1.08727585e+00,\n",
       "        7.15948379e-01, 7.76679903e-01, 7.81938146e-01, 4.79053707e-01,\n",
       "        6.60774999e-01, 8.25964480e-01, 5.59056089e-01, 4.89148765e-01,\n",
       "        7.66575723e-01, 8.00089549e-01, 5.57311887e-01, 1.01711605e+00,\n",
       "        1.30766169e+00, 1.52192092e+00, 1.89061813e+00, 1.58604036e+00,\n",
       "        1.84188541e+00, 9.27093414e-01, 1.31265694e+00, 1.70600756e+00,\n",
       "        1.73643880e+00, 1.54777014e+00, 5.21934691e-01, 1.37425201e+00,\n",
       "        7.28339534e-01, 1.69080795e+00, 1.02099417e+00, 9.38450411e-01,\n",
       "        9.68735036e-01, 1.54601873e+00, 9.27797695e-01, 8.24695364e-01,\n",
       "        1.04652453e+00, 1.44201682e+00, 1.15154662e+00, 1.39534760e+00,\n",
       "        7.52497452e-01, 1.05766869e+00, 1.31898475e+00, 7.88098255e-01,\n",
       "        1.16283952e+00, 1.12781716e+00, 9.63284295e-01, 1.20656332e+00,\n",
       "        1.43363523e+00, 7.89505730e-01, 1.09725418e+00, 8.26464315e-01,\n",
       "        8.72205331e-01, 1.13812031e+00, 1.09614628e+00, 1.15246944e+00,\n",
       "        1.04719438e+00, 9.56703303e-01, 1.18101590e+00, 1.34905576e+00,\n",
       "        1.26202273e+00, 1.48338065e+00, 1.15604761e+00, 1.19972161e+00,\n",
       "        1.28014969e+00, 1.98587669e+00, 1.92923387e+00, 1.56913302e+00,\n",
       "        9.47244966e-01, 1.27997689e+00, 1.03796429e+00, 1.01678340e+00,\n",
       "        1.54968627e+00, 1.43406056e+00, 1.63155841e+00, 1.60575776e+00,\n",
       "        1.20611555e+00, 1.19325199e+00, 9.88365723e-01, 1.34482901e+00,\n",
       "        1.50303782e+00, 1.57333504e+00, 1.45630123e+00, 1.26339763e+00,\n",
       "        1.20500100e+00, 1.20994905e+00, 1.26123537e+00, 1.20583684e+00,\n",
       "        1.36124314e+00, 1.41746208e+00, 1.28479289e+00, 1.16746604e+00,\n",
       "        9.92769727e-01, 1.14155741e+00, 1.03693271e+00, 1.36054458e+00,\n",
       "        1.17726505e+00, 1.16346733e+00, 1.16805915e+00, 1.01861402e+00,\n",
       "        1.52492841e+00, 1.48314055e+00, 1.38947007e+00, 1.24237830e+00,\n",
       "        1.31630770e+00, 1.28322060e+00, 1.16864194e+00, 1.27512023e+00,\n",
       "        1.36848537e+00, 1.37992943e+00, 1.26410759e+00, 1.06549008e+00,\n",
       "        1.41402268e+00, 1.34638284e+00, 1.84051784e+00, 1.27824729e+00,\n",
       "        1.42261685e+00, 1.39433257e+00, 1.29839202e+00, 1.71813443e+00,\n",
       "        7.94697489e-01, 1.71931759e+00, 1.65938150e+00, 1.27986360e+00,\n",
       "        1.55372155e+00, 1.10703484e+00, 1.35290309e+00, 1.15317545e+00,\n",
       "        1.48031770e+00, 1.29914265e+00, 1.30931796e+00, 1.54481798e+00,\n",
       "        1.53347180e+00, 1.24169265e+00, 1.42106265e+00, 9.47802086e-01,\n",
       "        1.30241446e+00, 1.23768879e+00, 1.15313488e+00, 1.14726320e+00,\n",
       "        2.34936501e+00, 1.96888068e+00, 1.81403189e+00, 2.41728249e+00,\n",
       "        1.25611986e+00, 1.37104539e+00, 1.73661178e+00, 1.53258953e+00,\n",
       "        1.41310373e+00, 1.20864272e+00, 1.39778694e+00, 1.22867988e+00,\n",
       "        9.70532459e-01, 1.19711125e+00, 1.34575267e+00, 1.39878752e+00,\n",
       "        1.34986843e+00, 1.57344838e+00, 1.92654113e+00, 9.14458593e-01,\n",
       "        1.36383715e+00, 1.16893132e+00, 1.17417742e+00, 1.20600512e+00,\n",
       "        1.18513160e+00, 1.43156811e+00, 1.20113190e+00, 1.46925226e+00,\n",
       "        1.48301409e+00, 1.32237222e+00, 1.71577291e+00, 2.24121416e+00,\n",
       "        2.63125647e+00, 7.83565922e-01, 1.39416644e+00, 1.32710293e+00,\n",
       "        1.13238058e+00, 1.79888095e+00, 1.20341124e+00, 1.13906837e+00,\n",
       "        1.31391930e+00, 1.37866155e+00, 7.17493064e-01, 4.59693804e-01]),\n",
       " 'mean_score_time': array([0.91963847, 0.96650648, 1.01336424, 0.89700516, 0.9495643 ,\n",
       "        0.97659485, 0.98197548, 0.93483305, 0.79220533, 0.95818377,\n",
       "        0.98659476, 0.87578861, 0.90323321, 0.9197584 , 0.90603399,\n",
       "        0.88343183, 0.7879413 , 0.81931822, 0.83834696, 0.86857406,\n",
       "        0.72378596, 0.8130153 , 0.83455292, 0.8123103 , 0.74067156,\n",
       "        0.85156345, 0.82378189, 0.86193228, 0.73333549, 0.7800444 ,\n",
       "        0.78935417, 0.8141226 , 0.7572666 , 0.78136587, 0.7614998 ,\n",
       "        0.75878811, 0.73135654, 0.77585848, 0.80710268, 0.79668601,\n",
       "        0.70401597, 0.73331928, 0.72723087, 0.74461595, 0.69687319,\n",
       "        0.74461508, 0.78392641, 0.73940921, 0.71948926, 0.76362602,\n",
       "        0.73823524, 0.71162438, 0.70171642, 0.7447331 , 0.74982532,\n",
       "        0.71560407, 0.68589592, 0.68125804, 0.73420366, 0.76544372,\n",
       "        0.70816684, 0.67171518, 0.72378929, 0.70816763, 0.71032   ,\n",
       "        0.72811882, 0.70816644, 0.7853876 , 0.74300345, 0.70730249,\n",
       "        0.71371198, 0.73166172, 0.70640143, 0.70274075, 0.6982166 ,\n",
       "        0.7372841 , 0.742541  , 0.7356805 , 0.69325384, 0.72379176,\n",
       "        0.75157118, 0.77344124, 0.71374631, 0.72595127, 0.74982365,\n",
       "        0.70816851, 0.73420254, 0.72378858, 0.69774938, 0.67692208,\n",
       "        0.67692431, 0.7193346 , 0.7289923 , 0.70816747, 0.72754566,\n",
       "        0.70816946, 0.70816978, 0.71537169, 0.72292209, 0.76544182,\n",
       "        0.69167566, 0.69502004, 0.67762415, 0.70332503, 0.70521339,\n",
       "        0.72389332, 0.73764809, 0.74802621, 0.70295954, 0.71337104,\n",
       "        0.73332206, 0.73432461, 0.67337513, 0.66130129, 0.68646439,\n",
       "        0.71314534, 0.69232368, 0.70296001, 0.68761722, 0.73940992,\n",
       "        0.6982921 , 0.68386348, 0.66429885, 0.82613436, 0.66130193,\n",
       "        0.66996702, 0.68126464, 0.67045482, 0.66763449, 0.64598862,\n",
       "        0.68261154, 0.68213113, 0.67435543, 0.69775192, 0.71858112,\n",
       "        0.68125621, 0.64742192, 0.67692256, 0.73940889, 0.75814684,\n",
       "        0.68186084, 0.68964823, 0.7239902 , 0.68733811, 0.64655153,\n",
       "        0.70932937, 0.71337295, 0.72933825, 0.64714146, 0.70727897,\n",
       "        0.69254533, 0.66696779, 0.69812997, 0.70296137, 0.67919215,\n",
       "        0.73762019, 0.648597  , 0.73420119, 0.74461722, 0.69775367,\n",
       "        0.6855735 , 0.68213185, 0.70816549, 0.71858128, 0.64568448,\n",
       "        0.69567227, 0.66684588, 0.71337422, 0.75850677, 0.80189522,\n",
       "        0.7654438 , 0.7706519 , 0.72722586, 0.72291652, 0.73200194,\n",
       "        0.72681729, 0.77064912, 0.75503071, 0.77375213, 0.72811882,\n",
       "        0.78106642, 0.70640167, 0.76023897, 0.80831067, 0.73750742,\n",
       "        0.75539788, 0.79148046, 0.72031951, 0.78453732, 0.76023769,\n",
       "        0.7360901 , 0.7531569 , 0.76544404, 0.76023817, 0.75502936,\n",
       "        0.73747921, 0.76312502, 0.77499096, 0.74689833, 0.75417932,\n",
       "        0.79668625, 0.72291573, 0.7550296 , 0.75668057, 0.78627054,\n",
       "        0.75098793, 0.73420087, 0.75087325, 0.73067617, 0.71271189,\n",
       "        0.74289107, 0.71460191, 0.73763188, 0.73420294, 0.72619176,\n",
       "        0.73922936, 0.71328012, 0.75327174, 0.76544468, 0.71300395,\n",
       "        0.73763418, 0.72536119, 0.72899501, 0.75806626, 0.7116069 ,\n",
       "        0.7333312 , 0.69775414, 0.71419263, 0.74982444, 0.72259776,\n",
       "        0.77065094, 0.70883139, 0.76463405, 0.76964299, 0.73073665,\n",
       "        0.74982246, 0.7349089 , 0.75242694, 0.72379073, 0.71857913,\n",
       "        0.7150596 , 0.71683073, 0.70488238, 0.71250017, 0.72484279,\n",
       "        0.68991152, 0.77585896, 0.72926792, 0.75470956, 0.70729168,\n",
       "        0.71386401, 0.72724231, 0.69111053, 0.68713339, 0.69359525,\n",
       "        0.71158353, 0.71858358, 0.75502841, 0.73456891, 0.73419984,\n",
       "        0.73960892, 0.76890667, 0.71337255, 0.76544785, 0.71895409,\n",
       "        0.70314177, 0.73940873, 0.70442716, 0.73904276, 0.73766478,\n",
       "        0.73699633, 0.74867845, 0.72553619, 0.68098521, 0.67481184,\n",
       "        0.70433704, 0.7012976 , 0.68125836, 0.65298438, 0.73854423,\n",
       "        0.70816684, 0.69315386, 0.69076149, 0.70143207, 0.70394309,\n",
       "        0.73043911, 0.72663927, 0.74800237, 0.69775089, 0.71858048,\n",
       "        0.73332365, 0.73140693, 0.7550265 , 0.69254708, 0.67011595,\n",
       "        0.73827728, 0.67944503, 0.77644324, 0.72944371, 0.68928742,\n",
       "        0.68871427, 0.6845065 , 0.67515103, 0.67692367, 0.65581274,\n",
       "        0.73021444, 0.71226239, 0.71508797, 0.68387024, 0.76766753,\n",
       "        0.74035494, 0.67818697, 0.66399407, 0.69078358, 0.69167105,\n",
       "        0.72058169, 0.70167001, 0.68733811, 0.70172652, 0.70295922,\n",
       "        0.71621577, 0.68280959, 0.68733907, 0.6847233 , 0.76544309,\n",
       "        0.69254486, 0.67692415, 0.72899413, 0.71291908, 0.76960786,\n",
       "        0.66516916, 0.70639777, 0.69297123, 0.71636009, 0.69354884,\n",
       "        0.7029597 , 0.76502045, 0.69478861, 0.71382777, 0.78423285,\n",
       "        0.72922889, 0.74446289, 0.70337876, 0.72219801, 0.74555119,\n",
       "        0.75565712, 0.76559329, 0.76094325, 0.76040196, 0.75151475,\n",
       "        0.73533829, 0.76386817, 0.73447935, 0.76542894, 0.77399341,\n",
       "        0.75836261, 0.7731754 , 0.7293272 , 0.80710228, 0.79148022,\n",
       "        0.75505193, 0.73890336, 0.74280071, 0.77781574, 0.77802499,\n",
       "        0.72724072, 0.77024221, 0.7984314 , 0.82272188, 0.74522424,\n",
       "        0.74389259, 0.81543509, 0.75417209, 0.74805435, 0.73420231,\n",
       "        0.76833614, 0.73877088, 0.76577218, 0.6997149 , 0.72970271,\n",
       "        0.74668948, 0.79732911, 0.7333324 , 0.7558372 , 0.67585206,\n",
       "        0.68646208, 0.72722785, 0.72725193, 0.75328763, 0.71342055,\n",
       "        0.7367382 , 0.72398448, 0.69811519, 0.72601151, 0.73764062,\n",
       "        0.76563819, 0.75131162, 0.80253919, 0.70968175, 0.73853755,\n",
       "        0.75627915, 0.75503087, 0.7376705 , 0.74387813, 0.74693735,\n",
       "        0.79799453, 0.7027878 , 0.75849287, 0.73123058, 0.74455754,\n",
       "        0.73762671, 0.73670236, 0.77519202, 0.79848433, 0.72756179,\n",
       "        0.73941072, 0.75846465, 0.78689766, 0.71711357, 0.70880898,\n",
       "        0.72899683, 0.70730654, 0.71373789, 0.78627459, 0.73482577,\n",
       "        0.73420254, 0.71646198, 0.72378961, 0.72368121, 0.71337461,\n",
       "        0.7790215 , 0.70209535, 0.70817137, 0.68646391, 0.71337446,\n",
       "        0.69254486, 0.7127889 , 0.72121604, 0.70714951, 0.71250923,\n",
       "        0.73941247, 0.71685576, 0.72354499, 0.71343573, 0.73245899,\n",
       "        0.7081666 , 0.86550705, 0.75036605, 0.73431865, 0.72287226,\n",
       "        0.72384222, 0.74768933, 0.73973163, 0.87042967, 0.70816557,\n",
       "        0.72366238, 0.72032404, 0.71330889, 0.71886905, 0.71803006,\n",
       "        0.74716886, 0.68125129, 0.718515  , 0.67605281, 0.71337493,\n",
       "        0.72227446, 0.74508707, 0.72378914, 0.68977404, 0.72291565,\n",
       "        0.73246193, 0.69818068, 0.70816652, 0.71877925, 0.6801877 ,\n",
       "        0.70640874, 0.68124398, 0.7073036 , 0.68389829, 0.77064959,\n",
       "        0.69826579, 0.6916647 , 0.68062282, 0.71700382, 0.72766081,\n",
       "        0.73274589, 0.71099226, 0.73420382, 0.89261349, 0.85025112,\n",
       "        0.7076176 , 0.72851221, 0.70356154, 0.76457636, 0.70150256,\n",
       "        0.72963683, 0.69188039, 0.7324628 , 0.71250558, 0.72966115,\n",
       "        0.71573814, 0.7309312 , 0.79216329, 0.6651051 , 0.72064281,\n",
       "        0.77599406, 0.77576184, 0.77082102, 0.77065142, 0.74387566,\n",
       "        0.72379009, 0.74229614, 0.74461516, 0.76767747, 0.8166248 ,\n",
       "        0.7705876 , 0.75367808, 0.7342031 , 0.73941072, 0.7717429 ,\n",
       "        0.76612655, 0.78695997, 0.74344595, 0.78106674, 0.77367147,\n",
       "        0.78373988, 0.74521875, 0.74286461, 0.79090285, 0.76148502,\n",
       "        0.76544444, 0.78106411, 0.81231133, 0.76372147, 0.78230898,\n",
       "        0.77499048, 0.80803402, 0.77125049, 0.78106594, 0.82792958,\n",
       "        0.79707964, 0.7843341 , 0.82603073, 0.77605089, 0.71983091,\n",
       "        0.73244818, 0.73420143, 0.72203   , 0.7751557 , 0.75353297,\n",
       "        0.74963069, 0.73148338, 0.70843418, 0.75415047, 0.75521382,\n",
       "        0.75725174, 0.77103885, 0.74447036, 0.73765484, 0.74982309,\n",
       "        0.74894977, 0.74432731, 0.7492768 , 0.78291353, 0.7486221 ,\n",
       "        0.74806412, 0.74982476, 0.75936222, 0.76331186, 0.76460147,\n",
       "        0.78348517, 0.7623171 , 0.7897222 , 0.7758588 , 0.76286896,\n",
       "        0.75055035, 0.75678531, 0.78239481, 0.76957027, 0.79581269,\n",
       "        0.74982905, 0.76023833, 0.75014806, 0.809244  , 0.77321442,\n",
       "        0.74818349, 0.72899508, 0.71985857, 0.72293766, 0.75218876,\n",
       "        0.7472287 , 0.76469302, 0.74982484, 0.72748089, 0.70728676,\n",
       "        0.72721076, 0.73420191, 0.74635196, 0.76437163, 0.73591781,\n",
       "        0.73449222, 0.75271082, 0.73411139, 0.74177051, 0.76035873,\n",
       "        0.71702655, 0.79401135, 0.75503   , 0.76023817, 0.69973516,\n",
       "        0.75133228, 0.7244002 , 0.73855448, 0.75321937, 0.72918963,\n",
       "        0.72899445, 0.73489833, 0.76454488, 0.74914519, 0.75100652,\n",
       "        0.75097315, 0.77586015, 0.75936119, 0.7662739 , 0.77171008,\n",
       "        0.76544635, 0.75503079, 0.74461706, 0.71142268, 0.69640485,\n",
       "        0.70295906, 0.74282781, 0.72622967, 0.77082133, 0.73940857,\n",
       "        0.73630198, 0.69167757, 0.71858048, 0.72412769, 0.76544555,\n",
       "        0.73805134, 0.75861843, 0.74878224, 0.73416249, 0.73833219,\n",
       "        0.71875453, 0.74461587, 0.77660998, 0.73480392, 0.72378834,\n",
       "        0.71858176, 0.73420389, 0.73511608, 0.74332619, 0.73193407,\n",
       "        0.73563369, 0.7409447 , 0.72899628, 0.72888215, 0.7361091 ,\n",
       "        0.7438666 , 0.75324217, 0.75708795, 0.73420421, 0.73489118,\n",
       "        0.75503238, 0.78362791, 0.75915178, 0.7185808 , 0.70177571,\n",
       "        0.65387384, 0.61713799, 0.83676203, 0.85742299, 0.93714213,\n",
       "        0.89714622, 0.86880692, 0.81746133, 0.7726802 , 0.82703964,\n",
       "        0.85817719, 0.87655195, 0.98049339, 0.87008794, 0.85347684,\n",
       "        0.81310217, 0.8634944 , 0.86929774, 0.87009645, 0.87070624,\n",
       "        0.89448698, 0.8421727 , 0.81078537, 0.85441875, 0.86176888,\n",
       "        0.88034797, 0.8873771 , 0.86438012, 0.88409193, 0.864381  ,\n",
       "        0.84992337, 0.85074441, 0.87363148, 0.87440006, 0.88006488,\n",
       "        0.88398274, 0.85308083, 0.85157879, 0.85829171, 0.83870371,\n",
       "        0.85917123, 0.8355341 , 0.80187217, 0.76456022, 0.86930482,\n",
       "        0.87110249, 0.88937958, 0.89952405, 0.90470084, 0.83429495,\n",
       "        0.80464037, 0.84456182, 0.8848501 , 0.87960291, 0.90677786,\n",
       "        0.85538999, 0.85366782, 0.8061138 , 0.84320927, 0.88024116,\n",
       "        0.8797915 , 0.89613406, 0.90118901, 0.85472282, 0.84062831,\n",
       "        0.86861022, 0.88063399, 0.86571407, 0.87479424, 0.88779704,\n",
       "        0.86526577, 0.82704663, 0.85828177, 0.84786328, 0.85934552,\n",
       "        0.88000099, 0.86870758, 0.86659185, 0.89113196, 0.86566114,\n",
       "        0.87392481, 0.86804112, 0.86260732, 0.82855042, 0.79580673,\n",
       "        0.78116035, 0.86159094, 0.8637414 , 0.87993018, 0.89457448,\n",
       "        0.86634541, 0.82791305, 0.78526799, 0.84876116, 0.85919333,\n",
       "        0.88521242, 0.89506229, 0.86416348, 0.83857369, 0.80905946,\n",
       "        0.87161287, 0.88351885, 0.87233353, 0.8900044 , 0.85917385,\n",
       "        0.95079478, 0.75931756, 0.8162605 , 0.83834473, 0.87024061,\n",
       "        0.87369212, 0.87326884, 0.84875822, 0.83305836, 0.85683187,\n",
       "        0.86459041, 0.87489629, 0.86935178, 0.89159632, 0.85311174,\n",
       "        0.8534809 , 0.85253334, 0.85907952, 0.86841861, 0.94399651,\n",
       "        0.84481478, 0.80541277, 0.82032196, 0.85307225, 0.87909953,\n",
       "        0.92859721, 0.90777   , 0.86352452, 0.8239553 , 0.77229659,\n",
       "        0.85158038, 0.87392394, 0.95232924, 0.88863118, 0.86871314,\n",
       "        0.8478783 , 0.79665526, 0.88000186, 0.87411634, 0.88226469,\n",
       "        0.90038172, 0.85431377, 0.83898886, 0.81098946, 0.86922089,\n",
       "        0.89171576, 0.87821015, 0.87034623, 0.85968113, 0.87479536,\n",
       "        0.89931297, 0.85668349, 0.84791215, 0.86278788, 0.91887609,\n",
       "        0.87015589, 0.86207589, 0.83190767, 0.8383313 , 0.85962351,\n",
       "        0.87333457, 0.81924446, 0.76517081, 0.56955671, 0.49269636]),\n",
       " 'std_score_time': array([1.84414941e-02, 1.60262328e-02, 3.01685798e-02, 1.17418115e-01,\n",
       "        1.06434852e-01, 7.03722664e-02, 2.16690100e-02, 7.54852374e-02,\n",
       "        3.58281536e-02, 1.13722315e-02, 1.94821915e-02, 7.22966687e-02,\n",
       "        4.82106881e-02, 3.02507468e-02, 1.27552284e-02, 3.81375121e-02,\n",
       "        7.14647160e-02, 7.01582145e-02, 1.79509207e-02, 1.54941346e-02,\n",
       "        2.94567134e-02, 1.36306590e-02, 6.36389331e-03, 6.37734166e-02,\n",
       "        1.10481405e-02, 3.96503148e-02, 2.33062763e-02, 1.66749413e-02,\n",
       "        1.38316153e-02, 1.38244250e-02, 1.90013066e-02, 7.36367261e-03,\n",
       "        2.51420372e-02, 7.21146786e-03, 1.08028261e-02, 1.92023566e-02,\n",
       "        1.69225215e-02, 4.47948993e-02, 1.47269518e-02, 2.20909054e-02,\n",
       "        2.42278388e-02, 1.16910484e-02, 6.11488961e-03, 2.65517356e-02,\n",
       "        3.32423624e-02, 1.94824677e-02, 1.64302225e-02, 1.47289751e-02,\n",
       "        2.44055102e-02, 3.24825968e-02, 4.04822087e-02, 1.41485627e-02,\n",
       "        1.23082732e-02, 7.45866604e-03, 2.58500671e-06, 2.17877801e-02,\n",
       "        1.45566674e-02, 1.92855121e-02, 3.37449918e-02, 1.27575644e-02,\n",
       "        3.20984071e-02, 1.27561046e-02, 2.65482288e-02, 1.47297054e-02,\n",
       "        1.68883518e-02, 4.38239814e-02, 7.36518988e-03, 4.06112397e-02,\n",
       "        1.41869569e-02, 2.82343986e-02, 7.65225458e-03, 1.29061014e-02,\n",
       "        2.53396217e-02, 2.88507672e-02, 2.49164789e-02, 2.32584938e-02,\n",
       "        6.70907230e-02, 3.89563112e-02, 6.91844350e-03, 7.36041525e-03,\n",
       "        2.46963674e-03, 3.61394554e-02, 2.05032618e-02, 8.77209974e-02,\n",
       "        2.20885454e-02, 1.47274576e-02, 2.20932656e-02, 1.47286939e-02,\n",
       "        1.94824676e-02, 1.47261091e-02, 7.36080694e-03, 1.18427842e-02,\n",
       "        1.94816606e-02, 7.36479671e-03, 4.17042582e-02, 3.68193184e-02,\n",
       "        7.36637020e-03, 5.50028768e-02, 2.77425054e-02, 1.27526977e-02,\n",
       "        3.09745516e-02, 2.31705828e-02, 1.37352650e-02, 3.32426770e-02,\n",
       "        3.18506544e-03, 1.45736498e-02, 4.37735987e-02, 2.18085132e-02,\n",
       "        2.55078288e-02, 5.15473298e-02, 2.55404214e-02, 3.55858809e-02,\n",
       "        1.07891149e-02, 7.36547090e-03, 3.25322100e-02, 2.92966678e-02,\n",
       "        1.51762650e-02, 1.03008599e-06, 2.51686848e-02, 7.36474031e-03,\n",
       "        1.04529618e-02, 2.70048907e-02, 1.59912577e-03, 1.55931168e-01,\n",
       "        1.47265024e-02, 2.08554970e-02, 1.53740171e-02, 2.17906965e-02,\n",
       "        2.34094141e-02, 7.80025774e-03, 2.85731620e-02, 1.94826801e-02,\n",
       "        3.00921695e-02, 7.36434706e-03, 3.37447710e-02, 8.59975538e-03,\n",
       "        1.76978170e-02, 2.65522655e-02, 1.94841460e-02, 4.14472557e-02,\n",
       "        7.29743447e-03, 3.68740333e-02, 7.63401157e-03, 2.20906806e-02,\n",
       "        1.01743246e-02, 4.44391441e-02, 1.47293122e-02, 3.27805849e-02,\n",
       "        8.88895706e-03, 2.04485212e-02, 1.47289188e-02, 1.52613181e-02,\n",
       "        4.12632696e-02, 1.27532817e-02, 3.02036186e-02, 3.10951038e-02,\n",
       "        1.14905796e-02, 1.27557151e-02, 2.65520785e-02, 2.65519382e-02,\n",
       "        1.16946416e-02, 3.89633211e-02, 1.47286939e-02, 2.55077314e-02,\n",
       "        2.65505823e-02, 2.69853331e-02, 7.61335070e-03, 3.21007406e-02,\n",
       "        3.80472002e-02, 7.36400979e-03, 1.27560071e-02, 1.47278509e-02,\n",
       "        6.11303510e-03, 2.77530483e-02, 2.52196858e-02, 3.14789306e-02,\n",
       "        1.47253785e-02, 2.65505667e-02, 8.66868875e-03, 2.06590386e-02,\n",
       "        1.27535738e-02, 8.87926354e-03, 7.36631380e-03, 4.01578523e-02,\n",
       "        6.80077894e-03, 9.78830051e-03, 7.36333542e-03, 1.06973676e-02,\n",
       "        1.29887579e-02, 7.36372879e-03, 2.63385922e-02, 3.77190159e-02,\n",
       "        1.78416128e-06, 1.94832960e-02, 7.36395357e-03, 2.31858289e-03,\n",
       "        3.19251139e-02, 8.59621509e-03, 1.14736509e-02, 1.52552093e-02,\n",
       "        1.27561046e-02, 8.05197002e-03, 3.20974532e-02, 9.69473049e-03,\n",
       "        7.36530227e-03, 3.26904992e-02, 2.20970307e-02, 2.68061458e-02,\n",
       "        1.36970389e-02, 2.03678047e-02, 2.59760514e-02, 1.70304276e-02,\n",
       "        2.53352826e-02, 2.20919169e-02, 2.32690929e-02, 1.37167623e-04,\n",
       "        2.65878401e-02, 2.53439428e-02, 1.27538657e-02, 3.10629047e-02,\n",
       "        1.85495117e-02, 1.92170847e-02, 7.36468412e-03, 1.71760772e-02,\n",
       "        1.72081654e-02, 1.38457073e-02, 1.47299864e-02, 2.14940611e-02,\n",
       "        2.55102622e-02, 1.40623512e-02, 1.94825102e-02, 3.16986713e-02,\n",
       "        1.48310659e-02, 1.89017210e-02, 3.07611982e-02, 1.27548391e-02,\n",
       "        2.26082124e-02, 6.38569292e-03, 4.10013134e-02, 1.27528926e-02,\n",
       "        2.70728315e-02, 2.08534177e-02, 1.93732204e-02, 3.99064808e-02,\n",
       "        1.83797640e-02, 1.60022534e-02, 7.36513368e-03, 1.89089824e-02,\n",
       "        7.11458719e-03, 2.57073062e-02, 1.98104177e-02, 1.83161309e-02,\n",
       "        1.67598912e-02, 2.30098538e-02, 8.84875910e-03, 1.41391575e-02,\n",
       "        3.82630572e-02, 1.94836996e-02, 4.54932717e-02, 1.27538657e-02,\n",
       "        1.49404444e-02, 2.88597367e-02, 7.36361639e-03, 1.27547418e-02,\n",
       "        3.32274873e-02, 1.25335714e-02, 3.89655725e-02, 1.45897332e-02,\n",
       "        2.91026448e-02, 1.92865866e-02, 1.17195776e-02, 1.33408062e-02,\n",
       "        1.76889836e-02, 1.31120532e-02, 1.64712267e-02, 1.57889672e-02,\n",
       "        7.97888992e-03, 6.83203583e-03, 4.88736150e-02, 2.57182769e-02,\n",
       "        1.94851440e-02, 1.51574914e-02, 2.14548139e-02, 2.15679621e-03,\n",
       "        2.50336536e-02, 3.25885434e-02, 2.35013852e-02, 2.14773173e-02,\n",
       "        1.94836997e-02, 2.20921979e-02, 1.16941632e-02, 1.41029469e-02,\n",
       "        7.36327930e-03, 1.94824677e-02, 1.62796818e-02, 3.96527002e-02,\n",
       "        1.15242697e-02, 3.32463022e-02, 3.16302056e-02, 2.74251892e-02,\n",
       "        1.46182590e-02, 2.00870756e-02, 6.85349425e-03, 2.65509252e-02,\n",
       "        7.51465465e-03, 3.12575159e-03, 1.76408665e-02, 4.89808717e-03,\n",
       "        4.90718568e-03, 7.36254868e-03, 6.83028313e-03, 1.34049280e-02,\n",
       "        1.43472536e-02, 6.82703014e-03, 8.05274881e-03, 1.41261125e-04,\n",
       "        3.33275743e-02, 2.20911864e-02, 2.83126232e-02, 2.97360213e-07,\n",
       "        3.60256210e-02, 1.94516595e-02, 5.15042996e-07, 2.06716885e-02,\n",
       "        4.41840586e-02, 1.47258841e-02, 7.36260488e-03, 1.94825314e-02,\n",
       "        3.72727180e-02, 4.48316121e-03, 1.57598505e-02, 6.82281655e-03,\n",
       "        3.16151969e-02, 1.20894448e-02, 1.82380504e-02, 4.89903609e-07,\n",
       "        2.54569972e-02, 2.36283808e-02, 1.17339896e-02, 1.93109104e-02,\n",
       "        7.03121825e-03, 3.90099263e-02, 3.47278158e-02, 2.12332996e-02,\n",
       "        2.96476667e-02, 3.24556265e-02, 1.21686616e-02, 1.57298222e-02,\n",
       "        7.87707740e-03, 2.40668112e-02, 7.28576531e-03, 1.14369087e-02,\n",
       "        2.22890983e-02, 1.27751898e-02, 2.19941987e-02, 1.00160019e-02,\n",
       "        7.36232389e-03, 1.95782002e-02, 1.47265585e-02, 7.36198672e-03,\n",
       "        1.91346098e-02, 2.03547586e-02, 1.61659521e-02, 9.07046068e-03,\n",
       "        1.84421684e-02, 6.12286940e-03, 1.18953269e-02, 2.34054162e-02,\n",
       "        7.36384119e-03, 2.59639909e-02, 4.23928323e-03, 3.47379219e-02,\n",
       "        1.83398423e-02, 1.28152038e-02, 1.07214749e-06, 3.28577575e-02,\n",
       "        1.65407212e-02, 3.34476705e-02, 4.58878051e-03, 3.87890271e-02,\n",
       "        1.06292354e-02, 7.36445933e-03, 1.38366567e-02, 4.09311816e-02,\n",
       "        3.56801079e-02, 1.23434350e-03, 3.09575896e-02, 2.57120360e-02,\n",
       "        2.88584465e-02, 1.47929257e-02, 7.36372879e-03, 1.48752585e-02,\n",
       "        7.63472681e-03, 1.15804368e-02, 3.07049907e-02, 2.22264496e-02,\n",
       "        3.51581751e-02, 3.94276782e-02, 1.11467460e-02, 1.59640463e-02,\n",
       "        4.59358096e-02, 7.36507772e-03, 2.06475836e-02, 1.45462538e-02,\n",
       "        3.38681324e-02, 2.67423133e-02, 1.11120428e-02, 2.62372729e-02,\n",
       "        2.52616807e-02, 2.65791719e-02, 6.82231338e-03, 2.04822592e-02,\n",
       "        3.40439654e-02, 7.36372912e-03, 8.99918662e-03, 1.47263337e-02,\n",
       "        2.56982149e-02, 4.31371819e-02, 2.41685764e-02, 1.51828712e-02,\n",
       "        2.65501770e-02, 8.04303231e-03, 6.84948105e-03, 1.94814694e-02,\n",
       "        1.79393531e-02, 2.20911302e-02, 2.01378734e-02, 1.94818517e-02,\n",
       "        2.12918678e-02, 7.36423455e-03, 1.00945224e-01, 2.08595994e-02,\n",
       "        7.36120409e-03, 1.28136938e-02, 7.36226775e-03, 1.47277386e-02,\n",
       "        1.67605313e-02, 1.89111213e-02, 2.10715762e-02, 6.83714307e-03,\n",
       "        2.65515330e-02, 2.08716252e-02, 2.83701646e-02, 1.89836932e-02,\n",
       "        2.44494012e-02, 1.94823402e-02, 4.72296974e-02, 2.15443473e-02,\n",
       "        2.30324542e-02, 3.09167185e-02, 1.46481092e-02, 2.15472964e-02,\n",
       "        1.94025100e-02, 3.71226393e-02, 7.36597667e-03, 1.79294186e-02,\n",
       "        1.06895180e-02, 7.31752475e-03, 2.23758974e-03, 1.27780998e-02,\n",
       "        1.27555204e-02, 1.34815967e-02, 3.37758584e-02, 8.04961949e-03,\n",
       "        1.47292559e-02, 3.38378565e-02, 3.89360450e-02, 3.68184191e-02,\n",
       "        9.93665162e-03, 8.05116341e-03, 1.22967770e-03, 1.95473931e-02,\n",
       "        1.94838270e-02, 2.22355503e-02, 6.11150560e-03, 3.11090002e-02,\n",
       "        6.82236167e-03, 2.62395987e-02, 1.26604444e-02, 7.36580807e-03,\n",
       "        2.00407351e-02, 1.59798933e-02, 2.70860858e-02, 3.43141460e-03,\n",
       "        3.57577142e-02, 5.28127294e-02, 2.94637866e-02, 1.27541579e-02,\n",
       "        1.79696036e-02, 2.22545676e-02, 7.78297597e-03, 1.03483175e-02,\n",
       "        8.50524077e-04, 2.27319867e-02, 1.65957545e-03, 6.37713937e-03,\n",
       "        7.95461114e-03, 2.44531748e-02, 1.92926322e-02, 1.50324242e-02,\n",
       "        1.18956824e-02, 3.55282584e-02, 1.94830836e-02, 1.47485959e-02,\n",
       "        2.91538200e-03, 6.92987544e-03, 1.94584551e-02, 1.50343573e-02,\n",
       "        7.36451553e-03, 1.98536124e-02, 2.65504576e-02, 1.06410116e-02,\n",
       "        7.36243628e-03, 7.58699987e-03, 8.06822133e-03, 1.46812494e-02,\n",
       "        1.56226219e-02, 1.27565911e-02, 7.36518988e-03, 1.44031999e-02,\n",
       "        1.19283893e-02, 3.13258314e-02, 2.83824815e-03, 1.27574671e-02,\n",
       "        8.16626321e-03, 3.37593466e-02, 1.96628967e-02, 6.12781485e-03,\n",
       "        4.16969208e-02, 1.38697461e-02, 1.27584404e-02, 2.20933221e-02,\n",
       "        2.55053955e-02, 1.28099104e-02, 8.75418163e-04, 8.60177891e-03,\n",
       "        7.41611174e-03, 1.38816548e-02, 2.20927036e-02, 2.55080234e-02,\n",
       "        1.32358434e-02, 3.10006316e-02, 3.72507431e-02, 8.97756697e-03,\n",
       "        7.59487303e-03, 1.28156750e-02, 1.27530871e-02, 4.87464832e-03,\n",
       "        2.96193924e-02, 3.05775500e-02, 9.93319040e-03, 1.57229998e-02,\n",
       "        1.98408848e-02, 3.00963136e-02, 2.23609771e-02, 3.04882507e-02,\n",
       "        1.96913131e-02, 1.79642545e-02, 1.34871039e-02, 7.78671819e-07,\n",
       "        1.38398734e-02, 1.77493663e-02, 2.17575418e-02, 7.66467122e-03,\n",
       "        1.05037948e-02, 2.44384997e-02, 3.37429316e-02, 6.83051110e-03,\n",
       "        3.74668625e-03, 2.46516674e-02, 7.47566880e-03, 2.33534928e-03,\n",
       "        6.12090252e-03, 7.36518988e-03, 3.64764537e-02, 2.26061089e-02,\n",
       "        6.62482330e-03, 2.55778834e-02, 1.79299846e-02, 1.17001162e-02,\n",
       "        1.27530882e-02, 7.36552706e-03, 1.23589705e-02, 3.79810733e-02,\n",
       "        6.57272868e-03, 1.25131988e-02, 1.94839332e-02, 2.74068146e-02,\n",
       "        6.15237346e-03, 1.16669863e-02, 8.28398611e-03, 2.03468920e-02,\n",
       "        2.55095808e-02, 1.59081270e-02, 1.41487961e-02, 1.82962571e-02,\n",
       "        1.27550337e-02, 3.07563085e-02, 2.66094880e-02, 2.09851953e-02,\n",
       "        4.10230065e-04, 1.64230452e-02, 1.43055658e-02, 2.94833962e-02,\n",
       "        3.15143936e-02, 1.01325924e-02, 1.27556178e-02, 2.65490704e-02,\n",
       "        7.36389795e-03, 4.56298651e-03, 1.15139648e-02, 1.51786221e-02,\n",
       "        6.15563156e-03, 8.93254336e-03, 7.85732791e-03, 7.36530267e-03,\n",
       "        1.31849980e-02, 2.55405739e-02, 3.43828288e-02, 2.29731398e-02,\n",
       "        5.16061134e-03, 7.36361650e-03, 2.06573851e-02, 1.97565832e-02,\n",
       "        1.55292983e-02, 1.27548391e-02, 1.94822340e-02, 1.94831898e-02,\n",
       "        1.38992904e-02, 9.27090178e-03, 1.85701393e-06, 1.62878368e-02,\n",
       "        2.95640241e-02, 1.94402390e-02, 3.20990904e-02, 1.30344279e-02,\n",
       "        1.59508963e-02, 2.20955697e-02, 1.49722037e-02, 2.20918046e-02,\n",
       "        1.99422898e-02, 2.63052741e-02, 3.08487921e-02, 1.95537029e-02,\n",
       "        2.76079274e-02, 2.43608804e-04, 1.94809596e-02, 7.11175939e-03,\n",
       "        2.62390454e-02, 7.36299825e-03, 2.55076341e-02, 8.77806426e-07,\n",
       "        2.30568652e-02, 1.81429320e-02, 1.01051882e-02, 2.02383641e-03,\n",
       "        1.70542127e-02, 7.36524607e-03, 1.48115376e-02, 3.28351407e-02,\n",
       "        8.24509426e-03, 4.37588727e-02, 2.86465587e-02, 1.27542551e-02,\n",
       "        2.46708320e-02, 1.47270080e-02, 3.21002379e-02, 2.03246761e-02,\n",
       "        2.08152149e-06, 3.53159003e-02, 9.38036410e-03, 1.09095151e-02,\n",
       "        5.87836149e-03, 2.56295214e-02, 6.45208615e-02, 5.18289915e-03,\n",
       "        3.06467899e-02, 7.28865148e-03, 7.91558333e-03, 2.27487796e-02,\n",
       "        1.34571159e-02, 3.43812069e-02, 9.05230134e-02, 7.87852452e-03,\n",
       "        1.64681809e-02, 1.05414911e-02, 1.41443250e-02, 1.72829075e-02,\n",
       "        7.74673018e-03, 1.43823787e-02, 7.90663995e-03, 1.29030129e-02,\n",
       "        1.09400994e-02, 3.20694892e-02, 1.32797978e-02, 2.20823244e-02,\n",
       "        3.23804085e-02, 1.47281319e-02, 6.71608101e-03, 3.21000445e-02,\n",
       "        1.17718121e-02, 1.49069842e-02, 2.51841992e-02, 2.52657432e-02,\n",
       "        6.32237571e-03, 2.02043697e-02, 1.85556626e-02, 1.08498708e-02,\n",
       "        1.38498740e-02, 1.52377154e-02, 1.27553258e-02, 2.94453759e-02,\n",
       "        7.93795250e-03, 2.27428932e-02, 1.66757008e-02, 1.55227795e-02,\n",
       "        1.24523888e-02, 4.26815291e-03, 2.11881904e-02, 4.44841326e-03,\n",
       "        2.25973269e-02, 5.49824918e-03, 2.28048734e-02, 2.04460133e-02,\n",
       "        2.15850742e-02, 1.43780245e-02, 3.86120029e-02, 1.94066661e-02,\n",
       "        1.18755554e-02, 2.68241568e-02, 1.92022773e-02, 7.66450231e-03,\n",
       "        2.64154383e-02, 9.94466526e-03, 1.64671800e-02, 8.70478727e-03,\n",
       "        1.45097246e-02, 1.60314061e-02, 1.27558124e-02, 8.83070505e-03,\n",
       "        1.53773198e-02, 1.38494664e-02, 1.38611359e-02, 8.06950357e-03,\n",
       "        1.44980670e-02, 2.94566572e-02, 1.53932611e-02, 1.78726258e-02,\n",
       "        2.20912426e-02, 1.65227341e-02, 2.44544187e-02, 6.55025396e-03,\n",
       "        1.92871867e-02, 1.27848363e-02, 1.24591704e-03, 1.18323842e-02,\n",
       "        1.48496820e-02, 1.95157126e-02, 7.25841866e-03, 1.60550542e-02,\n",
       "        3.19377216e-02, 1.27778174e-02, 8.12959640e-03, 7.36283005e-03,\n",
       "        1.27553606e-02, 1.47257720e-02, 8.50740737e-03, 1.64774667e-02,\n",
       "        1.74486392e-02, 1.35571252e-02, 3.51813842e-02, 1.61080759e-02,\n",
       "        2.00566293e-02, 4.90588582e-03, 1.27541579e-02, 1.41834449e-01,\n",
       "        1.34258505e-02, 1.93882981e-02, 7.36502135e-03, 2.63087210e-02,\n",
       "        2.38522809e-02, 1.29358809e-02, 1.47293120e-02, 7.42117597e-03,\n",
       "        3.87627752e-03, 1.94315268e-02, 9.83440165e-03, 2.03868894e-02,\n",
       "        1.13392552e-02, 1.35193603e-02, 2.04339179e-02, 9.39183515e-03,\n",
       "        1.34308098e-04, 3.51764909e-02, 3.15365748e-02, 2.38770326e-02,\n",
       "        1.14923282e-02, 5.69610811e-02, 6.81996255e-03, 1.97647298e-02,\n",
       "        3.19060073e-02, 3.30262295e-02, 1.95225639e-02, 8.37308481e-03,\n",
       "        7.48015093e-03, 5.72573565e-03, 2.65836021e-02, 7.28830175e-03,\n",
       "        2.15237863e-02, 6.82990127e-03, 1.83121430e-02, 1.27546309e-02,\n",
       "        7.36282965e-03, 1.16004380e-02, 2.51026618e-02, 2.34720512e-02,\n",
       "        1.90178597e-02, 1.96764796e-02, 1.28976250e-02, 6.70173086e-03,\n",
       "        1.27851857e-02, 1.34602423e-02, 1.71636861e-02, 1.12753031e-02,\n",
       "        1.27563964e-02, 7.34545138e-02, 1.30147194e-02, 1.98197302e-02,\n",
       "        3.87773988e-02, 6.99537463e-02, 2.27465704e-02, 1.61300345e-02,\n",
       "        2.50517996e-02, 1.47068337e-02, 2.27277162e-02, 1.45796277e-02,\n",
       "        4.14971836e-02, 1.92427731e-02, 2.80938509e-02, 2.17318797e-02]),\n",
       " 'param_max_depth': masked_array(data=[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4,\n",
       "                    4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3,\n",
       "                    3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    20, 20, 20, 20, 20, 20, 20, 50, 50, 50, 50, 50, 50, 50,\n",
       "                    2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 10, 10, 10, 10, 10, 10, 10, 20, 20, 20, 20,\n",
       "                    20, 20, 20, 50, 50, 50, 50, 50, 50, 50, 2, 2, 2, 2, 2,\n",
       "                    2, 2, 3, 3, 3, 3, 3, 3, 3, 5, 5, 5, 5, 5, 5, 5, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 20, 50, 50,\n",
       "                    50, 50, 50, 50, 50],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_split': masked_array(data=[2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350,\n",
       "                    2, 3, 5, 10, 50, 100, 350, 2, 3, 5, 10, 50, 100, 350],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500, 500, 500, 500, 500, 500, 500, 500,\n",
       "                    500, 500, 500, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 4,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 6,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 7,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 2,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 10,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 20,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 2,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 10,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 50,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 100,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 50,\n",
       "   'min_samples_split': 350,\n",
       "   'n_estimators': 500}],\n",
       " 'split0_test_score': array([0.82419758, 0.82419758, 0.82351715, 0.82499349, 0.82655714,\n",
       "        0.82633111, 0.82251669, 0.8248464 , 0.8248464 , 0.8248464 ,\n",
       "        0.8243567 , 0.82478521, 0.82298946, 0.82444259, 0.82548275,\n",
       "        0.82548275, 0.82548275, 0.82548275, 0.82517701, 0.82607565,\n",
       "        0.82327788, 0.82349875, 0.82349875, 0.82349875, 0.82349875,\n",
       "        0.82497526, 0.82482816, 0.82343742, 0.82134837, 0.82134837,\n",
       "        0.82134837, 0.82134837, 0.82231383, 0.82482816, 0.82171757,\n",
       "        0.82378694, 0.82378694, 0.82378694, 0.82378694, 0.82378694,\n",
       "        0.82378694, 0.82120658, 0.82542161, 0.82542161, 0.82419758,\n",
       "        0.82550091, 0.82517701, 0.8268261 , 0.82672212, 0.8240567 ,\n",
       "        0.8240567 , 0.8240567 , 0.82694807, 0.82609374, 0.82525636,\n",
       "        0.82401376, 0.826399  , 0.826399  , 0.826399  , 0.826399  ,\n",
       "        0.82507289, 0.8267651 , 0.8237502 , 0.82458333, 0.82458333,\n",
       "        0.82458333, 0.82458333, 0.82438135, 0.825605  , 0.82529932,\n",
       "        0.82595348, 0.82595348, 0.82595348, 0.82595348, 0.82722785,\n",
       "        0.82827024, 0.82595348, 0.82554387, 0.82554387, 0.82554387,\n",
       "        0.82554387, 0.82554387, 0.82554387, 0.8243201 , 0.82327788,\n",
       "        0.82327788, 0.8219078 , 0.82511584, 0.82450383, 0.82517701,\n",
       "        0.82629499, 0.82295253, 0.82295253, 0.82295253, 0.82450383,\n",
       "        0.82327788, 0.82619097, 0.82472402, 0.82227674, 0.82227674,\n",
       "        0.82227674, 0.82227674, 0.82407504, 0.8238666 , 0.82349875,\n",
       "        0.82460801, 0.82460801, 0.82460801, 0.82460801, 0.82358461,\n",
       "        0.82554387, 0.82474871, 0.82321652, 0.82321652, 0.82321652,\n",
       "        0.82321652, 0.82307532, 0.82305085, 0.82438135, 0.8231367 ,\n",
       "        0.8231367 , 0.8231367 , 0.8231367 , 0.8231367 , 0.8231367 ,\n",
       "        0.82376857, 0.82638094, 0.82638094, 0.82454678, 0.82370726,\n",
       "        0.8263199 , 0.82401376, 0.8227683 , 0.82482816, 0.82482816,\n",
       "        0.82482816, 0.82577019, 0.8263199 , 0.82511584, 0.82558684,\n",
       "        0.82417926, 0.82417926, 0.82417926, 0.82417926, 0.82332082,\n",
       "        0.82609374, 0.82664309, 0.82550091, 0.82550091, 0.82550091,\n",
       "        0.82550091, 0.82540344, 0.82485287, 0.82446088, 0.82705204,\n",
       "        0.82705204, 0.82705204, 0.82705204, 0.82479167, 0.82613672,\n",
       "        0.8231367 , 0.8240567 , 0.8240567 , 0.8240567 , 0.8240567 ,\n",
       "        0.8240567 , 0.8240567 , 0.82619778, 0.82747869, 0.82747869,\n",
       "        0.82528113, 0.82629499, 0.82591051, 0.82562315, 0.82566611,\n",
       "        0.82501171, 0.82501171, 0.82501171, 0.82834891, 0.82723493,\n",
       "        0.82536047, 0.82502993, 0.82641706, 0.82641706, 0.82641706,\n",
       "        0.82641706, 0.82694807, 0.82470576, 0.82741776, 0.8273927 ,\n",
       "        0.8273927 , 0.8273927 , 0.8273927 , 0.82731383, 0.825605  ,\n",
       "        0.82344353, 0.82554387, 0.82554387, 0.82554387, 0.82554387,\n",
       "        0.8248464 , 0.82629499, 0.82584942, 0.82584942, 0.82584942,\n",
       "        0.82584942, 0.82584942, 0.82584942, 0.82584942, 0.82584942,\n",
       "        0.82582458, 0.82582458, 0.82505467, 0.82497526, 0.82536047,\n",
       "        0.82556203, 0.82686909, 0.82786204, 0.82786204, 0.82786204,\n",
       "        0.8274357 , 0.82578832, 0.82543978, 0.8251588 , 0.82751455,\n",
       "        0.82751455, 0.82751455, 0.82751455, 0.82548275, 0.82521997,\n",
       "        0.82519521, 0.82597159, 0.82597159, 0.82597159, 0.82597159,\n",
       "        0.82733177, 0.82652106, 0.8267651 , 0.82753247, 0.82753247,\n",
       "        0.82753247, 0.82753247, 0.82833108, 0.82607565, 0.82589239,\n",
       "        0.82800166, 0.82800166, 0.82800166, 0.82800166, 0.82800166,\n",
       "        0.82800166, 0.82854918, 0.82307532, 0.82307532, 0.82786204,\n",
       "        0.82601457, 0.82548275, 0.82577019, 0.82215378, 0.82607565,\n",
       "        0.82607565, 0.82607565, 0.82474871, 0.82603267, 0.82686909,\n",
       "        0.82376857, 0.82662507, 0.82662507, 0.82662507, 0.82662507,\n",
       "        0.82700904, 0.82419758, 0.82436305, 0.82462628, 0.82462628,\n",
       "        0.82462628, 0.82462628, 0.82401376, 0.82456506, 0.82370726,\n",
       "        0.82625884, 0.82625884, 0.82625884, 0.82625884, 0.825605  ,\n",
       "        0.82460801, 0.82401376, 0.82425884, 0.82425884, 0.82425884,\n",
       "        0.82425884, 0.82425884, 0.82425884, 0.82378694, 0.82609374,\n",
       "        0.82609374, 0.82644198, 0.8287138 , 0.82713098, 0.82562315,\n",
       "        0.82755754, 0.82456506, 0.82456506, 0.82456506, 0.82444259,\n",
       "        0.82603267, 0.82517701, 0.82646003, 0.82767936, 0.82767936,\n",
       "        0.82767936, 0.82767936, 0.82714895, 0.82919996, 0.82411798,\n",
       "        0.82672212, 0.82672212, 0.82672212, 0.82672212, 0.8265391 ,\n",
       "        0.82745363, 0.825605  , 0.82586754, 0.82586754, 0.82586754,\n",
       "        0.82586754, 0.82719193, 0.82552571, 0.82609374, 0.82534229,\n",
       "        0.82534229, 0.82534229, 0.82534229, 0.82534229, 0.82534229,\n",
       "        0.82523817, 0.82696606, 0.82696606, 0.82576349, 0.82801952,\n",
       "        0.82680112, 0.82707001, 0.82543978, 0.82446088, 0.82446088,\n",
       "        0.82446088, 0.82592862, 0.82714895, 0.82570239, 0.82556203,\n",
       "        0.82946058, 0.82946058, 0.82946058, 0.82946058, 0.82611183,\n",
       "        0.82344353, 0.82429546, 0.82413631, 0.82413631, 0.82413631,\n",
       "        0.82413631, 0.82572722, 0.8258313 , 0.82731383, 0.82493231,\n",
       "        0.82493231, 0.82493231, 0.82493231, 0.82378694, 0.82617289,\n",
       "        0.82409337, 0.82696606, 0.82696606, 0.82696606, 0.82696606,\n",
       "        0.82696606, 0.82696606, 0.82556203, 0.82877459, 0.82877459,\n",
       "        0.825605  , 0.82580645, 0.82568425, 0.83000674, 0.82755754,\n",
       "        0.8274357 , 0.8274357 , 0.8274357 , 0.82717397, 0.82751455,\n",
       "        0.8259897 , 0.82542161, 0.82725288, 0.82725288, 0.82725288,\n",
       "        0.82725288, 0.82580645, 0.82694807, 0.82737477, 0.82647808,\n",
       "        0.82647808, 0.82647808, 0.82647808, 0.82737477, 0.82753247,\n",
       "        0.8267651 , 0.82777605, 0.82777605, 0.82777605, 0.82777605,\n",
       "        0.82698404, 0.82844537, 0.8280268 , 0.8279838 , 0.8279838 ,\n",
       "        0.8279838 , 0.8279838 , 0.8279838 , 0.8279838 , 0.8265391 ,\n",
       "        0.82548275, 0.82548275, 0.82635602, 0.82646003, 0.82627692,\n",
       "        0.82625884, 0.8274357 , 0.8263199 , 0.8263199 , 0.8263199 ,\n",
       "        0.82501171, 0.82482816, 0.82529932, 0.82627692, 0.82627692,\n",
       "        0.82627692, 0.82627692, 0.82627692, 0.8279838 , 0.82646003,\n",
       "        0.82568425, 0.82592862, 0.82592862, 0.82592862, 0.82592862,\n",
       "        0.82605077, 0.82534229, 0.82509763, 0.82558684, 0.82558684,\n",
       "        0.82558684, 0.82558684, 0.82595348, 0.82699106, 0.82556203,\n",
       "        0.82517701, 0.82517701, 0.82517701, 0.82517701, 0.82517701,\n",
       "        0.82517701, 0.82572722, 0.82584942, 0.82584942, 0.82633796,\n",
       "        0.82824507, 0.82660011, 0.82595348, 0.82885314, 0.82595348,\n",
       "        0.82595348, 0.82595348, 0.82694807, 0.82787992, 0.82601457,\n",
       "        0.8263199 , 0.82686909, 0.82686909, 0.82686909, 0.82686909,\n",
       "        0.82609374, 0.82812338, 0.82572722, 0.82680809, 0.82680809,\n",
       "        0.82680809, 0.82680809, 0.82572722, 0.8258313 , 0.82536047,\n",
       "        0.82775815, 0.82775815, 0.82775815, 0.82775815, 0.82664309,\n",
       "        0.82511584, 0.82848837, 0.82609374, 0.82609374, 0.82609374,\n",
       "        0.82609374, 0.82609374, 0.82609374, 0.82688709, 0.82800166,\n",
       "        0.82800166, 0.82713098, 0.82664309, 0.82693008, 0.8273927 ,\n",
       "        0.82617289, 0.82722785, 0.82722785, 0.82722785, 0.82786204,\n",
       "        0.82737477, 0.82897468, 0.82637408, 0.82796593, 0.82796593,\n",
       "        0.82796593, 0.82796593, 0.82594673, 0.82903544, 0.82766145,\n",
       "        0.82713098, 0.82713098, 0.82713098, 0.82713098, 0.82619097,\n",
       "        0.82698404, 0.82658208, 0.82713098, 0.82713098, 0.82713098,\n",
       "        0.82713098, 0.82856698, 0.82617289, 0.82570239, 0.82674014,\n",
       "        0.82674014, 0.82674014, 0.82674014, 0.82674014, 0.82674014,\n",
       "        0.82702703, 0.82419758, 0.82419758, 0.82644198, 0.82647808,\n",
       "        0.8268261 , 0.8267651 , 0.8282629 , 0.82895693, 0.82895693,\n",
       "        0.82895693, 0.82641706, 0.8279838 , 0.82647808, 0.82777605,\n",
       "        0.82729588, 0.82729588, 0.82729588, 0.82729588, 0.82881761,\n",
       "        0.82860999, 0.82814853, 0.82731383, 0.82731383, 0.82731383,\n",
       "        0.82731383, 0.82711301, 0.82816638, 0.82727084, 0.82761845,\n",
       "        0.82761845, 0.82761845, 0.82761845, 0.82727084, 0.82731383,\n",
       "        0.82710596, 0.82619097, 0.82619097, 0.82619097, 0.82619097,\n",
       "        0.82619097, 0.82619097, 0.8268441 , 0.82816638, 0.82816638,\n",
       "        0.82668608, 0.82816638, 0.82804466, 0.82713098, 0.82621586,\n",
       "        0.82753962, 0.82753962, 0.82753962, 0.82664309, 0.82672212,\n",
       "        0.82735682, 0.82664309, 0.82745363, 0.82745363, 0.82745363,\n",
       "        0.82745363, 0.82772236, 0.82806252, 0.82572722, 0.82694807,\n",
       "        0.82694807, 0.82694807, 0.82694807, 0.82700904, 0.82760054,\n",
       "        0.82700904, 0.82774026, 0.82774026, 0.82774026, 0.82774026,\n",
       "        0.82705204, 0.82713098, 0.82680112, 0.8273927 , 0.8273927 ,\n",
       "        0.8273927 , 0.8273927 , 0.8273927 , 0.8273927 , 0.82607565,\n",
       "        0.82625884, 0.82625884, 0.8267041 , 0.82662507, 0.82851358,\n",
       "        0.82822723, 0.82664309, 0.82556203, 0.82556203, 0.82556203,\n",
       "        0.82672212, 0.82725288, 0.82932144, 0.82580645, 0.82652106,\n",
       "        0.82652106, 0.82652106, 0.82652106, 0.82796593, 0.8268261 ,\n",
       "        0.82550091, 0.82656404, 0.82656404, 0.82656404, 0.82656404,\n",
       "        0.82731383, 0.82589239, 0.82452211, 0.82792292, 0.82792292,\n",
       "        0.82792292, 0.82792292, 0.82688709, 0.82881761, 0.82766145,\n",
       "        0.82711301, 0.82711301, 0.82711301, 0.82711301, 0.82711301,\n",
       "        0.82711301, 0.8274357 , 0.825605  , 0.825605  , 0.82519521,\n",
       "        0.82513405, 0.82537865, 0.8265391 , 0.82801952, 0.82488935,\n",
       "        0.82488935, 0.82488935, 0.82439965, 0.82533569, 0.82517701,\n",
       "        0.82556203, 0.82447917, 0.82447917, 0.82447917, 0.82447917,\n",
       "        0.82660011, 0.82556203, 0.82548275, 0.82606887, 0.82606887,\n",
       "        0.82606887, 0.82606887, 0.82501171, 0.82707001, 0.82707001,\n",
       "        0.82395247, 0.82395247, 0.82395247, 0.82395247, 0.8250911 ,\n",
       "        0.82558019, 0.82623394, 0.82647808, 0.82647808, 0.82647808,\n",
       "        0.82647808, 0.82647808, 0.82647808, 0.82519521, 0.82554387,\n",
       "        0.82554387, 0.82409337, 0.82574536, 0.82592862, 0.8268441 ,\n",
       "        0.82725288, 0.82517701, 0.82517701, 0.82517701, 0.82501171,\n",
       "        0.82621586, 0.82554387, 0.82566611, 0.82578832, 0.82578832,\n",
       "        0.82578832, 0.82578832, 0.82554387, 0.82439965, 0.82568425,\n",
       "        0.82495054, 0.82495054, 0.82495054, 0.82495054, 0.82562315,\n",
       "        0.82576349, 0.82564129, 0.82591051, 0.82591051, 0.82591051,\n",
       "        0.82591051, 0.825605  , 0.82658208, 0.82678311, 0.8268261 ,\n",
       "        0.8268261 , 0.8268261 , 0.8268261 , 0.8268261 , 0.8268261 ,\n",
       "        0.82664309, 0.82537865, 0.82537865, 0.82409337, 0.82523817,\n",
       "        0.8241117 , 0.82621586, 0.82448554, 0.826399  , 0.826399  ,\n",
       "        0.826399  , 0.82493231, 0.82372563, 0.82424053, 0.82462628,\n",
       "        0.82511584, 0.82511584, 0.82511584, 0.82511584, 0.82521997,\n",
       "        0.82525636, 0.82588566, 0.82537865, 0.82537865, 0.82537865,\n",
       "        0.82537865, 0.82499349, 0.82529932, 0.8242159 , 0.82474871,\n",
       "        0.82474871, 0.82474871, 0.82474871, 0.82450383, 0.82529932,\n",
       "        0.82519521, 0.82534229, 0.82534229, 0.82534229, 0.82534229,\n",
       "        0.82534229, 0.82534229, 0.82505467, 0.82511584, 0.82511584,\n",
       "        0.82456506, 0.82529932, 0.82496876, 0.82470576, 0.82550091,\n",
       "        0.82456506, 0.82456506, 0.82456506, 0.8243201 , 0.82499349,\n",
       "        0.8243384 , 0.82572722, 0.82536047, 0.82536047, 0.82536047,\n",
       "        0.82536047, 0.82378694, 0.8246875 , 0.8258313 , 0.82419758,\n",
       "        0.82419758, 0.82419758, 0.82419758, 0.82501171, 0.82680809,\n",
       "        0.82668608, 0.82487111, 0.82487111, 0.82487111, 0.82487111,\n",
       "        0.82425884, 0.82595348, 0.82731383, 0.82615481, 0.82615481,\n",
       "        0.82615481, 0.82615481, 0.82615481, 0.82615481, 0.82507289]),\n",
       " 'split1_test_score': array([0.98976531, 0.98976531, 0.99025358, 0.98924447, 0.98959619,\n",
       "        0.98898096, 0.98963616, 0.98954888, 0.98954888, 0.98954888,\n",
       "        0.99038292, 0.9897644 , 0.98967981, 0.98984906, 0.99003   ,\n",
       "        0.99003   , 0.99003   , 0.99003   , 0.98907104, 0.99034093,\n",
       "        0.98884037, 0.98990166, 0.98990166, 0.98990166, 0.98990166,\n",
       "        0.9902553 , 0.98989988, 0.98971983, 0.98941052, 0.98941052,\n",
       "        0.98941052, 0.98941052, 0.98984906, 0.99082164, 0.98962976,\n",
       "        0.99082164, 0.99082164, 0.99082164, 0.99082164, 0.99082164,\n",
       "        0.99082164, 0.98989453, 0.98972618, 0.98972618, 0.99029726,\n",
       "        0.98964347, 0.9901191 , 0.98977613, 0.98989899, 0.99047703,\n",
       "        0.99047703, 0.99047703, 0.98999603, 0.99077873, 0.98963616,\n",
       "        0.99047535, 0.99012607, 0.99012607, 0.99012607, 0.99012607,\n",
       "        0.99016798, 0.98920657, 0.99064348, 0.98964164, 0.98964164,\n",
       "        0.98964164, 0.98964164, 0.98977523, 0.98989988, 0.99025358,\n",
       "        0.99020732, 0.99020732, 0.99020732, 0.99020732, 0.98999162,\n",
       "        0.99047283, 0.9905115 , 0.9909139 , 0.9909139 , 0.9909139 ,\n",
       "        0.9909139 , 0.9909139 , 0.9909139 , 0.99037613, 0.99056354,\n",
       "        0.99056354, 0.98960261, 0.99074237, 0.99095681, 0.99038801,\n",
       "        0.99100291, 0.9910919 , 0.9910919 , 0.9910919 , 0.99029726,\n",
       "        0.99100529, 0.99034604, 0.99060639, 0.99086859, 0.99086859,\n",
       "        0.99086859, 0.99086859, 0.98977793, 0.99065091, 0.99090347,\n",
       "        0.99047535, 0.99047535, 0.99047535, 0.99047535, 0.9906946 ,\n",
       "        0.9910919 , 0.99165968, 0.9911317 , 0.9911317 , 0.9911317 ,\n",
       "        0.9911317 , 0.99127138, 0.99056521, 0.99073502, 0.9906987 ,\n",
       "        0.9906987 , 0.9906987 , 0.9906987 , 0.9906987 , 0.9906987 ,\n",
       "        0.99095122, 0.99161518, 0.99161518, 0.99064843, 0.99082731,\n",
       "        0.99166336, 0.99157514, 0.9917917 , 0.99082973, 0.99082973,\n",
       "        0.99082973, 0.99091791, 0.99086939, 0.99126753, 0.99104346,\n",
       "        0.99135345, 0.99135345, 0.99135345, 0.99135345, 0.99153066,\n",
       "        0.99095921, 0.99152542, 0.99113483, 0.99113483, 0.99113483,\n",
       "        0.99113483, 0.99074319, 0.99095841, 0.99099656, 0.99113561,\n",
       "        0.99113561, 0.99113561, 0.99113561, 0.99156919, 0.99117777,\n",
       "        0.99135498, 0.99144394, 0.99144394, 0.99144394, 0.99144394,\n",
       "        0.99144394, 0.99144394, 0.99095362, 0.99014518, 0.99014518,\n",
       "        0.99079417, 0.99114654, 0.99123695, 0.99075541, 0.9913212 ,\n",
       "        0.99031605, 0.99031605, 0.99031605, 0.9904007 , 0.99053072,\n",
       "        0.9909315 , 0.99140174, 0.99123695, 0.99123695, 0.99123695,\n",
       "        0.99123695, 0.99048961, 0.99127523, 0.99167291, 0.99106317,\n",
       "        0.99106317, 0.99106317, 0.99106317, 0.9911871 , 0.99092671,\n",
       "        0.99070198, 0.99105924, 0.99105924, 0.99105924, 0.99105924,\n",
       "        0.99052655, 0.99079579, 0.99132426, 0.99127446, 0.99127446,\n",
       "        0.99127446, 0.99127446, 0.99127446, 0.99127446, 0.9917603 ,\n",
       "        0.9915426 , 0.9915426 , 0.99141385, 0.99149892, 0.99079903,\n",
       "        0.99114498, 0.99140628, 0.99088066, 0.99088066, 0.99088066,\n",
       "        0.99075379, 0.99092351, 0.99057684, 0.99113874, 0.99092751,\n",
       "        0.99092751, 0.99092751, 0.99092751, 0.99166997, 0.99105845,\n",
       "        0.99123155, 0.99005369, 0.99005369, 0.99005369, 0.99005369,\n",
       "        0.99075216, 0.99167364, 0.99162331, 0.99097433, 0.99097433,\n",
       "        0.99097433, 0.99097433, 0.99109661, 0.990837  , 0.99158108,\n",
       "        0.99149218, 0.99149218, 0.99149218, 0.99149218, 0.99149218,\n",
       "        0.99149218, 0.99175449, 0.99075541, 0.99075541, 0.99119253,\n",
       "        0.99080065, 0.99132273, 0.99070771, 0.99215237, 0.99093469,\n",
       "        0.99093469, 0.99093469, 0.99136944, 0.99119253, 0.99159072,\n",
       "        0.99192873, 0.99132655, 0.99132655, 0.99132655, 0.99132655,\n",
       "        0.9915426 , 0.99193726, 0.99184411, 0.99110289, 0.99110289,\n",
       "        0.99110289, 0.99110289, 0.99088307, 0.99197955, 0.99215444,\n",
       "        0.99040408, 0.99040408, 0.99040408, 0.99040408, 0.99167291,\n",
       "        0.99185201, 0.99250309, 0.99176103, 0.99176103, 0.99176103,\n",
       "        0.99176103, 0.99176103, 0.99176103, 0.99179966, 0.99132732,\n",
       "        0.99132732, 0.99110524, 0.99111463, 0.99180545, 0.99132426,\n",
       "        0.99180761, 0.99102034, 0.99102034, 0.99102034, 0.99102271,\n",
       "        0.99163217, 0.99163438, 0.99202397, 0.99150042, 0.99150042,\n",
       "        0.99150042, 0.99150042, 0.99145826, 0.99176103, 0.99153887,\n",
       "        0.99207048, 0.99207048, 0.99207048, 0.99207048, 0.99180761,\n",
       "        0.99158776, 0.99096717, 0.99206909, 0.99206909, 0.99206909,\n",
       "        0.99206909, 0.99246729, 0.99250837, 0.99162627, 0.99229109,\n",
       "        0.99229109, 0.99229109, 0.99229109, 0.99229109, 0.99229109,\n",
       "        0.99193228, 0.99059506, 0.99059506, 0.99041505, 0.99024347,\n",
       "        0.99081036, 0.99085312, 0.99088949, 0.99054987, 0.99054987,\n",
       "        0.99054987, 0.99068541, 0.99019651, 0.99036558, 0.99114888,\n",
       "        0.99081117, 0.99081117, 0.99081117, 0.99081117, 0.9904628 ,\n",
       "        0.99023747, 0.99106553, 0.99067886, 0.99067886, 0.99067886,\n",
       "        0.99067886, 0.99063695, 0.99063036, 0.99176175, 0.99111307,\n",
       "        0.99111307, 0.99111307, 0.99111307, 0.99220573, 0.99097354,\n",
       "        0.99207467, 0.99146578, 0.99146578, 0.99146578, 0.99146578,\n",
       "        0.99146578, 0.99146578, 0.99172098, 0.99024605, 0.99024605,\n",
       "        0.99041927, 0.98989722, 0.99067804, 0.99071997, 0.99198309,\n",
       "        0.99037405, 0.99037405, 0.99037405, 0.99050466, 0.9915079 ,\n",
       "        0.99155376, 0.99119718, 0.99112166, 0.99112166, 0.99112166,\n",
       "        0.99112166, 0.99098624, 0.99045944, 0.9910235 , 0.99173118,\n",
       "        0.99173118, 0.99173118, 0.99173118, 0.99080874, 0.99058844,\n",
       "        0.99150341, 0.99159812, 0.99159812, 0.99159812, 0.99159812,\n",
       "        0.99181482, 0.9913319 , 0.99220299, 0.99155004, 0.99155004,\n",
       "        0.99155004, 0.99155004, 0.99155004, 0.99155004, 0.9919845 ,\n",
       "        0.99081601, 0.99081601, 0.99103139, 0.99055485, 0.99111854,\n",
       "        0.99116056, 0.99150192, 0.99011814, 0.99011814, 0.99011814,\n",
       "        0.99060002, 0.99107653, 0.99059175, 0.99194223, 0.99098861,\n",
       "        0.99098861, 0.99098861, 0.99098861, 0.99116367, 0.9912057 ,\n",
       "        0.99229041, 0.9906386 , 0.9906386 , 0.9906386 , 0.9906386 ,\n",
       "        0.99116445, 0.99085393, 0.99106946, 0.99216687, 0.99216687,\n",
       "        0.99216687, 0.99216687, 0.99164468, 0.99181842, 0.99172462,\n",
       "        0.99190283, 0.99190283, 0.99190283, 0.99190283, 0.99190283,\n",
       "        0.99190283, 0.99202959, 0.99038166, 0.99038166, 0.9904695 ,\n",
       "        0.99086196, 0.99129517, 0.99103297, 0.99220779, 0.99046866,\n",
       "        0.99046866, 0.99046866, 0.99077248, 0.991166  , 0.99120802,\n",
       "        0.99172681, 0.99081763, 0.99081763, 0.99081763, 0.99081763,\n",
       "        0.99064107, 0.9911201 , 0.9922972 , 0.99099257, 0.99099257,\n",
       "        0.99099257, 0.99099257, 0.99133799, 0.99094505, 0.99177118,\n",
       "        0.99125159, 0.99125159, 0.99125159, 0.99125159, 0.99164174,\n",
       "        0.99147028, 0.9928216 , 0.99207886, 0.99207886, 0.99207886,\n",
       "        0.99207886, 0.99207886, 0.99207886, 0.99207537, 0.98994865,\n",
       "        0.98994865, 0.98964367, 0.98960025, 0.98916429, 0.99020598,\n",
       "        0.99098386, 0.98981742, 0.98981742, 0.98981742, 0.98947091,\n",
       "        0.98998858, 0.98999034, 0.9908144 , 0.98934164, 0.98934164,\n",
       "        0.98934164, 0.98934164, 0.99025033, 0.98989899, 0.99129211,\n",
       "        0.98986086, 0.98986086, 0.98986086, 0.98986086, 0.98998858,\n",
       "        0.99064189, 0.99107339, 0.99073057, 0.99073057, 0.99073057,\n",
       "        0.99073057, 0.99059919, 0.99046615, 0.99159516, 0.99050967,\n",
       "        0.99050967, 0.99050967, 0.99050967, 0.99050967, 0.99050967,\n",
       "        0.99094028, 0.99047117, 0.99047117, 0.98986353, 0.98990608,\n",
       "        0.98938317, 0.99029638, 0.99124929, 0.98929918, 0.98929918,\n",
       "        0.98929918, 0.98968801, 0.99007902, 0.9902077 , 0.99081521,\n",
       "        0.98968801, 0.98968801, 0.98968801, 0.98968801, 0.98981831,\n",
       "        0.98986086, 0.99160181, 0.98929731, 0.98929731, 0.98929731,\n",
       "        0.98929731, 0.99051467, 0.99107888, 0.99103454, 0.99116445,\n",
       "        0.99116445, 0.99116445, 0.99116445, 0.99007902, 0.99099099,\n",
       "        0.99107496, 0.99099178, 0.99099178, 0.99099178, 0.99099178,\n",
       "        0.99099178, 0.99099178, 0.99199226, 0.98942936, 0.98942936,\n",
       "        0.98903989, 0.9893869 , 0.98972963, 0.99055651, 0.99125313,\n",
       "        0.98921431, 0.98921431, 0.98921431, 0.98921242, 0.99021114,\n",
       "        0.98990608, 0.99112088, 0.98925674, 0.98925674, 0.98925674,\n",
       "        0.98925674, 0.98968891, 0.99025375, 0.99077166, 0.98986353,\n",
       "        0.98986353, 0.98986353, 0.98986353, 0.98986353, 0.9904695 ,\n",
       "        0.99086036, 0.99060002, 0.99060002, 0.99060002, 0.99060002,\n",
       "        0.98994953, 0.99073301, 0.99133876, 0.99138386, 0.99138386,\n",
       "        0.99138386, 0.99138386, 0.99138386, 0.99138386, 0.99203731,\n",
       "        0.98890789, 0.98890789, 0.98912758, 0.99003818, 0.9896039 ,\n",
       "        0.98942843, 0.99051467, 0.98929918, 0.98929918, 0.98929918,\n",
       "        0.98973504, 0.98973414, 0.99003643, 0.99072813, 0.98995041,\n",
       "        0.98995041, 0.98995041, 0.98995041, 0.98951616, 0.9907322 ,\n",
       "        0.99147178, 0.98921242, 0.98921242, 0.98921242, 0.98921242,\n",
       "        0.98968982, 0.99068869, 0.99099099, 0.99047201, 0.99047201,\n",
       "        0.99047201, 0.99047201, 0.99029723, 0.99047117, 0.99238724,\n",
       "        0.99107888, 0.99107888, 0.99107888, 0.99107888, 0.99107888,\n",
       "        0.99107888, 0.99160107, 0.98627502, 0.98627502, 0.9869221 ,\n",
       "        0.9861014 , 0.98623071, 0.9865314 , 0.98808272, 0.98597334,\n",
       "        0.98597334, 0.98597334, 0.98593026, 0.98640318, 0.98687894,\n",
       "        0.98869215, 0.98571491, 0.98571491, 0.98571491, 0.98571491,\n",
       "        0.98657689, 0.98735285, 0.98895125, 0.98657454, 0.98657454,\n",
       "        0.98657454, 0.98657454, 0.98761217, 0.98696413, 0.98864881,\n",
       "        0.98752571, 0.98752571, 0.98752571, 0.98752571, 0.98709367,\n",
       "        0.98834662, 0.9893407 , 0.98856116, 0.98856116, 0.98856116,\n",
       "        0.98856116, 0.98856116, 0.98856116, 0.98981831, 0.98541357,\n",
       "        0.98541357, 0.98588718, 0.98485444, 0.9857998 , 0.9870948 ,\n",
       "        0.98864881, 0.98657571, 0.98657571, 0.98657571, 0.9854123 ,\n",
       "        0.9861014 , 0.98640318, 0.98847553, 0.98631694, 0.98631694,\n",
       "        0.98631694, 0.98631694, 0.98614571, 0.98662003, 0.98873647,\n",
       "        0.98614571, 0.98614571, 0.98614571, 0.98614571, 0.98648944,\n",
       "        0.98687779, 0.98825797, 0.98713686, 0.98713686, 0.98713686,\n",
       "        0.98713686, 0.98687664, 0.98782944, 0.98869115, 0.98826106,\n",
       "        0.98826106, 0.98826106, 0.98826106, 0.98826106, 0.98826106,\n",
       "        0.98942751, 0.98571491, 0.98571491, 0.98627382, 0.98537054,\n",
       "        0.98636125, 0.98584287, 0.9883456 , 0.98640437, 0.98640437,\n",
       "        0.98640437, 0.98541357, 0.98537054, 0.98730964, 0.98847755,\n",
       "        0.9856706 , 0.9856706 , 0.9856706 , 0.9856706 , 0.98575673,\n",
       "        0.98657571, 0.98830435, 0.98653375, 0.98653375, 0.98653375,\n",
       "        0.98653375, 0.9861014 , 0.98627502, 0.98821777, 0.98657689,\n",
       "        0.98657689, 0.98657689, 0.98657689, 0.98653258, 0.98735285,\n",
       "        0.9892558 , 0.98826106, 0.98826106, 0.98826106, 0.98826106,\n",
       "        0.98826106, 0.98826106, 0.98921147, 0.98593026, 0.98593026,\n",
       "        0.98605952, 0.98532623, 0.98571366, 0.98644631, 0.98852086,\n",
       "        0.98511242, 0.98511242, 0.98511242, 0.98494042, 0.98593026,\n",
       "        0.98657571, 0.98769864, 0.98562879, 0.98562879, 0.98562879,\n",
       "        0.98562879, 0.98554269, 0.98597334, 0.9883023 , 0.98545534,\n",
       "        0.98545534, 0.98545534, 0.98545534, 0.98610261, 0.98696527,\n",
       "        0.98821571, 0.98653375, 0.98653375, 0.98653375, 0.98653375,\n",
       "        0.98705049, 0.98683462, 0.98873548, 0.98778512, 0.98778512,\n",
       "        0.98778512, 0.98778512, 0.98778512, 0.98778512, 0.98899654]),\n",
       " 'split2_test_score': array([0.98884922, 0.98884922, 0.98888987, 0.98810258, 0.98758256,\n",
       "        0.98779789, 0.98753249, 0.98797939, 0.98797939, 0.98797939,\n",
       "        0.98824151, 0.98766194, 0.9879688 , 0.9880134 , 0.988284  ,\n",
       "        0.988284  , 0.988284  , 0.988284  , 0.98801551, 0.98814403,\n",
       "        0.98845306, 0.98749229, 0.98749229, 0.98749229, 0.98749229,\n",
       "        0.98827987, 0.98857974, 0.98779574, 0.98832548, 0.98832548,\n",
       "        0.98832548, 0.98832548, 0.98888889, 0.98757381, 0.98766085,\n",
       "        0.98858981, 0.98858981, 0.98858981, 0.98858981, 0.98858981,\n",
       "        0.98858981, 0.9885402 , 0.98810887, 0.98810887, 0.98788493,\n",
       "        0.98832753, 0.98867392, 0.98840848, 0.98796986, 0.98828503,\n",
       "        0.98828503, 0.98828503, 0.98793377, 0.98849967, 0.98898678,\n",
       "        0.98889085, 0.98854424, 0.98854424, 0.98854424, 0.98854424,\n",
       "        0.98762605, 0.98911655, 0.98862735, 0.98831621, 0.98831621,\n",
       "        0.98831621, 0.98831621, 0.98840235, 0.98770438, 0.98915248,\n",
       "        0.9889761 , 0.9889761 , 0.9889761 , 0.9889761 , 0.98841971,\n",
       "        0.98932981, 0.98898096, 0.98832239, 0.98832239, 0.98832239,\n",
       "        0.98832239, 0.98832239, 0.98832239, 0.98884332, 0.98946069,\n",
       "        0.98946069, 0.98981526, 0.98889868, 0.98876206, 0.98902939,\n",
       "        0.98876107, 0.98932981, 0.98932981, 0.98932981, 0.9895071 ,\n",
       "        0.98941799, 0.98911559, 0.98937811, 0.98942265, 0.98942265,\n",
       "        0.98942265, 0.98942265, 0.98928335, 0.98920372, 0.98941799,\n",
       "        0.98915822, 0.98915822, 0.98915822, 0.98915822, 0.98903229,\n",
       "        0.9894644 , 0.98945511, 0.98950895, 0.98950895, 0.98950895,\n",
       "        0.98950895, 0.98955533, 0.98994798, 0.98863436, 0.98959527,\n",
       "        0.98959527, 0.98959527, 0.98959527, 0.98959527, 0.98959527,\n",
       "        0.9891477 , 0.98968072, 0.98968072, 0.98945883, 0.99003615,\n",
       "        0.98981347, 0.98962976, 0.98972437, 0.98955349, 0.98955349,\n",
       "        0.98955349, 0.989907  , 0.98986159, 0.98929091, 0.98963433,\n",
       "        0.99029726, 0.99029726, 0.99029726, 0.99029726, 0.98955073,\n",
       "        0.99034264, 0.98981437, 0.98916109, 0.98916109, 0.98916109,\n",
       "        0.98916109, 0.98924826, 0.98950062, 0.98932981, 0.99047451,\n",
       "        0.99047451, 0.99047451, 0.99047451, 0.989072  , 0.98959986,\n",
       "        0.99007805, 0.99016885, 0.99016885, 0.99016885, 0.99016885,\n",
       "        0.99016885, 0.99016885, 0.9893753 , 0.9894848 , 0.9894848 ,\n",
       "        0.99057352, 0.99031946, 0.99044852, 0.98965259, 0.98991412,\n",
       "        0.99001188, 0.99001188, 0.99001188, 0.98992211, 0.98991589,\n",
       "        0.98992122, 0.99052655, 0.99018097, 0.99018097, 0.99018097,\n",
       "        0.99018097, 0.99071017, 0.99049128, 0.99069952, 0.99057352,\n",
       "        0.99057352, 0.99057352, 0.99057352, 0.98991856, 0.9904007 ,\n",
       "        0.98978604, 0.99084588, 0.99084588, 0.99084588, 0.99084588,\n",
       "        0.99009988, 0.98969889, 0.99061715, 0.99061715, 0.99061715,\n",
       "        0.99061715, 0.99061715, 0.99061715, 0.99061715, 0.99039055,\n",
       "        0.99070935, 0.99070935, 0.99049045, 0.98987765, 0.99097354,\n",
       "        0.99035794, 0.99092591, 0.99088387, 0.99088387, 0.99088387,\n",
       "        0.98975239, 0.99062046, 0.99031008, 0.99035625, 0.99089029,\n",
       "        0.99089029, 0.99089029, 0.99089029, 0.99018356, 0.99110681,\n",
       "        0.99030922, 0.99075297, 0.99075297, 0.99075297, 0.99075297,\n",
       "        0.9910148 , 0.99045189, 0.99061633, 0.99010075, 0.99010075,\n",
       "        0.99010075, 0.99010075, 0.99066491, 0.99035794, 0.99075053,\n",
       "        0.99132579, 0.99132579, 0.99132579, 0.99132579, 0.99132579,\n",
       "        0.99132579, 0.99070771, 0.99088628, 0.99088628, 0.99053572,\n",
       "        0.99032031, 0.99041168, 0.99032031, 0.99092591, 0.99019306,\n",
       "        0.99019306, 0.99019306, 0.99088949, 0.98971067, 0.99097433,\n",
       "        0.99140628, 0.99036812, 0.99036812, 0.99036812, 0.99036812,\n",
       "        0.99089269, 0.99075704, 0.99118943, 0.99097592, 0.99097592,\n",
       "        0.99097592, 0.99097592, 0.99080551, 0.99066984, 0.99075786,\n",
       "        0.99018875, 0.99018875, 0.99018875, 0.99018875, 0.99023661,\n",
       "        0.99049296, 0.99101322, 0.9907118 , 0.9907118 , 0.9907118 ,\n",
       "        0.9907118 , 0.9907118 , 0.9907118 , 0.99092511, 0.99045189,\n",
       "        0.99045189, 0.99132732, 0.99084668, 0.99128444, 0.99197955,\n",
       "        0.99180761, 0.99102587, 0.99102587, 0.99102587, 0.99084668,\n",
       "        0.99075623, 0.9918105 , 0.99198026, 0.99110837, 0.99110837,\n",
       "        0.99110837, 0.99110837, 0.99088949, 0.99084829, 0.99180472,\n",
       "        0.99145901, 0.99145901, 0.99145901, 0.99145901, 0.99172317,\n",
       "        0.99150266, 0.99145299, 0.99159146, 0.99159146, 0.99159146,\n",
       "        0.99159146, 0.99119563, 0.99145751, 0.99119176, 0.99145676,\n",
       "        0.99145676, 0.99145676, 0.99145676, 0.99145676, 0.99145676,\n",
       "        0.9917166 , 0.99058844, 0.99058844, 0.99080874, 0.99016077,\n",
       "        0.99011814, 0.99019909, 0.99136944, 0.99019823, 0.99019823,\n",
       "        0.99019823, 0.99050716, 0.99055236, 0.98980757, 0.99107025,\n",
       "        0.98933134, 0.98933134, 0.98933134, 0.98933134, 0.99055236,\n",
       "        0.9907265 , 0.99093469, 0.99050549, 0.99050549, 0.99050549,\n",
       "        0.99050549, 0.99015817, 0.99050215, 0.99154781, 0.99054904,\n",
       "        0.99054904, 0.99054904, 0.99054904, 0.9899407 , 0.9903732 ,\n",
       "        0.99045357, 0.99063283, 0.99063283, 0.99063283, 0.99063283,\n",
       "        0.99063283, 0.99063283, 0.99163732, 0.98985463, 0.98985463,\n",
       "        0.9906386 , 0.98963549, 0.98998331, 0.99050633, 0.99124312,\n",
       "        0.98916049, 0.98916049, 0.98916049, 0.99033222, 0.99094426,\n",
       "        0.99024947, 0.99124621, 0.99016163, 0.99016163, 0.99016163,\n",
       "        0.99016163, 0.99007117, 0.99120493, 0.99063119, 0.99067968,\n",
       "        0.99067968, 0.99067968, 0.99067968, 0.99028785, 0.99055402,\n",
       "        0.99146427, 0.99046363, 0.99046363, 0.99046363, 0.99046363,\n",
       "        0.98998331, 0.99111697, 0.99107261, 0.99177263, 0.99177263,\n",
       "        0.99177263, 0.99177263, 0.99177263, 0.99177263, 0.99137476,\n",
       "        0.99007466, 0.99007466, 0.99046699, 0.99068296, 0.99024605,\n",
       "        0.99063942, 0.99146653, 0.9909023 , 0.9909023 , 0.9909023 ,\n",
       "        0.99042263, 0.99042432, 0.9901138 , 0.99107104, 0.99055236,\n",
       "        0.99055236, 0.99055236, 0.99055236, 0.99033222, 0.99046447,\n",
       "        0.99181194, 0.99085875, 0.99085875, 0.99085875, 0.99085875,\n",
       "        0.99055402, 0.99085955, 0.99129058, 0.99094665, 0.99094665,\n",
       "        0.99094665, 0.99094665, 0.99055402, 0.99011554, 0.99154855,\n",
       "        0.9908991 , 0.9908991 , 0.9908991 , 0.9908991 , 0.9908991 ,\n",
       "        0.9908991 , 0.992031  , 0.9903825 , 0.9903825 , 0.99059754,\n",
       "        0.99072813, 0.9909902 , 0.99059423, 0.9915959 , 0.99037743,\n",
       "        0.99037743, 0.99037743, 0.99016336, 0.99072813, 0.99050883,\n",
       "        0.99137779, 0.9907741 , 0.9907741 , 0.9907741 , 0.9907741 ,\n",
       "        0.99029126, 0.99068459, 0.99133495, 0.99059671, 0.99059671,\n",
       "        0.99059671, 0.99059671, 0.9909007 , 0.99064024, 0.99216549,\n",
       "        0.99076842, 0.99076842, 0.99076842, 0.99076842, 0.99155599,\n",
       "        0.99107653, 0.99093788, 0.99085634, 0.99085634, 0.99085634,\n",
       "        0.99085634, 0.99085634, 0.99085634, 0.99155524, 0.98908134,\n",
       "        0.98908134, 0.98921053, 0.99011988, 0.98916334, 0.98907559,\n",
       "        0.99098703, 0.98973054, 0.98973054, 0.98973054, 0.98920674,\n",
       "        0.98942379, 0.99003293, 0.99055319, 0.98981831, 0.98981831,\n",
       "        0.98981831, 0.98981831, 0.98946999, 0.99029212, 0.99064024,\n",
       "        0.98964367, 0.98964367, 0.98964367, 0.98964367, 0.98990254,\n",
       "        0.98981473, 0.99046447, 0.99073139, 0.99073139, 0.99073139,\n",
       "        0.99073139, 0.98999122, 0.98990342, 0.99059506, 0.99046699,\n",
       "        0.99046699, 0.99046699, 0.99046699, 0.99046699, 0.99046699,\n",
       "        0.99085714, 0.98921053, 0.98921053, 0.98838687, 0.98916809,\n",
       "        0.98925203, 0.98807854, 0.99086036, 0.98864881, 0.98864881,\n",
       "        0.98864881, 0.98942751, 0.98968891, 0.98916714, 0.99077166,\n",
       "        0.98964458, 0.98964458, 0.98964458, 0.98964458, 0.98903413,\n",
       "        0.98968801, 0.99077248, 0.98995129, 0.98995129, 0.98995129,\n",
       "        0.98995129, 0.98886258, 0.98972783, 0.99107575, 0.99025204,\n",
       "        0.99025204, 0.99025204, 0.99025204, 0.98964276, 0.98908038,\n",
       "        0.99050633, 0.99094585, 0.99094585, 0.99094585, 0.99094585,\n",
       "        0.99094585, 0.99094585, 0.99125082, 0.9892558 , 0.9892558 ,\n",
       "        0.98934164, 0.98912662, 0.98947184, 0.98929449, 0.99081682,\n",
       "        0.98864782, 0.98864782, 0.98864782, 0.98964731, 0.98960025,\n",
       "        0.98903605, 0.99063942, 0.98908134, 0.98908134, 0.98908134,\n",
       "        0.98908134, 0.98899268, 0.98929543, 0.99033732, 0.98908038,\n",
       "        0.98908038, 0.98908038, 0.98908038, 0.98860549, 0.99003468,\n",
       "        0.9904695 , 0.98908038, 0.98908038, 0.98908038, 0.98908038,\n",
       "        0.98955591, 0.98951248, 0.99068459, 0.99021114, 0.99021114,\n",
       "        0.99021114, 0.99021114, 0.99021114, 0.99021114, 0.99129594,\n",
       "        0.98930106, 0.98930106, 0.98903893, 0.98860349, 0.98977756,\n",
       "        0.98964367, 0.99094585, 0.98782624, 0.98782624, 0.98782624,\n",
       "        0.98908134, 0.98873252, 0.98942658, 0.99055485, 0.98890886,\n",
       "        0.98890886, 0.98890886, 0.98890886, 0.98921336, 0.98916619,\n",
       "        0.99072894, 0.9893841 , 0.9893841 , 0.9893841 , 0.9893841 ,\n",
       "        0.98903797, 0.99016336, 0.99037997, 0.9888202 , 0.9888202 ,\n",
       "        0.9888202 , 0.9888202 , 0.9893407 , 0.98972963, 0.99068623,\n",
       "        0.98951156, 0.98951156, 0.98951156, 0.98951156, 0.98951156,\n",
       "        0.98951156, 0.99055236, 0.98558574, 0.98558574, 0.98498341,\n",
       "        0.98515543, 0.98519845, 0.98537054, 0.98782837, 0.98485311,\n",
       "        0.98485311, 0.98485311, 0.98451067, 0.98506941, 0.98588595,\n",
       "        0.98730964, 0.9849391 , 0.9849391 , 0.9849391 , 0.9849391 ,\n",
       "        0.98468252, 0.98705049, 0.9878695 , 0.98463955, 0.98463955,\n",
       "        0.98463955, 0.98463955, 0.98549965, 0.98623192, 0.98787162,\n",
       "        0.98545534, 0.98545534, 0.98545534, 0.98545534, 0.98567185,\n",
       "        0.98627502, 0.98787056, 0.98800245, 0.98800245, 0.98800245,\n",
       "        0.98800245, 0.98800245, 0.98800245, 0.98825695, 0.98442476,\n",
       "        0.98442476, 0.98494042, 0.98421007, 0.98425163, 0.9852832 ,\n",
       "        0.98700617, 0.98459659, 0.98459659, 0.98459659, 0.98463955,\n",
       "        0.98429593, 0.98584287, 0.98696185, 0.98451067, 0.98451067,\n",
       "        0.98451067, 0.98451067, 0.98451067, 0.98481145, 0.98670399,\n",
       "        0.98472416, 0.98472416, 0.98472416, 0.98472416, 0.98532751,\n",
       "        0.98593026, 0.98704709, 0.98536926, 0.98536926, 0.98536926,\n",
       "        0.98536926, 0.98571366, 0.98636125, 0.98773866, 0.98696413,\n",
       "        0.98696413, 0.98696413, 0.98696413, 0.98696413, 0.98696413,\n",
       "        0.98839094, 0.98476847, 0.98476847, 0.98519845, 0.98339508,\n",
       "        0.98390825, 0.98515543, 0.98592903, 0.98502641, 0.98502641,\n",
       "        0.98502641, 0.98494042, 0.98390965, 0.98455228, 0.98730742,\n",
       "        0.98519845, 0.98519845, 0.98519845, 0.98519845, 0.98429593,\n",
       "        0.98459524, 0.98713798, 0.98502641, 0.98502641, 0.98502641,\n",
       "        0.98502641, 0.98395256, 0.98584411, 0.98730742, 0.98545661,\n",
       "        0.98545661, 0.98545661, 0.98545661, 0.98502641, 0.9850251 ,\n",
       "        0.98752681, 0.98674831, 0.98674831, 0.98674831, 0.98674831,\n",
       "        0.98674831, 0.98674831, 0.98787162, 0.98455363, 0.98455363,\n",
       "        0.98506941, 0.98373807, 0.98403838, 0.98549965, 0.98679262,\n",
       "        0.98433887, 0.98433887, 0.98433887, 0.98360942, 0.98378096,\n",
       "        0.98429593, 0.98722324, 0.98476847, 0.98476847, 0.98476847,\n",
       "        0.98476847, 0.98459659, 0.98399546, 0.98713461, 0.98442476,\n",
       "        0.98442476, 0.98442476, 0.98442476, 0.9850251 , 0.98506941,\n",
       "        0.98674946, 0.98502641, 0.98502641, 0.98502641, 0.98502641,\n",
       "        0.98451067, 0.98536926, 0.98653258, 0.98597334, 0.98597334,\n",
       "        0.98597334, 0.98597334, 0.98597334, 0.98597334, 0.98782944]),\n",
       " 'mean_test_score': array([0.9342707 , 0.9342707 , 0.9342202 , 0.93411351, 0.93457863,\n",
       "        0.93436999, 0.93322845, 0.93412489, 0.93412489, 0.93412489,\n",
       "        0.93432704, 0.93407052, 0.93354602, 0.93410168, 0.93459892,\n",
       "        0.93459892, 0.93459892, 0.93459892, 0.93408785, 0.93485354,\n",
       "        0.93352377, 0.9336309 , 0.9336309 , 0.9336309 , 0.9336309 ,\n",
       "        0.93450348, 0.93443593, 0.933651  , 0.93302812, 0.93302812,\n",
       "        0.93302812, 0.93302812, 0.93368393, 0.93440787, 0.93300273,\n",
       "        0.93439946, 0.93439946, 0.93439946, 0.93439946, 0.93439946,\n",
       "        0.93439946, 0.93321377, 0.93441889, 0.93441889, 0.93412659,\n",
       "        0.93449064, 0.93465668, 0.93500357, 0.93486366, 0.93427292,\n",
       "        0.93427292, 0.93427292, 0.93495929, 0.93512405, 0.93462644,\n",
       "        0.93445999, 0.9350231 , 0.9350231 , 0.9350231 , 0.9350231 ,\n",
       "        0.93428897, 0.93502941, 0.93434034, 0.9341804 , 0.9341804 ,\n",
       "        0.9341804 , 0.9341804 , 0.93418631, 0.93440308, 0.9349018 ,\n",
       "        0.93504564, 0.93504564, 0.93504564, 0.93504564, 0.93521306,\n",
       "        0.93602429, 0.93514865, 0.93492672, 0.93492672, 0.93492672,\n",
       "        0.93492672, 0.93492672, 0.93492672, 0.93451318, 0.93443404,\n",
       "        0.93443404, 0.93377522, 0.93491897, 0.9347409 , 0.9348648 ,\n",
       "        0.93535299, 0.93445808, 0.93445808, 0.93445808, 0.93476939,\n",
       "        0.93456706, 0.93521753, 0.93490284, 0.93418933, 0.93418933,\n",
       "        0.93418933, 0.93418933, 0.93437878, 0.93457374, 0.93460674,\n",
       "        0.93474719, 0.93474719, 0.93474719, 0.93474719, 0.93443716,\n",
       "        0.93536673, 0.93528783, 0.93461906, 0.93461906, 0.93461906,\n",
       "        0.93461906, 0.93463401, 0.93452134, 0.93458358, 0.93447689,\n",
       "        0.93447689, 0.93447689, 0.93447689, 0.93447689, 0.93447689,\n",
       "        0.9346225 , 0.93589228, 0.93589228, 0.93488468, 0.9348569 ,\n",
       "        0.93593224, 0.93507289, 0.93476146, 0.93507046, 0.93507046,\n",
       "        0.93507046, 0.9355317 , 0.93568363, 0.93522476, 0.93542155,\n",
       "        0.93527666, 0.93527666, 0.93527666, 0.93527666, 0.93480073,\n",
       "        0.93579853, 0.93599429, 0.93526561, 0.93526561, 0.93526561,\n",
       "        0.93526561, 0.93513163, 0.93510397, 0.93492908, 0.93622072,\n",
       "        0.93622072, 0.93622072, 0.93622072, 0.93514429, 0.93563812,\n",
       "        0.93485658, 0.93522317, 0.93522317, 0.93522317, 0.93522317,\n",
       "        0.93522317, 0.93522317, 0.9355089 , 0.93570289, 0.93570289,\n",
       "        0.93554961, 0.93592033, 0.93586533, 0.93534372, 0.93563381,\n",
       "        0.93511321, 0.93511321, 0.93511321, 0.93622391, 0.93589385,\n",
       "        0.9354044 , 0.93565274, 0.93594499, 0.93594499, 0.93594499,\n",
       "        0.93594499, 0.93604928, 0.93549076, 0.93659673, 0.93634313,\n",
       "        0.93634313, 0.93634313, 0.93634313, 0.93613983, 0.93564414,\n",
       "        0.93464385, 0.93581633, 0.93581633, 0.93581633, 0.93581633,\n",
       "        0.93515761, 0.93559656, 0.93593028, 0.93591368, 0.93591368,\n",
       "        0.93591368, 0.93591368, 0.93591368, 0.93591368, 0.93600009,\n",
       "        0.93602551, 0.93602551, 0.93565299, 0.93545061, 0.93571101,\n",
       "        0.93568832, 0.93640043, 0.93654219, 0.93654219, 0.93654219,\n",
       "        0.93598062, 0.93577743, 0.93544223, 0.93555126, 0.93644411,\n",
       "        0.93644411, 0.93644411, 0.93644411, 0.93577876, 0.93579508,\n",
       "        0.93557866, 0.93559275, 0.93559275, 0.93559275, 0.93559275,\n",
       "        0.93636624, 0.93621553, 0.93633491, 0.93620252, 0.93620252,\n",
       "        0.93620252, 0.93620252, 0.93669753, 0.93575687, 0.93607467,\n",
       "        0.93693988, 0.93693988, 0.93693988, 0.93693988, 0.93693988,\n",
       "        0.93693988, 0.93700379, 0.93490567, 0.93490567, 0.9365301 ,\n",
       "        0.93571184, 0.93573905, 0.9355994 , 0.93507735, 0.93573447,\n",
       "        0.93573447, 0.93573447, 0.93566921, 0.93564529, 0.93647805,\n",
       "        0.93570119, 0.93610658, 0.93610658, 0.93610658, 0.93610658,\n",
       "        0.93648144, 0.93563063, 0.93579886, 0.93556836, 0.93556836,\n",
       "        0.93556836, 0.93556836, 0.93523411, 0.93573815, 0.93553985,\n",
       "        0.93561722, 0.93561722, 0.93561722, 0.93561722, 0.93583817,\n",
       "        0.93565099, 0.93584335, 0.93557722, 0.93557722, 0.93557722,\n",
       "        0.93557722, 0.93557722, 0.93557722, 0.9355039 , 0.93595765,\n",
       "        0.93595765, 0.93629151, 0.9368917 , 0.93674029, 0.93630899,\n",
       "        0.93705759, 0.93553709, 0.93553709, 0.93553709, 0.93543733,\n",
       "        0.93614036, 0.93620729, 0.93682142, 0.93676272, 0.93676272,\n",
       "        0.93676272, 0.93676272, 0.9364989 , 0.93726976, 0.93582053,\n",
       "        0.93675054, 0.93675054, 0.93675054, 0.93675054, 0.93668996,\n",
       "        0.93684802, 0.93600839, 0.93650936, 0.93650936, 0.93650936,\n",
       "        0.93650936, 0.93695162, 0.9364972 , 0.93630392, 0.93636338,\n",
       "        0.93636338, 0.93636338, 0.93636338, 0.93636338, 0.93636338,\n",
       "        0.93629569, 0.93604985, 0.93604985, 0.93566243, 0.93614125,\n",
       "        0.93590988, 0.93604074, 0.93589957, 0.93506966, 0.93506966,\n",
       "        0.93506966, 0.93570707, 0.93596594, 0.93529185, 0.93592706,\n",
       "        0.93653436, 0.93653436, 0.93653436, 0.93653436, 0.935709  ,\n",
       "        0.9348025 , 0.9354319 , 0.93510689, 0.93510689, 0.93510689,\n",
       "        0.93510689, 0.93550745, 0.9356546 , 0.93687446, 0.93553147,\n",
       "        0.93553147, 0.93553147, 0.93553147, 0.93531112, 0.93583988,\n",
       "        0.93554054, 0.93635489, 0.93635489, 0.93635489, 0.93635489,\n",
       "        0.93635489, 0.93635489, 0.93630678, 0.93629175, 0.93629175,\n",
       "        0.93555429, 0.93511305, 0.93544853, 0.93707768, 0.93692792,\n",
       "        0.93565674, 0.93565674, 0.93565674, 0.93600362, 0.93665557,\n",
       "        0.93593098, 0.935955  , 0.93617872, 0.93617872, 0.93617872,\n",
       "        0.93617872, 0.93562129, 0.93620415, 0.93634315, 0.93629631,\n",
       "        0.93629631, 0.93629631, 0.93629631, 0.93615712, 0.93622498,\n",
       "        0.9365776 , 0.9366126 , 0.9366126 , 0.9366126 , 0.9366126 ,\n",
       "        0.93626072, 0.93696475, 0.9371008 , 0.93710215, 0.93710215,\n",
       "        0.93710215, 0.93710215, 0.93710215, 0.93710215, 0.93663279,\n",
       "        0.93545781, 0.93545781, 0.93595147, 0.93589928, 0.9358805 ,\n",
       "        0.93601961, 0.93680138, 0.93578011, 0.93578011, 0.93578011,\n",
       "        0.93534479, 0.935443  , 0.93533496, 0.93643006, 0.9359393 ,\n",
       "        0.9359393 , 0.9359393 , 0.9359393 , 0.93649323, 0.9360434 ,\n",
       "        0.93659553, 0.93580866, 0.93580866, 0.93580866, 0.93580866,\n",
       "        0.93592308, 0.93568526, 0.93581922, 0.93623345, 0.93623345,\n",
       "        0.93623345, 0.93623345, 0.93605073, 0.93630834, 0.9362784 ,\n",
       "        0.93599298, 0.93599298, 0.93599298, 0.93599298, 0.93599298,\n",
       "        0.93599298, 0.93659594, 0.93553786, 0.93553786, 0.93580167,\n",
       "        0.93661172, 0.93629516, 0.93586023, 0.93755228, 0.93559986,\n",
       "        0.93559986, 0.93559986, 0.9359613 , 0.93659135, 0.93591047,\n",
       "        0.93647483, 0.9361536 , 0.9361536 , 0.9361536 , 0.9361536 ,\n",
       "        0.93567536, 0.93664269, 0.93645312, 0.93613246, 0.93613246,\n",
       "        0.93613246, 0.93613246, 0.93598864, 0.93580553, 0.93643238,\n",
       "        0.93659272, 0.93659272, 0.93659272, 0.93659272, 0.93661361,\n",
       "        0.93588755, 0.93741595, 0.93634298, 0.93634298, 0.93634298,\n",
       "        0.93634298, 0.93634298, 0.93634298, 0.93683923, 0.93567722,\n",
       "        0.93567722, 0.93532839, 0.93545441, 0.9350859 , 0.93555809,\n",
       "        0.93604793, 0.93559193, 0.93559193, 0.93559193, 0.93551323,\n",
       "        0.93559571, 0.93633265, 0.93591389, 0.93570862, 0.93570862,\n",
       "        0.93570862, 0.93570862, 0.93522235, 0.93640885, 0.93653127,\n",
       "        0.93554517, 0.93554517, 0.93554517, 0.93554517, 0.9353607 ,\n",
       "        0.93581356, 0.93603998, 0.93619764, 0.93619764, 0.93619764,\n",
       "        0.93619764, 0.9363858 , 0.93551415, 0.9359642 , 0.9359056 ,\n",
       "        0.9359056 , 0.9359056 , 0.9359056 , 0.9359056 , 0.9359056 ,\n",
       "        0.93627482, 0.93462643, 0.93462643, 0.93489746, 0.93518409,\n",
       "        0.93515377, 0.93504667, 0.93679085, 0.93563498, 0.93563498,\n",
       "        0.93563498, 0.93517752, 0.93591724, 0.93528431, 0.93645431,\n",
       "        0.93554282, 0.93554282, 0.93554282, 0.93554282, 0.93589001,\n",
       "        0.93605295, 0.93684094, 0.93552081, 0.93552081, 0.93552081,\n",
       "        0.93552081, 0.93549675, 0.93632437, 0.93646038, 0.93634498,\n",
       "        0.93634498, 0.93634498, 0.93634498, 0.93566421, 0.93579507,\n",
       "        0.93622908, 0.93604287, 0.93604287, 0.93604287, 0.93604287,\n",
       "        0.93604287, 0.93604287, 0.93669573, 0.93561718, 0.93561718,\n",
       "        0.93502254, 0.93555997, 0.93574871, 0.93566066, 0.93609527,\n",
       "        0.93513392, 0.93513392, 0.93513392, 0.93516761, 0.93551117,\n",
       "        0.93543299, 0.93613446, 0.9352639 , 0.9352639 , 0.9352639 ,\n",
       "        0.9352639 , 0.93546798, 0.93587057, 0.93561207, 0.93529733,\n",
       "        0.93529733, 0.93529733, 0.93529733, 0.93515935, 0.93603491,\n",
       "        0.93611297, 0.93580689, 0.93580689, 0.93580689, 0.93580689,\n",
       "        0.93551916, 0.93579216, 0.93627482, 0.93632923, 0.93632923,\n",
       "        0.93632923, 0.93632923, 0.93632923, 0.93632923, 0.93646963,\n",
       "        0.9348226 , 0.9348226 , 0.93495687, 0.93508891, 0.93596501,\n",
       "        0.93576645, 0.93603454, 0.93422915, 0.93422915, 0.93422915,\n",
       "        0.9351795 , 0.93523985, 0.93626148, 0.93569648, 0.93512678,\n",
       "        0.93512678, 0.93512678, 0.93512678, 0.93556515, 0.93557483,\n",
       "        0.93590054, 0.93505352, 0.93505352, 0.93505352, 0.93505352,\n",
       "        0.93534721, 0.93558148, 0.93529769, 0.93573838, 0.93573838,\n",
       "        0.93573838, 0.93573838, 0.93550834, 0.93633947, 0.93691164,\n",
       "        0.93590115, 0.93590115, 0.93590115, 0.93590115, 0.93590115,\n",
       "        0.93590115, 0.93652971, 0.93248859, 0.93248859, 0.93236691,\n",
       "        0.93213029, 0.93226927, 0.93281368, 0.93464354, 0.93190527,\n",
       "        0.93190527, 0.93190527, 0.93161353, 0.93226943, 0.9326473 ,\n",
       "        0.93385461, 0.93171106, 0.93171106, 0.93171106, 0.93171106,\n",
       "        0.93261984, 0.93332179, 0.93410116, 0.93242765, 0.93242765,\n",
       "        0.93242765, 0.93242765, 0.93270784, 0.93342202, 0.93453015,\n",
       "        0.93231117, 0.93231117, 0.93231117, 0.93231117, 0.93261887,\n",
       "        0.93340061, 0.93448174, 0.93434723, 0.93434723, 0.93434723,\n",
       "        0.93434723, 0.93434723, 0.93434723, 0.93442349, 0.93179407,\n",
       "        0.93179407, 0.93164032, 0.93160329, 0.93199335, 0.93307403,\n",
       "        0.93430262, 0.93211644, 0.93211644, 0.93211644, 0.93168786,\n",
       "        0.9322044 , 0.93259664, 0.93370116, 0.93220531, 0.93220531,\n",
       "        0.93220531, 0.93220531, 0.93206675, 0.93194371, 0.93370824,\n",
       "        0.93194014, 0.93194014, 0.93194014, 0.93194014, 0.93248003,\n",
       "        0.93285718, 0.93364878, 0.93280554, 0.93280554, 0.93280554,\n",
       "        0.93280554, 0.93273177, 0.93359092, 0.93440431, 0.9340171 ,\n",
       "        0.9340171 , 0.9340171 , 0.9340171 , 0.9340171 , 0.9340171 ,\n",
       "        0.93482051, 0.93195401, 0.93195401, 0.93185521, 0.93133459,\n",
       "        0.9314604 , 0.93240472, 0.93292006, 0.93260993, 0.93260993,\n",
       "        0.93260993, 0.9317621 , 0.93100194, 0.93203415, 0.93347042,\n",
       "        0.93199496, 0.93199496, 0.93199496, 0.93199496, 0.93175754,\n",
       "        0.93214244, 0.933776  , 0.93231294, 0.93231294, 0.93231294,\n",
       "        0.93231294, 0.93168248, 0.93247282, 0.93324703, 0.93226074,\n",
       "        0.93226074, 0.93226074, 0.93226074, 0.93202094, 0.93255909,\n",
       "        0.93399261, 0.93345055, 0.93345055, 0.93345055, 0.93345055,\n",
       "        0.93345055, 0.93345055, 0.93404592, 0.93186658, 0.93186658,\n",
       "        0.931898  , 0.93145454, 0.9315736 , 0.93221724, 0.93360479,\n",
       "        0.93133878, 0.93133878, 0.93133878, 0.93095664, 0.93156824,\n",
       "        0.93173668, 0.9335497 , 0.93191925, 0.93191925, 0.93191925,\n",
       "        0.93191925, 0.93130874, 0.9315521 , 0.93375607, 0.93135923,\n",
       "        0.93135923, 0.93135923, 0.93135923, 0.93204648, 0.93294759,\n",
       "        0.93388375, 0.93214376, 0.93214376, 0.93214376, 0.93214376,\n",
       "        0.93194   , 0.93271912, 0.93419396, 0.93330442, 0.93330442,\n",
       "        0.93330442, 0.93330442, 0.93330442, 0.93330442, 0.93396629]),\n",
       " 'std_test_score': array([0.07783435, 0.07783435, 0.07828086, 0.07716092, 0.07638715,\n",
       "        0.07639655, 0.07828974, 0.07727422, 0.07727422, 0.07727422,\n",
       "        0.07776569, 0.07728115, 0.07817841, 0.07754431, 0.07716008,\n",
       "        0.07716008, 0.07716008, 0.07716008, 0.0770128 , 0.07692281,\n",
       "        0.07795577, 0.0778814 , 0.0778814 , 0.0778814 , 0.0778814 ,\n",
       "        0.07745234, 0.07750627, 0.07793673, 0.07897075, 0.07897075,\n",
       "        0.07897075, 0.07897075, 0.07875152, 0.0774959 , 0.0786946 ,\n",
       "        0.07822017, 0.07822017, 0.07822017, 0.07822017, 0.07822017,\n",
       "        0.07822017, 0.07920297, 0.07707554, 0.07707554, 0.07773778,\n",
       "        0.07706925, 0.07741606, 0.07649506, 0.07647167, 0.07793977,\n",
       "        0.07793977, 0.07793977, 0.07638011, 0.07710168, 0.07733677,\n",
       "        0.07809996, 0.07681155, 0.07681155, 0.07681155, 0.07681155,\n",
       "        0.07723441, 0.07655443, 0.07820337, 0.07749872, 0.07749872,\n",
       "        0.07749872, 0.07749872, 0.07764585, 0.07693709, 0.07750196,\n",
       "        0.07714144, 0.07714144, 0.07714144, 0.07714144, 0.07635977,\n",
       "        0.07619505, 0.07721517, 0.07735259, 0.07735259, 0.07735259,\n",
       "        0.07735259, 0.07735259, 0.07735259, 0.07792079, 0.07860056,\n",
       "        0.07860056, 0.07910226, 0.07764618, 0.07795453, 0.07756296,\n",
       "        0.07712108, 0.07884961, 0.07884961, 0.07884961, 0.0779702 ,\n",
       "        0.07869599, 0.07709506, 0.07790981, 0.07913635, 0.07913635,\n",
       "        0.07913635, 0.07913635, 0.07799678, 0.078284  , 0.07856755,\n",
       "        0.07788202, 0.07788202, 0.07788202, 0.07788202, 0.07838753,\n",
       "        0.07765933, 0.07816814, 0.07877627, 0.07877627, 0.07877627,\n",
       "        0.07877627, 0.07888702, 0.07882195, 0.07792946, 0.07873069,\n",
       "        0.07873069, 0.07873069, 0.07873069, 0.07873069, 0.07873069,\n",
       "        0.07838902, 0.07744024, 0.07744024, 0.07802219, 0.07859533,\n",
       "        0.07751131, 0.07853468, 0.07919562, 0.07795482, 0.07795482,\n",
       "        0.07795482, 0.07761421, 0.07733293, 0.07786294, 0.07766699,\n",
       "        0.07855891, 0.07855891, 0.07855891, 0.07855891, 0.07883235,\n",
       "        0.07757341, 0.07732613, 0.07761954, 0.07761954, 0.07761954,\n",
       "        0.07761954, 0.07759195, 0.07796157, 0.07811578, 0.07719439,\n",
       "        0.07719439, 0.07719439, 0.07719439, 0.07803774, 0.07743186,\n",
       "        0.0789996 , 0.07860828, 0.07860828, 0.07860828, 0.07860828,\n",
       "        0.07860828, 0.07860828, 0.07729732, 0.07652654, 0.07652654,\n",
       "        0.07797164, 0.07751756, 0.07775046, 0.07758547, 0.07776103,\n",
       "        0.07785362, 0.07785362, 0.07785362, 0.07627939, 0.07683387,\n",
       "        0.0778139 , 0.07822295, 0.07744915, 0.07744915, 0.07744915,\n",
       "        0.07744915, 0.07714626, 0.07833748, 0.07720221, 0.07703985,\n",
       "        0.07703985, 0.07703985, 0.07703985, 0.07695334, 0.07780972,\n",
       "        0.07863139, 0.07797445, 0.07797445, 0.07797445, 0.07797445,\n",
       "        0.078002  , 0.07728918, 0.07783946, 0.07782765, 0.07782765,\n",
       "        0.07782765, 0.07782765, 0.07782765, 0.07782765, 0.07789029,\n",
       "        0.07792457, 0.07792457, 0.07820573, 0.07812067, 0.07802965,\n",
       "        0.07787171, 0.0774506 , 0.07684847, 0.07684847, 0.07684847,\n",
       "        0.07675394, 0.07777414, 0.07778355, 0.07805991, 0.07702484,\n",
       "        0.07702484, 0.07702484, 0.07702484, 0.07799342, 0.07818841,\n",
       "        0.07805379, 0.07751439, 0.07751439, 0.07751439, 0.07751439,\n",
       "        0.07709909, 0.07756731, 0.07747865, 0.07684216, 0.07684216,\n",
       "        0.07684216, 0.07684216, 0.07662686, 0.07755658, 0.07791137,\n",
       "        0.07703098, 0.07703098, 0.07703098, 0.07703098, 0.07703098,\n",
       "        0.07703098, 0.07669018, 0.07907602, 0.07907602, 0.07684039,\n",
       "        0.07756793, 0.07796387, 0.07766114, 0.07985059, 0.07754109,\n",
       "        0.07754109, 0.07754109, 0.07843288, 0.07751019, 0.07750565,\n",
       "        0.0791486 , 0.07741611, 0.07741611, 0.07741611, 0.07741611,\n",
       "        0.07740913, 0.07879654, 0.07879747, 0.07844792, 0.07844792,\n",
       "        0.07844792, 0.07844792, 0.07864467, 0.07861306, 0.07907964,\n",
       "        0.0773281 , 0.0773281 , 0.0773281 , 0.0773281 , 0.07794883,\n",
       "        0.07852121, 0.0790778 , 0.07871515, 0.07871515, 0.07871515,\n",
       "        0.07871515, 0.07871515, 0.07871515, 0.07899663, 0.07768634,\n",
       "        0.07768634, 0.0776754 , 0.07649341, 0.07750578, 0.07826717,\n",
       "        0.07742823, 0.07846907, 0.07846907, 0.07846907, 0.07848516,\n",
       "        0.07785871, 0.0785103 , 0.07803729, 0.07713375, 0.07713375,\n",
       "        0.07713375, 0.07713375, 0.07732244, 0.0764178 , 0.0789857 ,\n",
       "        0.07780224, 0.07780224, 0.07780224, 0.07780224, 0.07788843,\n",
       "        0.07735352, 0.07806724, 0.07823583, 0.07823583, 0.07823583,\n",
       "        0.07823583, 0.07761355, 0.07846986, 0.07793057, 0.0785045 ,\n",
       "        0.0785045 , 0.0785045 , 0.0785045 , 0.0785045 , 0.0785045 ,\n",
       "        0.07852957, 0.07713389, 0.07713389, 0.07771045, 0.07645362,\n",
       "        0.07715206, 0.0770544 , 0.07810711, 0.07821235, 0.07821235,\n",
       "        0.07821235, 0.07762512, 0.07694537, 0.07749178, 0.07803986,\n",
       "        0.07571501, 0.07571501, 0.07571501, 0.07571501, 0.07749691,\n",
       "        0.07874294, 0.07858534, 0.07846808, 0.07846808, 0.07846808,\n",
       "        0.07846808, 0.07762659, 0.07765682, 0.07747112, 0.07820576,\n",
       "        0.07820576, 0.07820576, 0.07820576, 0.07886493, 0.07754666,\n",
       "        0.07880783, 0.07735033, 0.07735033, 0.07735033, 0.07735033,\n",
       "        0.07735033, 0.07735033, 0.07830837, 0.07602628, 0.07602628,\n",
       "        0.07774594, 0.07729151, 0.07761558, 0.07571064, 0.07733712,\n",
       "        0.07652544, 0.07652544, 0.07652544, 0.07695421, 0.0771747 ,\n",
       "        0.07774205, 0.07815891, 0.0770232 , 0.0770232 , 0.0770232 ,\n",
       "        0.0770232 , 0.07765171, 0.07725631, 0.07705245, 0.0776544 ,\n",
       "        0.0776544 , 0.0776544 , 0.0776544 , 0.07692103, 0.07685721,\n",
       "        0.07764916, 0.07696046, 0.07696046, 0.07696046, 0.07696046,\n",
       "        0.0772739 , 0.07673484, 0.07712834, 0.07715838, 0.07715838,\n",
       "        0.07715838, 0.07715838, 0.07715838, 0.07715838, 0.07784839,\n",
       "        0.0777647 , 0.0777647 , 0.07749602, 0.07738525, 0.07750226,\n",
       "        0.07761287, 0.07733322, 0.07740072, 0.07740072, 0.07740072,\n",
       "        0.0780173 , 0.07821696, 0.07780719, 0.07789085, 0.07754322,\n",
       "        0.07754322, 0.07754322, 0.07754322, 0.07672851, 0.07748773,\n",
       "        0.07842636, 0.07769697, 0.07769697, 0.07769697, 0.07769697,\n",
       "        0.07769185, 0.07802426, 0.07829204, 0.07824056, 0.07824056,\n",
       "        0.07824056, 0.07824056, 0.07785178, 0.07730212, 0.07828833,\n",
       "        0.0783598 , 0.0783598 , 0.0783598 , 0.0783598 , 0.0783598 ,\n",
       "        0.0783598 , 0.07839602, 0.07756144, 0.07756144, 0.07740255,\n",
       "        0.07662681, 0.07756621, 0.07771601, 0.0768623 , 0.0775317 ,\n",
       "        0.0775317 , 0.0775317 , 0.0770844 , 0.0768708 , 0.07770866,\n",
       "        0.07789143, 0.07727583, 0.07727583, 0.07727583, 0.07727583,\n",
       "        0.07748603, 0.07673495, 0.07829602, 0.07730417, 0.07730417,\n",
       "        0.07730417, 0.07730417, 0.0779668 , 0.07776363, 0.07853987,\n",
       "        0.07695791, 0.07695791, 0.07695791, 0.07695791, 0.0777609 ,\n",
       "        0.07832759, 0.07702727, 0.07795958, 0.07795958, 0.07795958,\n",
       "        0.07795958, 0.07795958, 0.07795958, 0.0777482 , 0.07613894,\n",
       "        0.07613894, 0.07650733, 0.07694151, 0.07647772, 0.07648587,\n",
       "        0.07769338, 0.07662499, 0.07662499, 0.07662499, 0.07612096,\n",
       "        0.07652411, 0.07591355, 0.07745641, 0.07618584, 0.07618584,\n",
       "        0.07618584, 0.07618584, 0.07727019, 0.07592464, 0.07698304,\n",
       "        0.07666046, 0.07666046, 0.07666046, 0.07666046, 0.07719466,\n",
       "        0.07695483, 0.07739882, 0.07712178, 0.07712178, 0.07712178,\n",
       "        0.07712178, 0.07623982, 0.07731629, 0.07796794, 0.07719164,\n",
       "        0.07719164, 0.07719164, 0.07719164, 0.07719164, 0.07719164,\n",
       "        0.07724986, 0.07808668, 0.07808668, 0.07669197, 0.07686734,\n",
       "        0.07659925, 0.07657199, 0.07674101, 0.07543324, 0.07543324,\n",
       "        0.07543324, 0.07690534, 0.07632064, 0.07693879, 0.07684714,\n",
       "        0.07654215, 0.07654215, 0.07654215, 0.07654215, 0.0757123 ,\n",
       "        0.07597368, 0.07685788, 0.07651436, 0.07651436, 0.07651436,\n",
       "        0.07651436, 0.07664185, 0.07648123, 0.07720866, 0.07688217,\n",
       "        0.07688217, 0.07688217, 0.07688217, 0.07664589, 0.07671179,\n",
       "        0.07716205, 0.07767702, 0.07767702, 0.07767702, 0.07767702,\n",
       "        0.07767702, 0.07767702, 0.07767742, 0.07597922, 0.07597922,\n",
       "        0.07660554, 0.07593881, 0.07615834, 0.0767438 , 0.07769668,\n",
       "        0.07608101, 0.07608101, 0.07608101, 0.07673862, 0.07692588,\n",
       "        0.07642221, 0.07742234, 0.07623341, 0.07623341, 0.07623341,\n",
       "        0.07623341, 0.07618819, 0.0762328 , 0.07770052, 0.07661516,\n",
       "        0.07661516, 0.07661516, 0.07661516, 0.07647554, 0.07667488,\n",
       "        0.07714829, 0.07641716, 0.07641716, 0.07641716, 0.07641716,\n",
       "        0.07669801, 0.07683667, 0.07741006, 0.07703125, 0.07703125,\n",
       "        0.07703125, 0.07703125, 0.07703125, 0.07703125, 0.07806092,\n",
       "        0.07676633, 0.07676633, 0.07654628, 0.07669776, 0.07597967,\n",
       "        0.07604176, 0.07735163, 0.07684161, 0.07684161, 0.07684161,\n",
       "        0.07669141, 0.07635941, 0.07561844, 0.07770401, 0.07679702,\n",
       "        0.07679702, 0.07679702, 0.07679702, 0.07608424, 0.07689962,\n",
       "        0.07806492, 0.07671368, 0.07671368, 0.07671368, 0.07671368,\n",
       "        0.0763916 , 0.07756219, 0.07833056, 0.07624002, 0.07624002,\n",
       "        0.07624002, 0.07624002, 0.07680782, 0.07603004, 0.07725467,\n",
       "        0.0769275 , 0.0769275 , 0.0769275 , 0.0769275 , 0.0769275 ,\n",
       "        0.0769275 , 0.0771423 , 0.07557864, 0.07557864, 0.07578597,\n",
       "        0.07565875, 0.07558426, 0.07514897, 0.07539463, 0.07567306,\n",
       "        0.07567306, 0.07567306, 0.07581388, 0.07561553, 0.07599405,\n",
       "        0.07657649, 0.07582506, 0.07582506, 0.07582506, 0.07582506,\n",
       "        0.07497126, 0.07619776, 0.07680609, 0.07521117, 0.07521117,\n",
       "        0.07521117, 0.07521117, 0.07615755, 0.07520282, 0.07598645,\n",
       "        0.07662584, 0.07662584, 0.07662584, 0.07662584, 0.07603583,\n",
       "        0.07624524, 0.0765451 , 0.07627535, 0.07627535, 0.07627535,\n",
       "        0.07627535, 0.07627535, 0.07627535, 0.07723869, 0.07513132,\n",
       "        0.07513132, 0.07604816, 0.07485332, 0.07500175, 0.07511955,\n",
       "        0.07569857, 0.07562191, 0.07562191, 0.07562191, 0.07543208,\n",
       "        0.07494884, 0.07569808, 0.07639482, 0.07525179, 0.07525179,\n",
       "        0.07525179, 0.07525179, 0.07532601, 0.07604872, 0.076389  ,\n",
       "        0.0756553 , 0.0756553 , 0.0756553 , 0.0756553 , 0.07556072,\n",
       "        0.07572766, 0.07637443, 0.07558965, 0.07558965, 0.07558965,\n",
       "        0.07558965, 0.07575155, 0.07566905, 0.07610067, 0.07579733,\n",
       "        0.07579733, 0.07579733, 0.07579733, 0.07579733, 0.07579733,\n",
       "        0.07649416, 0.07536115, 0.07536115, 0.07620039, 0.07502584,\n",
       "        0.0759136 , 0.07508739, 0.07668113, 0.07510457, 0.07510457,\n",
       "        0.07510457, 0.07554032, 0.07585815, 0.07622991, 0.07696591,\n",
       "        0.0755752 , 0.0755752 , 0.0755752 , 0.0755752 , 0.0753358 ,\n",
       "        0.07558419, 0.07629148, 0.07561646, 0.07561646, 0.07561646,\n",
       "        0.07561646, 0.07544561, 0.07578331, 0.07709755, 0.07602386,\n",
       "        0.07602386, 0.07602386, 0.07602386, 0.07602856, 0.07585006,\n",
       "        0.07693461, 0.07644658, 0.07644658, 0.07644658, 0.07644658,\n",
       "        0.07644658, 0.07644658, 0.07707039, 0.07548626, 0.07548626,\n",
       "        0.07589693, 0.07506587, 0.07538411, 0.07602308, 0.07644425,\n",
       "        0.07550109, 0.07550109, 0.07550109, 0.07540538, 0.07536483,\n",
       "        0.07594776, 0.07624225, 0.07534925, 0.07534925, 0.07534925,\n",
       "        0.07534925, 0.07603038, 0.075569  , 0.07631583, 0.07577589,\n",
       "        0.07577589, 0.07577589, 0.07577589, 0.07568628, 0.07505595,\n",
       "        0.07580256, 0.07585571, 0.07585571, 0.07585571, 0.07585571,\n",
       "        0.07614913, 0.07549708, 0.07558102, 0.07576983, 0.07576983,\n",
       "        0.07576983, 0.07576983, 0.07576983, 0.07576983, 0.07700074]),\n",
       " 'rank_test_score': array([647, 647, 652, 667, 597, 633, 717, 664, 664, 664, 641, 671, 698,\n",
       "        668, 592, 592, 592, 592, 670, 566, 699, 691, 691, 691, 691, 603,\n",
       "        617, 689, 720, 720, 720, 720, 688, 623, 724, 626, 626, 626, 626,\n",
       "        626, 626, 718, 621, 621, 663, 604, 579, 545, 563, 644, 644, 644,\n",
       "        546, 510, 583, 612, 540, 540, 540, 540, 643, 539, 640, 659, 659,\n",
       "        659, 659, 658, 625, 559, 535, 535, 535, 535, 492, 216, 500, 549,\n",
       "        549, 549, 549, 549, 549, 602, 618, 618, 684, 555, 578, 562, 454,\n",
       "        613, 613, 613, 572, 599, 491, 558, 654, 654, 654, 654, 632, 598,\n",
       "        591, 574, 574, 574, 574, 616, 452, 467, 587, 587, 587, 587, 582,\n",
       "        601, 596, 606, 606, 606, 606, 606, 606, 586, 278, 278, 561, 564,\n",
       "        246, 523, 573, 524, 524, 524, 420, 342, 483, 450, 469, 469, 469,\n",
       "        469, 571, 307, 221, 473, 473, 473, 473, 505, 519, 548, 158, 158,\n",
       "        158, 158, 501, 359, 565, 484, 484, 484, 484, 484, 484, 433, 336,\n",
       "        336, 404, 251, 284, 457, 363, 511, 511, 511, 157, 277, 451, 355,\n",
       "        238, 238, 238, 238, 201, 438,  53, 113, 113, 113, 113, 184, 358,\n",
       "        580, 291, 291, 291, 291, 498, 377, 248, 254, 254, 254, 254, 254,\n",
       "        254, 220, 214, 214, 354, 443, 329, 340,  93,  62,  62,  62, 229,\n",
       "        315, 446, 403,  86,  86,  86,  86, 314, 308, 387, 379, 379, 379,\n",
       "        379,  95, 162, 124, 165, 165, 165, 165,  41, 317, 196,  16,  16,\n",
       "         16,  16,  16,  16,  13, 556, 556,  70, 328, 319, 376, 522, 325,\n",
       "        325, 325, 346, 357,  80, 338, 191, 191, 191, 191,  79, 364, 306,\n",
       "        395, 395, 395, 395, 482, 324, 414, 366, 366, 366, 366, 288, 356,\n",
       "        286, 388, 388, 388, 388, 388, 388, 436, 234, 234, 145,  24,  40,\n",
       "        133,  12, 417, 417, 417, 447, 183, 163,  29,  32,  32,  32,  32,\n",
       "         76,   3, 289,  36,  36,  36,  36,  43,  26, 218,  72,  72,  72,\n",
       "         72,  15,  77, 136,  96,  96,  96,  96,  96,  96, 141, 199, 199,\n",
       "        348, 182, 261, 210, 275, 527, 527, 527, 335, 230, 466, 249,  65,\n",
       "         65,  65,  65, 330, 570, 449, 515, 515, 515, 515, 435, 353,  25,\n",
       "        421, 421, 421, 421, 460, 287, 413, 102, 102, 102, 102, 102, 102,\n",
       "        135, 143, 143, 402, 514, 444,  11,  22, 350, 350, 350, 219,  44,\n",
       "        247, 236, 173, 173, 173, 173, 365, 164, 112, 137, 137, 137, 137,\n",
       "        177, 156,  61,  48,  48,  48,  48, 150,  14,  10,   4,   4,   4,\n",
       "          4,   4,   4,  46, 440, 440, 237, 276, 282, 217,  30, 311, 311,\n",
       "        311, 456, 445, 458,  91, 242, 242, 242, 242,  78, 203,  55, 296,\n",
       "        296, 296, 296, 250, 341, 290, 151, 151, 151, 151, 198, 134, 146,\n",
       "        222, 222, 222, 222, 222, 222,  54, 415, 415, 305,  52, 142, 285,\n",
       "          1, 373, 373, 373, 233,  60, 260,  81, 178, 178, 178, 178, 345,\n",
       "         45,  85, 186, 186, 186, 186, 228, 304,  90,  56,  56,  56,  56,\n",
       "         47, 281,   2, 117, 117, 117, 117, 117, 117,  28, 343, 343, 459,\n",
       "        442, 521, 401, 202, 383, 383, 383, 431, 378, 125, 253, 331, 331,\n",
       "        331, 331, 490,  92,  69, 405, 405, 405, 405, 453, 295, 211, 169,\n",
       "        169, 169, 169,  94, 430, 232, 262, 262, 262, 262, 262, 262, 148,\n",
       "        584, 584, 560, 493, 499, 534,  31, 360, 360, 360, 495, 252, 468,\n",
       "         84, 409, 409, 409, 409, 280, 197,  27, 425, 425, 425, 425, 437,\n",
       "        132,  83, 108, 108, 108, 108, 347, 309, 155, 204, 204, 204, 204,\n",
       "        204, 204,  42, 370, 370, 544, 400, 318, 349, 195, 502, 502, 502,\n",
       "        496, 432, 448, 185, 477, 477, 477, 477, 439, 283, 372, 462, 462,\n",
       "        462, 462, 497, 212, 190, 300, 300, 300, 300, 429, 310, 147, 126,\n",
       "        126, 126, 126, 126, 126,  82, 567, 567, 547, 520, 231, 316, 213,\n",
       "        649, 649, 649, 494, 481, 149, 339, 506, 506, 506, 506, 399, 394,\n",
       "        274, 530, 530, 530, 530, 455, 386, 461, 320, 320, 320, 320, 434,\n",
       "        123,  23, 268, 268, 268, 268, 268, 268,  71, 744, 744, 753, 779,\n",
       "        763, 728, 581, 804, 804, 804, 823, 762, 736, 682, 816, 816, 816,\n",
       "        816, 737, 709, 669, 748, 748, 748, 748, 735, 707, 600, 758, 758,\n",
       "        758, 758, 738, 708, 605, 634, 634, 634, 634, 634, 634, 620, 811,\n",
       "        811, 822, 824, 791, 719, 642, 780, 780, 780, 820, 773, 742, 687,\n",
       "        769, 769, 769, 769, 783, 794, 686, 795, 795, 795, 795, 746, 727,\n",
       "        690, 729, 729, 729, 729, 733, 696, 624, 673, 673, 673, 673, 673,\n",
       "        673, 569, 792, 792, 810, 837, 828, 752, 726, 739, 739, 739, 813,\n",
       "        839, 785, 700, 787, 787, 787, 787, 814, 778, 683, 754, 754, 754,\n",
       "        754, 821, 747, 716, 764, 764, 764, 764, 786, 743, 679, 701, 701,\n",
       "        701, 701, 701, 701, 672, 808, 808, 807, 829, 825, 768, 695, 834,\n",
       "        834, 834, 840, 826, 815, 697, 800, 800, 800, 800, 838, 827, 685,\n",
       "        830, 830, 830, 830, 784, 725, 681, 774, 774, 774, 774, 799, 734,\n",
       "        653, 710, 710, 710, 710, 710, 710, 680])}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_gbt_cv.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.91%\n",
      "Balanced Accuracy: 70.85%\n",
      "Balanced Accuracy: 58.39%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97     12533\n",
      "           1       0.97      0.42      0.58      1169\n",
      "\n",
      "    accuracy                           0.95     13702\n",
      "   macro avg       0.96      0.71      0.78     13702\n",
      "weighted avg       0.95      0.95      0.94     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12516</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>680</td>\n",
       "      <td>489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1\n",
       "is_promoted            \n",
       "0            12516   17\n",
       "1              680  489"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_gbt_cv2.predict(X_val)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.f1_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acc=[]\n",
    "# balAcc=[]\n",
    "# f1=[]\n",
    "# for val in range(1,11):\n",
    "    \n",
    "#     sm = SMOTE(random_state=0,sampling_strategy=0.1*val)\n",
    "#     X_SMOTE, y_SMOTE = sm.fit_resample(X_train, Y_train)\n",
    "    \n",
    "#     print(X_SMOTE.shape)\n",
    "#     print(y_SMOTE.shape)\n",
    "    \n",
    "#     clf = GradientBoostingClassifier(random_state=0,max_depth=6, max_features= 9,min_samples_leaf= 2,min_samples_split= 350,n_estimators= 500)\n",
    "    \n",
    "#     clf.fit(X_SMOTE, y_SMOTE)\n",
    "#     y_pred = clf.predict(X_val)\n",
    "#     Acc.append(metrics.accuracy_score(Y_val, y_pred)*100)\n",
    "#     balAcc.append(metrics.balanced_accuracy_score(Y_val, y_pred)*100)\n",
    "#     f1.append(metrics.f1_score(Y_val, y_pred)*100)\n",
    "    \n",
    "#     #print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "#     print(f\"Balanced Accuracy: {round(metrics.f1_score(Y_val, y_pred)*100, 2)}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 56.85%\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(random_state=0,max_depth=6, max_features= 9,min_samples_leaf= 2,min_samples_split= 360,n_estimators= 500,)\n",
    "gbt_pipe2 = Pipeline([('stdScaler',preprocessing.MaxAbsScaler()),('classifier', clf)])\n",
    "gbt_pipe2.fit(x_train, y_train)\n",
    "y_pred = gbt_pipe2.predict(X_val)\n",
    "#Acc.append(metrics.accuracy_score(Y_val, y_pred)*100)\n",
    "#balAcc.append(metrics.balanced_accuracy_score(Y_val, y_pred)*100)\n",
    "#f1.append(metrics.f1_score(Y_val, y_pred)*100)\n",
    "print(f\"Balanced Accuracy: {round(metrics.f1_score(Y_val, y_pred)*100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy: 56.8497284249%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Balanced Accuracy: {round(metrics.f1_score(Y_val, y_pred)*100, 10)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('classifier',\n",
       "                 GradientBoostingClassifier(max_depth=6, max_features=9,\n",
       "                                            min_samples_leaf=2,\n",
       "                                            min_samples_split=350,\n",
       "                                            n_estimators=500,\n",
       "                                            random_state=0))])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbt_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SMOTE\n",
    "sm = SMOTE(random_state=0,sampling_strategy=0.9)\n",
    "X_SMOTE, y_SMOTE = sm.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('kneighborsclassifier', KNeighborsClassifier(n_neighbors=51))])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "knn_pipe = make_pipeline(StandardScaler(), KNeighborsClassifier(n_neighbors=51))\n",
    "knn_pipe.fit(X_SMOTE, y_SMOTE)\n",
    "# knn_clf = KNeighborsClassifier(n_neighbors=51)\n",
    "# knn_clf.fit(X_SMOTE, y_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.12%\n",
      "Balanced Accuracy: 65.96%\n",
      "Balanced Accuracy: 32.13%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91     12533\n",
      "           1       0.25      0.44      0.32      1169\n",
      "\n",
      "    accuracy                           0.84     13702\n",
      "   macro avg       0.60      0.66      0.62     13702\n",
      "weighted avg       0.88      0.84      0.86     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11011</td>\n",
       "      <td>1522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>654</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0     1\n",
       "is_promoted             \n",
       "0            11011  1522\n",
       "1              654   515"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = knn_pipe.predict(X_val)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.f1_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6437243\ttest: 0.6434129\tbest: 0.6434129 (0)\ttotal: 71.7ms\tremaining: 7.1s\n",
      "10:\tlearn: 0.3803608\ttest: 0.3794094\tbest: 0.3794094 (10)\ttotal: 207ms\tremaining: 1.68s\n",
      "20:\tlearn: 0.2766922\ttest: 0.2756350\tbest: 0.2756350 (20)\ttotal: 344ms\tremaining: 1.29s\n",
      "30:\tlearn: 0.2283211\ttest: 0.2272524\tbest: 0.2272524 (30)\ttotal: 470ms\tremaining: 1.04s\n",
      "40:\tlearn: 0.2023101\ttest: 0.2011812\tbest: 0.2011812 (40)\ttotal: 619ms\tremaining: 891ms\n",
      "50:\tlearn: 0.1903175\ttest: 0.1892271\tbest: 0.1892271 (50)\ttotal: 751ms\tremaining: 722ms\n",
      "60:\tlearn: 0.1810522\ttest: 0.1798213\tbest: 0.1798213 (60)\ttotal: 881ms\tremaining: 564ms\n",
      "70:\tlearn: 0.1762174\ttest: 0.1749706\tbest: 0.1749706 (70)\ttotal: 1.01s\tremaining: 412ms\n",
      "80:\tlearn: 0.1731446\ttest: 0.1719067\tbest: 0.1719067 (80)\ttotal: 1.14s\tremaining: 268ms\n",
      "90:\tlearn: 0.1707310\ttest: 0.1695303\tbest: 0.1695303 (90)\ttotal: 1.3s\tremaining: 129ms\n",
      "99:\tlearn: 0.1693506\ttest: 0.1681638\tbest: 0.1681638 (99)\ttotal: 1.44s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.1681638269\n",
      "bestIteration = 99\n",
      "\n",
      "Time to fit model on CPU: 1 sec\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "import timeit\n",
    "\n",
    "def train_on_cpu():  \n",
    "  model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    learning_rate=0.03\n",
    "  )\n",
    "  \n",
    "  model.fit(\n",
    "      x_train, y_train,\n",
    "      eval_set=(X_val, Y_val),\n",
    "      verbose=10\n",
    "  );   \n",
    "      \n",
    "cpu_time = timeit.timeit('train_on_cpu()', \n",
    "                         setup=\"from __main__ import train_on_cpu\", \n",
    "                         number=1)\n",
    "\n",
    "print('Time to fit model on CPU: {} sec'.format(int(cpu_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.6431445\ttest: 0.6429494\tbest: 0.6429494 (0)\ttotal: 16.7ms\tremaining: 1.65s\n",
      "10:\tlearn: 0.3704543\ttest: 0.3696230\tbest: 0.3696230 (10)\ttotal: 117ms\tremaining: 944ms\n",
      "20:\tlearn: 0.2668146\ttest: 0.2659239\tbest: 0.2659239 (20)\ttotal: 205ms\tremaining: 770ms\n",
      "30:\tlearn: 0.2182647\ttest: 0.2172213\tbest: 0.2172213 (30)\ttotal: 296ms\tremaining: 659ms\n",
      "40:\tlearn: 0.1951705\ttest: 0.1940342\tbest: 0.1940342 (40)\ttotal: 383ms\tremaining: 551ms\n",
      "50:\tlearn: 0.1840918\ttest: 0.1829410\tbest: 0.1829410 (50)\ttotal: 473ms\tremaining: 454ms\n",
      "60:\tlearn: 0.1781885\ttest: 0.1770544\tbest: 0.1770544 (60)\ttotal: 559ms\tremaining: 357ms\n",
      "70:\tlearn: 0.1737938\ttest: 0.1726547\tbest: 0.1726547 (70)\ttotal: 646ms\tremaining: 264ms\n",
      "80:\tlearn: 0.1706239\ttest: 0.1695407\tbest: 0.1695407 (80)\ttotal: 735ms\tremaining: 172ms\n",
      "90:\tlearn: 0.1686591\ttest: 0.1675893\tbest: 0.1675893 (90)\ttotal: 835ms\tremaining: 82.6ms\n",
      "99:\tlearn: 0.1673943\ttest: 0.1663833\tbest: 0.1663833 (99)\ttotal: 931ms\tremaining: 0us\n",
      "bestTest = 0.1663832792\n",
      "bestIteration = 99\n",
      "Time to fit model on GPU: 1 sec\n",
      "GPU speedup over CPU: 0.84x\n"
     ]
    }
   ],
   "source": [
    "def train_on_gpu():  \n",
    "  model = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    learning_rate=0.03,\n",
    "    task_type='GPU'\n",
    "  )\n",
    "\n",
    "    \n",
    "  \n",
    "  model.fit(\n",
    "     x_train, y_train,\n",
    "      eval_set=(X_val, Y_val),\n",
    "      verbose=10\n",
    "  );     \n",
    "      \n",
    "gpu_time = timeit.timeit('train_on_gpu()', \n",
    "                         setup=\"from __main__ import train_on_gpu\", \n",
    "                         number=1)\n",
    "\n",
    "print('Time to fit model on GPU: {} sec'.format(int(gpu_time)))\n",
    "print('GPU speedup over CPU: ' + '%.2f' % (cpu_time/gpu_time) + 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=categorical_features_indices,\n",
    "    eval_set=(X_validation, y_validation),\n",
    "#     logging_level='Verbose',  # you can uncomment this for text output\n",
    "    plot=True\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing to result to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "molelPipe=knn_pipe\n",
    "y_pred = molelPipe.predict(X_test)\n",
    "test['employee_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame()\n",
    "result['employee_id']=test['employee_id']\n",
    "result['is_promoted']=y_pred\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"base_result4.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DataExplorationAnd Cleaning.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
