{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\"> HR Analytics Data Exploration and Cleaning </div>                               \n",
    "\n",
    "\n",
    "####      <div style=\"text-align: right\">  by- Lakshya Gupta & Abhiraj Singh</div>           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "HR analytics is revolutionising the way human resources departments operate, leading to higher efficiency and better results overall. Human resources has been using analytics for years. However, the collection, processing and analysis of data has been largely manual, and given the nature of human resources dynamics and HR KPIs, the approach has been constraining HR. Therefore, it is surprising that HR departments woke up to the utility of machine learning so late in the game. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from scipy.spatial import distance_matrix\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\n",
    "#from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   employee_id         department     region         education gender  \\\n",
       "0        65438  Sales & Marketing   region_7  Master's & above      f   \n",
       "1        65141         Operations  region_22        Bachelor's      m   \n",
       "2         7513  Sales & Marketing  region_19        Bachelor's      m   \n",
       "3         2542  Sales & Marketing  region_23        Bachelor's      m   \n",
       "4        48945         Technology  region_26        Bachelor's      m   \n",
       "\n",
       "  recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0            sourcing                1   35                   5.0   \n",
       "1               other                1   30                   5.0   \n",
       "2            sourcing                1   34                   3.0   \n",
       "3               other                2   39                   1.0   \n",
       "4               other                1   45                   3.0   \n",
       "\n",
       "   length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \\\n",
       "0                  8              1            0                  49   \n",
       "1                  4              0            0                  60   \n",
       "2                  7              0            0                  50   \n",
       "3                 10              0            0                  50   \n",
       "4                  2              0            0                  73   \n",
       "\n",
       "   is_promoted  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54808, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>50684.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "      <td>54808.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39195.830627</td>\n",
       "      <td>1.253011</td>\n",
       "      <td>34.803915</td>\n",
       "      <td>3.329256</td>\n",
       "      <td>5.865512</td>\n",
       "      <td>0.351974</td>\n",
       "      <td>0.023172</td>\n",
       "      <td>63.386750</td>\n",
       "      <td>0.085170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22586.581449</td>\n",
       "      <td>0.609264</td>\n",
       "      <td>7.660169</td>\n",
       "      <td>1.259993</td>\n",
       "      <td>4.265094</td>\n",
       "      <td>0.477590</td>\n",
       "      <td>0.150450</td>\n",
       "      <td>13.371559</td>\n",
       "      <td>0.279137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>19669.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39225.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>58730.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>78298.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        employee_id  no_of_trainings           age  previous_year_rating  \\\n",
       "count  54808.000000     54808.000000  54808.000000          50684.000000   \n",
       "mean   39195.830627         1.253011     34.803915              3.329256   \n",
       "std    22586.581449         0.609264      7.660169              1.259993   \n",
       "min        1.000000         1.000000     20.000000              1.000000   \n",
       "25%    19669.750000         1.000000     29.000000              3.000000   \n",
       "50%    39225.500000         1.000000     33.000000              3.000000   \n",
       "75%    58730.500000         1.000000     39.000000              4.000000   \n",
       "max    78298.000000        10.000000     60.000000              5.000000   \n",
       "\n",
       "       length_of_service  KPIs_met >80%   awards_won?  avg_training_score  \\\n",
       "count       54808.000000   54808.000000  54808.000000        54808.000000   \n",
       "mean            5.865512       0.351974      0.023172           63.386750   \n",
       "std             4.265094       0.477590      0.150450           13.371559   \n",
       "min             1.000000       0.000000      0.000000           39.000000   \n",
       "25%             3.000000       0.000000      0.000000           51.000000   \n",
       "50%             5.000000       0.000000      0.000000           60.000000   \n",
       "75%             7.000000       1.000000      0.000000           76.000000   \n",
       "max            37.000000       1.000000      1.000000           99.000000   \n",
       "\n",
       "        is_promoted  \n",
       "count  54808.000000  \n",
       "mean       0.085170  \n",
       "std        0.279137  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describeDf=train.describe()\n",
    "print(type(describeDf))\n",
    "describeDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train['is_promoted']\n",
    "x_train=train.drop(columns=['is_promoted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess pipeline\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "\n",
    "\n",
    "dropColumnList= ['employee_id']\n",
    "imputeList = ['education']\n",
    "knnImputeList = ['previous_year_rating']\n",
    "catColumnList=['department', 'region','education','gender','recruitment_channel']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "* drop columns\n",
    "* NA values of education\n",
    "* KNN Impute for previous_year_rating\n",
    "* onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    \n",
    "    data = data.drop(columns=['employee_id'])   #drop columns\n",
    "    \n",
    "    for column in imputeList:\n",
    "        data[column].fillna('unknown',inplace=True)\n",
    "        \n",
    "    data= pd.get_dummies(data) \n",
    "    \n",
    "    data_columns=data.columns\n",
    "    \n",
    "    \n",
    "    \n",
    "    imputer = KNNImputer(n_neighbors=11)\n",
    "    data=imputer.fit_transform(data)\n",
    "    \n",
    "    data=pd.DataFrame(data, columns=data_columns)\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54808, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>department</th>\n",
       "      <th>region</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>recruitment_channel</th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65438</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>65141</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_22</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7513</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_19</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2542</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_23</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48945</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_26</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>58896</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>region_2</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20379</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_20</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>16290</td>\n",
       "      <td>Operations</td>\n",
       "      <td>region_34</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>33</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>73202</td>\n",
       "      <td>Analytics</td>\n",
       "      <td>region_20</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>m</td>\n",
       "      <td>other</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>28911</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_1</td>\n",
       "      <td>Master's &amp; above</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>29934</td>\n",
       "      <td>Technology</td>\n",
       "      <td>region_23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>49017</td>\n",
       "      <td>Sales &amp; Marketing</td>\n",
       "      <td>region_7</td>\n",
       "      <td>Bachelor's</td>\n",
       "      <td>f</td>\n",
       "      <td>sourcing</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    employee_id         department     region         education gender  \\\n",
       "0         65438  Sales & Marketing   region_7  Master's & above      f   \n",
       "1         65141         Operations  region_22        Bachelor's      m   \n",
       "2          7513  Sales & Marketing  region_19        Bachelor's      m   \n",
       "3          2542  Sales & Marketing  region_23        Bachelor's      m   \n",
       "4         48945         Technology  region_26        Bachelor's      m   \n",
       "5         58896          Analytics   region_2        Bachelor's      m   \n",
       "6         20379         Operations  region_20        Bachelor's      f   \n",
       "7         16290         Operations  region_34  Master's & above      m   \n",
       "8         73202          Analytics  region_20        Bachelor's      m   \n",
       "9         28911  Sales & Marketing   region_1  Master's & above      m   \n",
       "10        29934         Technology  region_23               NaN      m   \n",
       "11        49017  Sales & Marketing   region_7        Bachelor's      f   \n",
       "\n",
       "   recruitment_channel  no_of_trainings  age  previous_year_rating  \\\n",
       "0             sourcing                1   35                   5.0   \n",
       "1                other                1   30                   5.0   \n",
       "2             sourcing                1   34                   3.0   \n",
       "3                other                2   39                   1.0   \n",
       "4                other                1   45                   3.0   \n",
       "5             sourcing                2   31                   3.0   \n",
       "6                other                1   31                   3.0   \n",
       "7             sourcing                1   33                   3.0   \n",
       "8                other                1   28                   4.0   \n",
       "9             sourcing                1   32                   5.0   \n",
       "10            sourcing                1   30                   NaN   \n",
       "11            sourcing                1   35                   5.0   \n",
       "\n",
       "    length_of_service  KPIs_met >80%  awards_won?  avg_training_score  \n",
       "0                   8              1            0                  49  \n",
       "1                   4              0            0                  60  \n",
       "2                   7              0            0                  50  \n",
       "3                  10              0            0                  50  \n",
       "4                   2              0            0                  73  \n",
       "5                   7              0            0                  85  \n",
       "6                   5              0            0                  59  \n",
       "7                   6              0            0                  63  \n",
       "8                   5              0            0                  83  \n",
       "9                   5              1            0                  54  \n",
       "10                  1              0            0                  77  \n",
       "11                  3              1            0                  50  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "x_train.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54808, 59)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_trainings</th>\n",
       "      <th>age</th>\n",
       "      <th>previous_year_rating</th>\n",
       "      <th>length_of_service</th>\n",
       "      <th>KPIs_met &gt;80%</th>\n",
       "      <th>awards_won?</th>\n",
       "      <th>avg_training_score</th>\n",
       "      <th>department_Analytics</th>\n",
       "      <th>department_Finance</th>\n",
       "      <th>department_HR</th>\n",
       "      <th>...</th>\n",
       "      <th>region_region_9</th>\n",
       "      <th>education_Bachelor's</th>\n",
       "      <th>education_Below Secondary</th>\n",
       "      <th>education_Master's &amp; above</th>\n",
       "      <th>education_unknown</th>\n",
       "      <th>gender_f</th>\n",
       "      <th>gender_m</th>\n",
       "      <th>recruitment_channel_other</th>\n",
       "      <th>recruitment_channel_referred</th>\n",
       "      <th>recruitment_channel_sourcing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2.909091</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    no_of_trainings   age  previous_year_rating  length_of_service  \\\n",
       "0               1.0  35.0              5.000000                8.0   \n",
       "1               1.0  30.0              5.000000                4.0   \n",
       "2               1.0  34.0              3.000000                7.0   \n",
       "3               2.0  39.0              1.000000               10.0   \n",
       "4               1.0  45.0              3.000000                2.0   \n",
       "5               2.0  31.0              3.000000                7.0   \n",
       "6               1.0  31.0              3.000000                5.0   \n",
       "7               1.0  33.0              3.000000                6.0   \n",
       "8               1.0  28.0              4.000000                5.0   \n",
       "9               1.0  32.0              5.000000                5.0   \n",
       "10              1.0  30.0              2.909091                1.0   \n",
       "11              1.0  35.0              5.000000                3.0   \n",
       "\n",
       "    KPIs_met >80%  awards_won?  avg_training_score  department_Analytics  \\\n",
       "0             1.0          0.0                49.0                   0.0   \n",
       "1             0.0          0.0                60.0                   0.0   \n",
       "2             0.0          0.0                50.0                   0.0   \n",
       "3             0.0          0.0                50.0                   0.0   \n",
       "4             0.0          0.0                73.0                   0.0   \n",
       "5             0.0          0.0                85.0                   1.0   \n",
       "6             0.0          0.0                59.0                   0.0   \n",
       "7             0.0          0.0                63.0                   0.0   \n",
       "8             0.0          0.0                83.0                   1.0   \n",
       "9             1.0          0.0                54.0                   0.0   \n",
       "10            0.0          0.0                77.0                   0.0   \n",
       "11            1.0          0.0                50.0                   0.0   \n",
       "\n",
       "    department_Finance  department_HR  ...  region_region_9  \\\n",
       "0                  0.0            0.0  ...              0.0   \n",
       "1                  0.0            0.0  ...              0.0   \n",
       "2                  0.0            0.0  ...              0.0   \n",
       "3                  0.0            0.0  ...              0.0   \n",
       "4                  0.0            0.0  ...              0.0   \n",
       "5                  0.0            0.0  ...              0.0   \n",
       "6                  0.0            0.0  ...              0.0   \n",
       "7                  0.0            0.0  ...              0.0   \n",
       "8                  0.0            0.0  ...              0.0   \n",
       "9                  0.0            0.0  ...              0.0   \n",
       "10                 0.0            0.0  ...              0.0   \n",
       "11                 0.0            0.0  ...              0.0   \n",
       "\n",
       "    education_Bachelor's  education_Below Secondary  \\\n",
       "0                    0.0                        0.0   \n",
       "1                    1.0                        0.0   \n",
       "2                    1.0                        0.0   \n",
       "3                    1.0                        0.0   \n",
       "4                    1.0                        0.0   \n",
       "5                    1.0                        0.0   \n",
       "6                    1.0                        0.0   \n",
       "7                    0.0                        0.0   \n",
       "8                    1.0                        0.0   \n",
       "9                    0.0                        0.0   \n",
       "10                   0.0                        0.0   \n",
       "11                   1.0                        0.0   \n",
       "\n",
       "    education_Master's & above  education_unknown  gender_f  gender_m  \\\n",
       "0                          1.0                0.0       1.0       0.0   \n",
       "1                          0.0                0.0       0.0       1.0   \n",
       "2                          0.0                0.0       0.0       1.0   \n",
       "3                          0.0                0.0       0.0       1.0   \n",
       "4                          0.0                0.0       0.0       1.0   \n",
       "5                          0.0                0.0       0.0       1.0   \n",
       "6                          0.0                0.0       1.0       0.0   \n",
       "7                          1.0                0.0       0.0       1.0   \n",
       "8                          0.0                0.0       0.0       1.0   \n",
       "9                          1.0                0.0       0.0       1.0   \n",
       "10                         0.0                1.0       0.0       1.0   \n",
       "11                         0.0                0.0       1.0       0.0   \n",
       "\n",
       "    recruitment_channel_other  recruitment_channel_referred  \\\n",
       "0                         0.0                           0.0   \n",
       "1                         1.0                           0.0   \n",
       "2                         0.0                           0.0   \n",
       "3                         1.0                           0.0   \n",
       "4                         1.0                           0.0   \n",
       "5                         0.0                           0.0   \n",
       "6                         1.0                           0.0   \n",
       "7                         0.0                           0.0   \n",
       "8                         1.0                           0.0   \n",
       "9                         0.0                           0.0   \n",
       "10                        0.0                           0.0   \n",
       "11                        0.0                           0.0   \n",
       "\n",
       "    recruitment_channel_sourcing  \n",
       "0                            1.0  \n",
       "1                            0.0  \n",
       "2                            1.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "5                            1.0  \n",
       "6                            0.0  \n",
       "7                            1.0  \n",
       "8                            0.0  \n",
       "9                            1.0  \n",
       "10                           1.0  \n",
       "11                           1.0  \n",
       "\n",
       "[12 rows x 59 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train=preprocessing(x_train)\n",
    "print(x_train.shape)\n",
    "x_train.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10       2.909091\n",
       "23       3.000000\n",
       "29       3.545455\n",
       "56       3.272727\n",
       "58       3.727273\n",
       "           ...   \n",
       "54703    3.363636\n",
       "54734    3.454545\n",
       "54746    3.818182\n",
       "54773    3.363636\n",
       "54801    2.090909\n",
       "Name: previous_year_rating, Length: 4124, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputedRatingsDf=x_train[train['previous_year_rating'].isnull()]\n",
    "imputedRatings=imputedRatingsDf['previous_year_rating']\n",
    "imputedRatings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x167eafab288>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(imputedRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x167edbe51c8>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(train['previous_year_rating'][train['length_of_service']==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.909090909090909"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['previous_year_rating'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Validation Spliting\n",
    "\n",
    "75:25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilaks\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logr_pipe = make_pipeline( LogisticRegression(solver='lbfgs',max_iter=100))\n",
    "model_Lr=logr_pipe.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, cross_validate, ShuffleSplit, LeaveOneOut\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.13%\n",
      "Balanced Accuracy: 58.16%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96     12533\n",
      "           1       0.65      0.17      0.27      1169\n",
      "\n",
      "    accuracy                           0.92     13702\n",
      "   macro avg       0.79      0.58      0.62     13702\n",
      "weighted avg       0.90      0.92      0.90     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12423</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>968</td>\n",
       "      <td>201</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1\n",
       "is_promoted            \n",
       "0            12423  110\n",
       "1              968  201"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model_Lr.predict(X_val)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.05%\n",
      "Balanced Accuracy: 73.57%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.79      0.87     12533\n",
      "           1       0.23      0.68      0.35      1169\n",
      "\n",
      "    accuracy                           0.78     13702\n",
      "   macro avg       0.60      0.74      0.61     13702\n",
      "weighted avg       0.90      0.78      0.82     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9897</td>\n",
       "      <td>2636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>372</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0           0     1\n",
       "is_promoted            \n",
       "0            9897  2636\n",
       "1             372   797"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mythreshold=0.1\n",
    "y_pred = (model_Lr.predict_proba(X_val) >= mythreshold).astype(int)\n",
    "#y_pred = model_Lr.predict(X_val)\n",
    "y_pred=y_pred[:,1]\n",
    "#y_pred\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=0,sampling_strategy=0.9)\n",
    "X_SMOTE, y_SMOTE = sm.fit_resample(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ilaks\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logr_pipe = make_pipeline( LogisticRegression(solver='lbfgs',max_iter=100))\n",
    "model_Lr=logr_pipe.fit(X_SMOTE, y_SMOTE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33846"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_SMOTE.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 75.42%\n",
      "Balanced Accuracy: 74.58%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85     12533\n",
      "           1       0.22      0.74      0.34      1169\n",
      "\n",
      "    accuracy                           0.75     13702\n",
      "   macro avg       0.59      0.75      0.59     13702\n",
      "weighted avg       0.90      0.75      0.81     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9474</td>\n",
       "      <td>3059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>309</td>\n",
       "      <td>860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0           0     1\n",
       "is_promoted            \n",
       "0            9474  3059\n",
       "1             309   860"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mythreshold=0.48\n",
    "y_pred = (model_Lr.predict_proba(X_val) >= mythreshold).astype(int)\n",
    "#y_pred = model_Lr.predict(X_val)\n",
    "y_pred=y_pred[:,1]\n",
    "#y_pred\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23490, 13)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=preprocessing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_Lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         8724\n",
       "1        74430\n",
       "2        72255\n",
       "3        38562\n",
       "4        64486\n",
       "         ...  \n",
       "23485    53478\n",
       "23486    25600\n",
       "23487    45409\n",
       "23488     1186\n",
       "23489     5973\n",
       "Name: employee_id, Length: 23490, dtype: int64"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['employee_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['employee_id']=test['employee_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['is_promoted']=y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>is_promoted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8724</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>74430</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>72255</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38562</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64486</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23485</th>\n",
       "      <td>53478</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23486</th>\n",
       "      <td>25600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23487</th>\n",
       "      <td>45409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23488</th>\n",
       "      <td>1186</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23489</th>\n",
       "      <td>5973</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23490 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       employee_id  is_promoted\n",
       "0             8724            1\n",
       "1            74430            0\n",
       "2            72255            0\n",
       "3            38562            0\n",
       "4            64486            0\n",
       "...            ...          ...\n",
       "23485        53478            0\n",
       "23486        25600            0\n",
       "23487        45409            0\n",
       "23488         1186            0\n",
       "23489         5973            1\n",
       "\n",
       "[23490 rows x 2 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"base_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "forest.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'ccp_alpha': 0.0,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'gini',\n",
       " 'max_depth': None,\n",
       " 'max_features': 'auto',\n",
       " 'max_leaf_nodes': None,\n",
       " 'max_samples': None,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_impurity_split': None,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'oob_score': False,\n",
       " 'random_state': None,\n",
       " 'verbose': 0,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.33%\n",
      "Balanced Accuracy: 63.04%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.96     12533\n",
      "           1       0.85      0.27      0.40      1169\n",
      "\n",
      "    accuracy                           0.93     13702\n",
      "   macro avg       0.89      0.63      0.68     13702\n",
      "weighted avg       0.93      0.93      0.92     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12478</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>859</td>\n",
       "      <td>310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1\n",
       "is_promoted            \n",
       "0            12478   55\n",
       "1              859  310"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = forest.predict(X_val)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 200 candidates, totalling 800 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   44.9s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:  4.5min\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed: 13.5min\n",
      "[Parallel(n_jobs=-1)]: Done 776 tasks      | elapsed: 30.0min\n",
      "[Parallel(n_jobs=-1)]: Done 800 out of 800 | elapsed: 31.7min finished\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "               'max_depth':[5,8,10,12],\n",
    "              'min_samples_leaf': [3,4,5,6,8],\n",
    "              'max_features':[5,6,7,8,9],\n",
    "              'n_estimators': [200,500]}\n",
    "grid = GridSearchCV(RandomForestClassifier(random_state = 12), param_grid, cv=4, scoring = 'f1',verbose=1,n_jobs=-1)\n",
    "smote_best_param_tree = grid.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=12, max_features=9, min_samples_leaf=3,\n",
       "                       n_estimators=500, random_state=12)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_best_param_tree.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 8.85575795, 22.65842217,  8.90362871, 21.64658529,  8.96257871,\n",
       "        21.25875986,  8.80620855, 20.87495208,  8.57535845, 20.22389948,\n",
       "         9.25835156, 23.13479239,  9.2835331 , 22.05889034,  9.26998824,\n",
       "        22.75321287,  9.39903533, 22.16897869,  9.13772088, 22.03409719,\n",
       "         9.99937326, 25.12213117, 10.1569432 , 23.81874478, 10.05259699,\n",
       "        22.75183266,  9.26846784, 22.83906549,  9.05323428, 24.17038846,\n",
       "        10.73162788, 26.87585992, 10.73479491, 26.71404225, 10.8984428 ,\n",
       "        26.9938997 , 10.76804894, 26.96274179, 10.82017672, 26.17323714,\n",
       "        11.53905791, 27.73356152, 11.05438912, 29.11298174, 11.66665167,\n",
       "        28.60689712, 11.44574714, 28.61561739, 11.66660798, 28.96423811,\n",
       "        11.65117633, 28.82143307, 11.73321772, 29.03970504, 11.68036205,\n",
       "        28.70503742, 11.68770272, 28.53813273, 11.66772628, 28.49996734,\n",
       "        12.74949187, 32.22724897, 12.98552662, 31.11390001, 13.59743571,\n",
       "        30.97744244, 12.15056092, 31.9606384 , 12.91028374, 31.99497181,\n",
       "        14.50399661, 35.66511965, 14.37037295, 35.74059123, 14.38661808,\n",
       "        35.84176618, 14.44553399, 35.48245716, 14.46338856, 35.561854  ,\n",
       "        15.95972532, 39.31331593, 15.91911376, 39.33610147, 16.05031669,\n",
       "        38.95787245, 15.97506744, 38.98918068, 15.47472191, 39.231121  ,\n",
       "        17.37178087, 42.75443721, 17.20371097, 42.66146594, 17.21696204,\n",
       "        42.64100683, 17.24517852, 42.08528286, 17.08188993, 42.26863867,\n",
       "        14.09311217, 33.88991457, 13.83259499, 34.41112494, 13.75901616,\n",
       "        33.57205105, 13.9501996 , 32.34048456, 12.87546152, 33.02935714,\n",
       "        14.78745496, 38.70695746, 15.561248  , 38.94320875, 15.89584589,\n",
       "        38.48596925, 15.79805207, 37.45067787, 15.50398743, 36.67114073,\n",
       "        16.48609185, 41.67275131, 17.28658408, 41.44066298, 16.85233092,\n",
       "        41.98758882, 16.66089898, 42.59721023, 17.37905556, 42.79392773,\n",
       "        19.32829851, 47.69935071, 19.21987879, 47.09991825, 19.1694504 ,\n",
       "        46.94604343, 19.1054706 , 47.40707171, 19.18290865, 47.53343868,\n",
       "        21.10074133, 52.36777729, 21.03989661, 51.91160595, 20.97497827,\n",
       "        51.86162251, 20.93626076, 52.00318742, 20.86158037, 51.59466457,\n",
       "        16.20261627, 40.06266171, 16.15825874, 39.49891156, 16.1494838 ,\n",
       "        39.9834379 , 16.28271979, 39.33424377, 15.83804566, 39.86279625,\n",
       "        18.32728243, 44.02419895, 18.40519321, 44.09900439, 17.4691124 ,\n",
       "        45.00453693, 18.14942753, 44.96251667, 18.11851388, 44.08707416,\n",
       "        20.48776454, 48.70619684, 19.88082594, 49.63325703, 19.37694567,\n",
       "        50.1264782 , 20.38837534, 50.25341207, 20.2464844 , 50.10530263,\n",
       "        22.93794543, 56.39252585, 22.53993249, 55.77503657, 22.81968695,\n",
       "        55.87256896, 22.57745403, 54.74077868, 22.42159081, 54.42848647,\n",
       "        24.14462966, 60.96080607, 24.56215662, 60.33533359, 24.66448498,\n",
       "        59.82921118, 23.54916584, 53.82601845, 24.10034901, 45.55850738]),\n",
       " 'std_fit_time': array([0.21072687, 0.36735549, 0.37119715, 0.35780616, 0.16408063,\n",
       "        0.30400921, 0.07304427, 0.18285679, 0.14342777, 0.25007237,\n",
       "        0.14695781, 0.16376498, 0.13435613, 0.34874767, 0.45694231,\n",
       "        0.66904046, 0.30570386, 0.32734711, 0.20670824, 0.23398203,\n",
       "        0.0919243 , 0.39717345, 0.14597303, 0.33997828, 0.11248475,\n",
       "        0.33171293, 0.0675335 , 0.4219901 , 0.21345388, 0.48541895,\n",
       "        0.32447964, 0.48412011, 0.08552255, 0.10562445, 0.2112988 ,\n",
       "        0.34880333, 0.06383297, 0.48221117, 0.11600867, 0.22542629,\n",
       "        0.12386134, 0.14733848, 0.23394916, 0.33635176, 0.15122979,\n",
       "        0.28235527, 0.12087261, 0.26056033, 0.26318572, 0.34853933,\n",
       "        0.0957631 , 0.14933463, 0.14253553, 0.10672286, 0.040602  ,\n",
       "        0.24385905, 0.117886  , 0.13360459, 0.06258216, 0.06642591,\n",
       "        0.02955529, 0.3904487 , 0.05004314, 0.56287066, 0.24095914,\n",
       "        0.14351833, 0.11657843, 0.0834447 , 0.11029349, 0.17011955,\n",
       "        0.12030305, 0.23961852, 0.07714667, 0.14195689, 0.07090442,\n",
       "        0.25728189, 0.08227848, 0.07430766, 0.0715172 , 0.14523925,\n",
       "        0.12962915, 0.17627857, 0.11035406, 0.12972359, 0.07111627,\n",
       "        0.16198259, 0.04340669, 0.05643326, 0.05320681, 0.10084409,\n",
       "        0.04896429, 0.13082866, 0.12497315, 0.14612278, 0.06564967,\n",
       "        0.16701576, 0.10682592, 0.22831438, 0.10532457, 0.42615137,\n",
       "        0.38366931, 0.15634839, 0.17160324, 0.19788592, 0.07139545,\n",
       "        0.06109695, 0.06632793, 0.18638706, 0.08622204, 0.3956147 ,\n",
       "        0.09681211, 0.27122762, 0.16764109, 0.25755508, 0.22460315,\n",
       "        0.21056107, 0.12519392, 0.27119044, 0.10583167, 0.38540626,\n",
       "        0.45453918, 0.10518538, 0.31784755, 0.27419794, 0.10417436,\n",
       "        0.3707233 , 0.15330191, 0.22456592, 0.09069346, 0.22387723,\n",
       "        0.07542054, 0.14377652, 0.05751161, 0.67472943, 0.32653333,\n",
       "        0.13343639, 0.0912346 , 0.26167868, 0.11944046, 0.17042022,\n",
       "        0.20167673, 0.1359871 , 0.08965248, 0.44467949, 0.08887304,\n",
       "        0.22759951, 0.0370273 , 0.11587374, 0.04752751, 0.12351789,\n",
       "        0.18119678, 0.37590202, 0.03640679, 0.47131435, 0.10860659,\n",
       "        0.50965216, 0.11034326, 0.27816131, 0.16109889, 0.18868545,\n",
       "        0.30446684, 0.64703151, 0.23184555, 0.20461541, 0.11071481,\n",
       "        0.26280402, 0.087754  , 0.15881687, 0.08332363, 0.10879265,\n",
       "        0.01772265, 0.08707694, 0.05352411, 0.29828334, 0.20282552,\n",
       "        0.21494325, 0.08271292, 0.52454453, 0.18523823, 0.30706262,\n",
       "        0.03161649, 0.28491501, 0.14209572, 0.06584555, 0.21288706,\n",
       "        0.34298989, 0.03407056, 0.43219658, 0.08921305, 0.71310359,\n",
       "        0.19487579, 0.40104046, 0.06973169, 0.83076563, 0.29303793,\n",
       "        0.67697167, 0.28077083, 0.55296572, 0.36829759, 0.28650163]),\n",
       " 'mean_score_time': array([0.60421026, 1.52153951, 0.60937649, 1.49405181, 0.64612442,\n",
       "        1.47973746, 0.63728535, 1.47508293, 0.59518498, 1.49701768,\n",
       "        0.61959809, 1.52972049, 0.60485744, 1.48255759, 0.64763767,\n",
       "        1.44388926, 0.63827056, 1.49672365, 0.60937023, 1.49338871,\n",
       "        0.6163606 , 1.45494521, 0.63205922, 1.32807016, 0.62872899,\n",
       "        1.28795546, 0.53467858, 1.45899773, 0.55692661, 1.44514978,\n",
       "        0.63219237, 1.48496795, 0.62033057, 1.46380943, 0.61086649,\n",
       "        1.46121526, 0.57458448, 1.47731471, 0.62358385, 1.44495577,\n",
       "        0.60953927, 1.49300784, 0.58296555, 1.54600692, 0.609034  ,\n",
       "        1.50075155, 0.61111563, 1.47480685, 0.62009221, 1.52542228,\n",
       "        0.76669914, 1.88582897, 0.81955957, 1.88374513, 0.7831549 ,\n",
       "        1.9087584 , 0.76945883, 1.84008014, 0.76817477, 1.92021477,\n",
       "        0.76355988, 1.64881992, 0.78639674, 1.88937247, 0.78437781,\n",
       "        1.91120815, 0.79138571, 1.85573924, 0.77984899, 1.87117285,\n",
       "        0.7783978 , 1.94155878, 0.75991178, 1.88422465, 0.7774207 ,\n",
       "        1.91014159, 0.78098243, 1.91725349, 0.78440231, 1.9096427 ,\n",
       "        0.80597293, 1.90167689, 0.79637122, 1.90887493, 0.78641075,\n",
       "        1.87758082, 0.80465651, 1.9375369 , 0.7623291 , 1.92286354,\n",
       "        0.81357306, 1.92637098, 0.78889114, 1.84530419, 0.79249144,\n",
       "        1.92875218, 0.79485971, 1.73574388, 0.76848567, 1.89348394,\n",
       "        0.75176823, 2.2138291 , 0.88338727, 2.24424809, 0.89635384,\n",
       "        2.03901839, 0.88762611, 2.19092596, 0.79166347, 2.21682209,\n",
       "        0.88987011, 2.19807285, 0.91106385, 2.25035828, 0.927001  ,\n",
       "        2.17372084, 0.90778899, 2.06618392, 0.89100647, 2.24907696,\n",
       "        0.87612522, 2.03410071, 0.91654885, 2.1489529 , 0.84451407,\n",
       "        2.24587148, 0.88169527, 2.19959879, 0.87977123, 2.14211398,\n",
       "        0.92549282, 2.1631645 , 0.90338504, 2.199624  , 0.83606911,\n",
       "        2.25670379, 0.91751873, 2.23633605, 0.91505241, 2.22078788,\n",
       "        0.92305851, 2.27900153, 0.89921457, 2.25135446, 0.91405636,\n",
       "        2.26620853, 0.92897362, 2.2282725 , 0.91125488, 2.25884485,\n",
       "        1.03043044, 2.53958726, 1.02301991, 2.46676344, 1.03661919,\n",
       "        2.51378095, 1.00059694, 2.443609  , 0.93193287, 2.52633673,\n",
       "        1.00882834, 2.52921283, 1.06433547, 2.52922153, 1.03844827,\n",
       "        2.48479694, 1.0260731 , 2.43827075, 1.0287146 , 2.25449944,\n",
       "        1.03142363, 2.55604923, 1.00646389, 2.52434814, 1.05731219,\n",
       "        2.51511735, 1.03421408, 2.54843408, 1.03245258, 2.41636759,\n",
       "        1.04905134, 2.56880617, 1.01759964, 2.56998962, 1.04239422,\n",
       "        2.47501671, 1.01486272, 2.44460046, 0.97676259, 2.48555207,\n",
       "        1.04765111, 2.56692821, 1.01236475, 2.60852545, 1.01775217,\n",
       "        1.9446727 , 1.00907177, 2.1578058 , 0.76868427, 1.91542786]),\n",
       " 'std_score_time': array([0.03393246, 0.06912899, 0.01303165, 0.01739696, 0.02987557,\n",
       "        0.02583167, 0.03295374, 0.05078571, 0.04056827, 0.04333273,\n",
       "        0.02892298, 0.03714307, 0.00917079, 0.0153031 , 0.07666957,\n",
       "        0.01942126, 0.01301664, 0.05074085, 0.02708389, 0.02246328,\n",
       "        0.03641859, 0.01580439, 0.03049866, 0.04932517, 0.0152084 ,\n",
       "        0.01846314, 0.0177844 , 0.02337924, 0.07345129, 0.04918927,\n",
       "        0.02626294, 0.05213636, 0.04748768, 0.04465459, 0.02636313,\n",
       "        0.03498723, 0.03283557, 0.01971526, 0.0189409 , 0.02461514,\n",
       "        0.00890356, 0.02962706, 0.02407427, 0.04502527, 0.01689394,\n",
       "        0.00881805, 0.03977669, 0.01310614, 0.03238182, 0.02194704,\n",
       "        0.01879764, 0.01821997, 0.0211373 , 0.02694336, 0.00990732,\n",
       "        0.0404772 , 0.02131793, 0.02692774, 0.02208108, 0.02292992,\n",
       "        0.01638615, 0.03940314, 0.01696134, 0.03223336, 0.00386526,\n",
       "        0.04654582, 0.02351844, 0.04877076, 0.01919296, 0.03178288,\n",
       "        0.0112985 , 0.03962157, 0.01313645, 0.04725617, 0.00699974,\n",
       "        0.05576758, 0.04276053, 0.03338687, 0.01523153, 0.01975017,\n",
       "        0.02529514, 0.02918221, 0.01675533, 0.02225472, 0.00943516,\n",
       "        0.04664379, 0.01444496, 0.02418034, 0.04788098, 0.04680791,\n",
       "        0.02145356, 0.0372605 , 0.00462469, 0.01107894, 0.02954565,\n",
       "        0.02383233, 0.02870654, 0.07312193, 0.01450302, 0.03530993,\n",
       "        0.02086567, 0.03943214, 0.01637956, 0.02964863, 0.0311849 ,\n",
       "        0.02178606, 0.02492439, 0.02293221, 0.03063313, 0.03805902,\n",
       "        0.02442325, 0.0543974 , 0.02231845, 0.07373646, 0.03670637,\n",
       "        0.0298968 , 0.02122205, 0.08512442, 0.02014176, 0.04958109,\n",
       "        0.03231868, 0.0224128 , 0.03444017, 0.02814405, 0.02488639,\n",
       "        0.02616271, 0.02164942, 0.01819541, 0.02102251, 0.02440295,\n",
       "        0.02979077, 0.0216503 , 0.02836666, 0.0330635 , 0.01512813,\n",
       "        0.03925457, 0.00689779, 0.04062575, 0.02159345, 0.02387687,\n",
       "        0.04024194, 0.02773082, 0.02673209, 0.02886126, 0.01826128,\n",
       "        0.0272999 , 0.02438485, 0.04605493, 0.0087246 , 0.01969641,\n",
       "        0.03871952, 0.12945178, 0.0253766 , 0.03208969, 0.02807428,\n",
       "        0.08638125, 0.01903121, 0.04705783, 0.0323903 , 0.28771694,\n",
       "        0.0250728 , 0.03318216, 0.0563528 , 0.05285917, 0.01763807,\n",
       "        0.01703179, 0.02000464, 0.04668536, 0.04034841, 0.18236599,\n",
       "        0.01742373, 0.02668659, 0.03862842, 0.03629129, 0.004805  ,\n",
       "        0.08004442, 0.03743209, 0.03171656, 0.01918065, 0.03814354,\n",
       "        0.01671613, 0.0355508 , 0.03162757, 0.03899332, 0.02741331,\n",
       "        0.1355856 , 0.01812387, 0.02635668, 0.02987412, 0.02678734,\n",
       "        0.02452475, 0.06167746, 0.0508725 , 0.08805298, 0.00750338,\n",
       "        0.07035937, 0.03531109, 0.12615687, 0.0831646 , 0.07635728]),\n",
       " 'param_max_depth': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10,\n",
       "                    10, 10, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "                    12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "                    12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
       "                    12, 12, 12, 12, 12, 12, 12, 12, 12, 12],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6,\n",
       "                    6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
       "                    8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 5, 5, 5,\n",
       "                    5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7,\n",
       "                    7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "                    9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 5, 5, 5, 5, 5, 5, 5, 5,\n",
       "                    5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
       "                    7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9,\n",
       "                    9, 9, 9, 9, 9, 9, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6,\n",
       "                    6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7,\n",
       "                    8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9,\n",
       "                    9, 9],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_min_samples_leaf': masked_array(data=[3, 3, 4, 4, 5, 5, 6, 6, 8, 8, 3, 3, 4, 4, 5, 5, 6, 6,\n",
       "                    8, 8, 3, 3, 4, 4, 5, 5, 6, 6, 8, 8, 3, 3, 4, 4, 5, 5,\n",
       "                    6, 6, 8, 8, 3, 3, 4, 4, 5, 5, 6, 6, 8, 8, 3, 3, 4, 4,\n",
       "                    5, 5, 6, 6, 8, 8, 3, 3, 4, 4, 5, 5, 6, 6, 8, 8, 3, 3,\n",
       "                    4, 4, 5, 5, 6, 6, 8, 8, 3, 3, 4, 4, 5, 5, 6, 6, 8, 8,\n",
       "                    3, 3, 4, 4, 5, 5, 6, 6, 8, 8, 3, 3, 4, 4, 5, 5, 6, 6,\n",
       "                    8, 8, 3, 3, 4, 4, 5, 5, 6, 6, 8, 8, 3, 3, 4, 4, 5, 5,\n",
       "                    6, 6, 8, 8, 3, 3, 4, 4, 5, 5, 6, 6, 8, 8, 3, 3, 4, 4,\n",
       "                    5, 5, 6, 6, 8, 8, 3, 3, 4, 4, 5, 5, 6, 6, 8, 8, 3, 3,\n",
       "                    4, 4, 5, 5, 6, 6, 8, 8, 3, 3, 4, 4, 5, 5, 6, 6, 8, 8,\n",
       "                    3, 3, 4, 4, 5, 5, 6, 6, 8, 8, 3, 3, 4, 4, 5, 5, 6, 6,\n",
       "                    8, 8],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500, 200, 500, 200, 500, 200, 500, 200, 500, 200,\n",
       "                    500, 200, 500, 200, 500, 200, 500, 200, 500, 200, 500,\n",
       "                    200, 500],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 5,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 5,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 8,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 10,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 5,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 6,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 7,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 8,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 3,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 4,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 5,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 6,\n",
       "   'n_estimators': 500},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 200},\n",
       "  {'max_depth': 12,\n",
       "   'max_features': 9,\n",
       "   'min_samples_leaf': 8,\n",
       "   'n_estimators': 500}],\n",
       " 'split0_test_score': array([0.00171233, 0.00512821, 0.        , 0.00342173, 0.        ,\n",
       "        0.00171233, 0.00171233, 0.00171233, 0.00171233, 0.00171233,\n",
       "        0.05337781, 0.05337781, 0.05012531, 0.04849498, 0.05012531,\n",
       "        0.04849498, 0.04522613, 0.04849498, 0.04522613, 0.05012531,\n",
       "        0.06307054, 0.07107438, 0.06628003, 0.07425743, 0.06467662,\n",
       "        0.06467662, 0.06146179, 0.06788079, 0.05337781, 0.06467662,\n",
       "        0.12980769, 0.14319809, 0.13429257, 0.14171975, 0.11470113,\n",
       "        0.13875598, 0.11317704, 0.13875598, 0.11925866, 0.14467409,\n",
       "        0.1578532 , 0.17513683, 0.1563981 , 0.17370892, 0.15494071,\n",
       "        0.17370892, 0.1563981 , 0.17227878, 0.1563981 , 0.17227878,\n",
       "        0.11925866, 0.13875598, 0.12077295, 0.12379421, 0.12680578,\n",
       "        0.12980769, 0.12077295, 0.14614774, 0.09001637, 0.12077295,\n",
       "        0.16509434, 0.1765625 , 0.16941176, 0.17513683, 0.17227878,\n",
       "        0.17370892, 0.16365067, 0.16797488, 0.16653574, 0.16509434,\n",
       "        0.19907407, 0.19629057, 0.19489559, 0.19349845, 0.19209915,\n",
       "        0.19489559, 0.18648019, 0.18929403, 0.18506998, 0.19054996,\n",
       "        0.21543163, 0.21423106, 0.21526718, 0.21526718, 0.20980092,\n",
       "        0.20980092, 0.21117062, 0.21374046, 0.21237586, 0.21390374,\n",
       "        0.22070015, 0.22475323, 0.22340426, 0.22610015, 0.22070015,\n",
       "        0.22070015, 0.21934501, 0.22205323, 0.2179878 , 0.22340426,\n",
       "        0.17798595, 0.17940718, 0.1765625 , 0.18224299, 0.17513683,\n",
       "        0.18365759, 0.16797488, 0.17940718, 0.15494071, 0.17227878,\n",
       "        0.20737327, 0.20461538, 0.20980092, 0.20445811, 0.19305019,\n",
       "        0.19180201, 0.19489559, 0.19349845, 0.19054996, 0.18900077,\n",
       "        0.22070015, 0.22103659, 0.2179878 , 0.2179878 , 0.21679389,\n",
       "        0.22086824, 0.21543163, 0.22205323, 0.21679389, 0.21662853,\n",
       "        0.22995461, 0.23146747, 0.23413897, 0.23396226, 0.2351168 ,\n",
       "        0.23413897, 0.23012869, 0.22861469, 0.23129252, 0.22995461,\n",
       "        0.24096386, 0.23963828, 0.24078254, 0.24210526, 0.23030303,\n",
       "        0.2354717 , 0.23662396, 0.23813112, 0.23413897, 0.23280423,\n",
       "        0.1976834 , 0.201849  , 0.19629057, 0.20445811, 0.18914729,\n",
       "        0.20030817, 0.19069767, 0.19209915, 0.18774244, 0.18774244,\n",
       "        0.22475323, 0.22070015, 0.22053232, 0.21662853, 0.21390374,\n",
       "        0.21782178, 0.22053232, 0.21646341, 0.22053232, 0.21782178,\n",
       "        0.23680241, 0.23529412, 0.2354717 , 0.23146747, 0.22744503,\n",
       "        0.23012869, 0.23146747, 0.23012869, 0.2245827 , 0.22475323,\n",
       "        0.25392084, 0.24981301, 0.24456114, 0.24324324, 0.24587706,\n",
       "        0.24587706, 0.24587706, 0.24324324, 0.23680241, 0.23662396,\n",
       "        0.25983667, 0.2611276 , 0.25763217, 0.25912137, 0.25763217,\n",
       "        0.25873606, 0.24850299, 0.24737631, 0.24831713, 0.25112108]),\n",
       " 'split1_test_score': array([0.01192504, 0.02035623, 0.01192504, 0.01867572, 0.01361702,\n",
       "        0.01867572, 0.01023018, 0.01699235, 0.01192504, 0.01530612,\n",
       "        0.03535354, 0.03700589, 0.03535354, 0.03865546, 0.03535354,\n",
       "        0.04030227, 0.03700589, 0.04030227, 0.03535354, 0.0336984 ,\n",
       "        0.04030227, 0.05012531, 0.04030227, 0.04686192, 0.04030227,\n",
       "        0.04686192, 0.04030227, 0.04522613, 0.04030227, 0.04686192,\n",
       "        0.09934853, 0.12228479, 0.08216927, 0.11774194, 0.06307054,\n",
       "        0.11925866, 0.07266722, 0.11622276, 0.06947891, 0.11774194,\n",
       "        0.14171975, 0.152019  , 0.14750198, 0.152019  , 0.15189873,\n",
       "        0.152019  , 0.14885194, 0.15494071, 0.14750198, 0.152019  ,\n",
       "        0.10705596, 0.11925866, 0.11470113, 0.12680578, 0.11012146,\n",
       "        0.11925866, 0.10243902, 0.11470113, 0.09934853, 0.11622276,\n",
       "        0.14603175, 0.15481833, 0.14023904, 0.15481833, 0.14319809,\n",
       "        0.14896989, 0.14319809, 0.15335968, 0.1341853 , 0.14455917,\n",
       "        0.16627451, 0.16627451, 0.16062992, 0.16496465, 0.16194969,\n",
       "        0.1661442 , 0.15905512, 0.16339356, 0.16326531, 0.16588419,\n",
       "        0.19275251, 0.19135802, 0.17912773, 0.1859024 , 0.19290123,\n",
       "        0.18421053, 0.18435321, 0.18561485, 0.18153607, 0.17998448,\n",
       "        0.19785276, 0.20367534, 0.20229885, 0.20229885, 0.19121049,\n",
       "        0.19538462, 0.19121049, 0.19523444, 0.18421053, 0.18952234,\n",
       "        0.14908803, 0.15918046, 0.15189873, 0.15918046, 0.14908803,\n",
       "        0.15772871, 0.1473851 , 0.15627466, 0.14750198, 0.15189873,\n",
       "        0.17200938, 0.17472699, 0.17200938, 0.17214397, 0.17316693,\n",
       "        0.16901408, 0.16627451, 0.1677116 , 0.1660141 , 0.1661442 ,\n",
       "        0.20107444, 0.19953952, 0.19135802, 0.20229885, 0.19414484,\n",
       "        0.19523444, 0.19135802, 0.19245574, 0.18745159, 0.18841699,\n",
       "        0.22003035, 0.21867882, 0.21564161, 0.21292776, 0.21189024,\n",
       "        0.21172887, 0.20626432, 0.21036585, 0.20884146, 0.20594966,\n",
       "        0.22908817, 0.22908817, 0.22524565, 0.22792453, 0.22272727,\n",
       "        0.22255867, 0.22104466, 0.22239032, 0.21818182, 0.2193646 ,\n",
       "        0.1777085 , 0.18337218, 0.17757009, 0.17743191, 0.16914644,\n",
       "        0.17017955, 0.16483516, 0.16784314, 0.1657545 , 0.16588419,\n",
       "        0.20779221, 0.20779221, 0.20811018, 0.20383142, 0.19953952,\n",
       "        0.19245574, 0.19677171, 0.19230769, 0.18421053, 0.18266254,\n",
       "        0.22524565, 0.22373394, 0.21699545, 0.22104466, 0.21428571,\n",
       "        0.21716021, 0.21020564, 0.215478  , 0.20731707, 0.20988593,\n",
       "        0.23423423, 0.23573574, 0.23157895, 0.23042169, 0.23042169,\n",
       "        0.23024831, 0.23308271, 0.22891566, 0.21666667, 0.22071051,\n",
       "        0.24011931, 0.24292101, 0.24047797, 0.23916293, 0.23952096,\n",
       "        0.23705926, 0.23688156, 0.23388306, 0.23140496, 0.23140496]),\n",
       " 'split2_test_score': array([0.00512821, 0.01192504, 0.00512821, 0.01023018, 0.00342173,\n",
       "        0.01192504, 0.00342173, 0.01192504, 0.00342173, 0.00683177,\n",
       "        0.03865546, 0.0336984 , 0.04358759, 0.03865546, 0.04194631,\n",
       "        0.04194631, 0.04194631, 0.04194631, 0.03865546, 0.03865546,\n",
       "        0.05175292, 0.06146179, 0.05012531, 0.05985037, 0.05985037,\n",
       "        0.05985037, 0.05985037, 0.05985037, 0.05985037, 0.05985037,\n",
       "        0.13875598, 0.14908803, 0.12980769, 0.14467409, 0.12680578,\n",
       "        0.14467409, 0.11774194, 0.14171975, 0.12379421, 0.14908803,\n",
       "        0.18478261, 0.18365759, 0.1777085 , 0.18365759, 0.1777085 ,\n",
       "        0.18210117, 0.1735731 , 0.18351477, 0.17370892, 0.18351477,\n",
       "        0.11317704, 0.13130504, 0.11925866, 0.1253012 , 0.1328    ,\n",
       "        0.12830794, 0.1328    , 0.13429257, 0.10243902, 0.10858995,\n",
       "        0.16509434, 0.18365759, 0.16941176, 0.17227878, 0.16509434,\n",
       "        0.17798595, 0.16365067, 0.17513683, 0.15930599, 0.17370892,\n",
       "        0.19474498, 0.19459459, 0.19209915, 0.19489559, 0.19195046,\n",
       "        0.19209915, 0.19180201, 0.19195046, 0.18900077, 0.19040248,\n",
       "        0.20811018, 0.21237586, 0.20980092, 0.21237586, 0.21100917,\n",
       "        0.20948012, 0.20673813, 0.21205187, 0.20948012, 0.20916031,\n",
       "        0.21986353, 0.22104466, 0.22373394, 0.22255867, 0.21699545,\n",
       "        0.21953066, 0.21156773, 0.21428571, 0.20868241, 0.21276596,\n",
       "        0.18365759, 0.1878882 , 0.17513683, 0.18224299, 0.17940718,\n",
       "        0.18648019, 0.17798595, 0.18224299, 0.16365067, 0.18224299,\n",
       "        0.21357742, 0.20689655, 0.20430108, 0.20276498, 0.20689655,\n",
       "        0.20414428, 0.20383142, 0.19969278, 0.196139  , 0.19135802,\n",
       "        0.22121212, 0.21969697, 0.22675737, 0.22541604, 0.21084798,\n",
       "        0.21172887, 0.21461187, 0.21444867, 0.20721412, 0.20763359,\n",
       "        0.23308271, 0.23705926, 0.23573574, 0.23290759, 0.22926094,\n",
       "        0.22758101, 0.22908817, 0.22891566, 0.22339623, 0.22322775,\n",
       "        0.23652695, 0.23916293, 0.23405851, 0.23784592, 0.23520599,\n",
       "        0.23388306, 0.23273273, 0.23388306, 0.23370787, 0.23502994,\n",
       "        0.20122888, 0.20536398, 0.20673813, 0.20292083, 0.19040248,\n",
       "        0.19984627, 0.20138355, 0.20138355, 0.18841699, 0.19523444,\n",
       "        0.22926094, 0.22121212, 0.21716021, 0.21699545, 0.21580547,\n",
       "        0.2130898 , 0.20779221, 0.21052632, 0.21444867, 0.21052632,\n",
       "        0.23308271, 0.23423423, 0.22775264, 0.22891566, 0.23441022,\n",
       "        0.23024831, 0.22507553, 0.22607385, 0.21683093, 0.21666667,\n",
       "        0.2514881 , 0.24981413, 0.24197162, 0.24197162, 0.2406577 ,\n",
       "        0.24459359, 0.24047797, 0.23784592, 0.23652695, 0.23238381,\n",
       "        0.26529108, 0.2674504 , 0.25481481, 0.25997046, 0.25241277,\n",
       "        0.25720621, 0.24944321, 0.2546262 , 0.24590164, 0.25203855]),\n",
       " 'split3_test_score': array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00171233, 0.        , 0.00171233,\n",
       "        0.03700589, 0.03535354, 0.03037975, 0.02871622, 0.02871622,\n",
       "        0.02538071, 0.01867572, 0.0220339 , 0.01867572, 0.02538071,\n",
       "        0.06467662, 0.06947891, 0.06467662, 0.06947891, 0.06146179,\n",
       "        0.06467662, 0.05985037, 0.06146179, 0.055     , 0.06146179,\n",
       "        0.13429257, 0.15348101, 0.12680578, 0.15348101, 0.12980769,\n",
       "        0.15055468, 0.13578275, 0.15494071, 0.12980769, 0.15348101,\n",
       "        0.16797488, 0.18224299, 0.16653574, 0.18365759, 0.17084639,\n",
       "        0.17940718, 0.17227878, 0.18224299, 0.16941176, 0.18082619,\n",
       "        0.10551948, 0.1253012 , 0.08374384, 0.11925866, 0.12228479,\n",
       "        0.12680578, 0.08374384, 0.13727055, 0.08374384, 0.12228479,\n",
       "        0.16653574, 0.18224299, 0.16797488, 0.18082619, 0.1607565 ,\n",
       "        0.17784711, 0.16496465, 0.17784711, 0.16220472, 0.175     ,\n",
       "        0.20030817, 0.20445811, 0.20046261, 0.201849  , 0.19876733,\n",
       "        0.20445811, 0.19489559, 0.20138355, 0.18492618, 0.1933488 ,\n",
       "        0.21917808, 0.21884498, 0.21493902, 0.21884498, 0.21221374,\n",
       "        0.21341463, 0.21374046, 0.21390374, 0.2096404 , 0.21205187,\n",
       "        0.22441243, 0.22960725, 0.2245827 , 0.23111782, 0.22441243,\n",
       "        0.22675737, 0.22272727, 0.22809668, 0.22306525, 0.22541604,\n",
       "        0.16653574, 0.18365759, 0.17940718, 0.1878882 , 0.17940718,\n",
       "        0.18224299, 0.1735731 , 0.17926734, 0.14908803, 0.17084639,\n",
       "        0.20583717, 0.20996169, 0.20980092, 0.21100917, 0.20445811,\n",
       "        0.2056792 , 0.19459459, 0.20414428, 0.19707467, 0.19984627,\n",
       "        0.22844175, 0.22844175, 0.21477532, 0.22541604, 0.22323462,\n",
       "        0.22019742, 0.21884498, 0.21613394, 0.21461187, 0.21068702,\n",
       "        0.23891811, 0.24006002, 0.23891811, 0.23891811, 0.23343373,\n",
       "        0.23609023, 0.23476298, 0.23741548, 0.23476298, 0.23210249,\n",
       "        0.24269663, 0.24532536, 0.23873874, 0.24269663, 0.23873874,\n",
       "        0.24382947, 0.23855964, 0.23988006, 0.23705926, 0.23838081,\n",
       "        0.20874904, 0.21543163, 0.1976834 , 0.20721412, 0.19054996,\n",
       "        0.20030817, 0.1863354 , 0.20030817, 0.19290123, 0.19319938,\n",
       "        0.23343373, 0.22943396, 0.22744503, 0.22424242, 0.22826909,\n",
       "        0.22727273, 0.22675737, 0.22558668, 0.22137983, 0.21732523,\n",
       "        0.24024024, 0.23891811, 0.23909774, 0.24024024, 0.23360965,\n",
       "        0.23741548, 0.23609023, 0.23343373, 0.23076923, 0.2309434 ,\n",
       "        0.24813154, 0.25316456, 0.24906786, 0.24925373, 0.24401198,\n",
       "        0.24794623, 0.24532536, 0.24663677, 0.24251497, 0.24233358,\n",
       "        0.25705795, 0.25925926, 0.25667656, 0.25796887, 0.24663677,\n",
       "        0.25538233, 0.24869695, 0.2526003 , 0.24739195, 0.24869695]),\n",
       " 'mean_test_score': array([0.00469139, 0.00935237, 0.00426331, 0.00808191, 0.00425969,\n",
       "        0.00807827, 0.00384106, 0.00808551, 0.00426477, 0.00639064,\n",
       "        0.04109817, 0.03985891, 0.03986155, 0.03863053, 0.03903534,\n",
       "        0.03903107, 0.03571351, 0.03819436, 0.03447771, 0.03696497,\n",
       "        0.05495059, 0.0630351 , 0.05534606, 0.06261216, 0.05657276,\n",
       "        0.05901638, 0.0553662 , 0.05860477, 0.05213261, 0.05821268,\n",
       "        0.12555119, 0.14201298, 0.11826883, 0.13940419, 0.10859629,\n",
       "        0.13831085, 0.10984224, 0.1379098 , 0.11058487, 0.14124626,\n",
       "        0.16308261, 0.1732641 , 0.16203608, 0.17326077, 0.16384858,\n",
       "        0.17180907, 0.16277548, 0.17324431, 0.16175519, 0.17215969,\n",
       "        0.11125279, 0.12865522, 0.10961915, 0.12378996, 0.12300301,\n",
       "        0.12604502, 0.10993895, 0.133103  , 0.09388694, 0.11696761,\n",
       "        0.16068904, 0.17432035, 0.16175936, 0.17076503, 0.16033193,\n",
       "        0.16962797, 0.15886602, 0.16857963, 0.15555794, 0.16459061,\n",
       "        0.19010043, 0.19040445, 0.18702182, 0.18880192, 0.18619166,\n",
       "        0.18939926, 0.18305823, 0.1865054 , 0.18056556, 0.18504636,\n",
       "        0.2088681 , 0.20920248, 0.20478371, 0.20809761, 0.20648127,\n",
       "        0.20422655, 0.20400061, 0.20632773, 0.20325811, 0.2037751 ,\n",
       "        0.21570722, 0.21977012, 0.21850494, 0.22051887, 0.21332963,\n",
       "        0.2155932 , 0.21121263, 0.21491751, 0.2084865 , 0.21277715,\n",
       "        0.16931683, 0.17753335, 0.17075131, 0.17788866, 0.1707598 ,\n",
       "        0.17752737, 0.16672976, 0.17429804, 0.15379535, 0.16931672,\n",
       "        0.19969931, 0.19905015, 0.19897807, 0.19759406, 0.19439295,\n",
       "        0.19265989, 0.18989903, 0.19126178, 0.18744443, 0.18658732,\n",
       "        0.21785712, 0.21717871, 0.21271963, 0.21777968, 0.21125533,\n",
       "        0.21200724, 0.21006163, 0.21127289, 0.20651787, 0.20584153,\n",
       "        0.23049644, 0.23181639, 0.23110861, 0.22967893, 0.22742543,\n",
       "        0.22738477, 0.22506104, 0.22632792, 0.2245733 , 0.22280863,\n",
       "        0.2373189 , 0.23830368, 0.23470636, 0.23764309, 0.23174376,\n",
       "        0.23393572, 0.23224025, 0.23357114, 0.23077198, 0.2313949 ,\n",
       "        0.19634245, 0.2015042 , 0.19457055, 0.19800624, 0.18481154,\n",
       "        0.19266054, 0.18581295, 0.1904085 , 0.18370379, 0.18551511,\n",
       "        0.22381003, 0.21978461, 0.21831194, 0.21542445, 0.21437946,\n",
       "        0.21266001, 0.2129634 , 0.21122102, 0.21014284, 0.20708397,\n",
       "        0.23384275, 0.2330451 , 0.22982938, 0.23041701, 0.22743765,\n",
       "        0.22873817, 0.22570972, 0.22627857, 0.21987498, 0.22056231,\n",
       "        0.24694368, 0.24713186, 0.24179489, 0.24122257, 0.24024211,\n",
       "        0.2421663 , 0.24119077, 0.2391604 , 0.23312775, 0.23301297,\n",
       "        0.25557626, 0.25768957, 0.25240038, 0.25405591, 0.24905067,\n",
       "        0.25209597, 0.24588118, 0.24712147, 0.24325392, 0.24581538]),\n",
       " 'std_test_score': array([0.00456619, 0.0076324 , 0.00489392, 0.0071393 , 0.00558014,\n",
       "        0.00763032, 0.00388207, 0.00662021, 0.00458513, 0.00555548,\n",
       "        0.00718513, 0.00789226, 0.00757389, 0.00699289, 0.0079294 ,\n",
       "        0.00845595, 0.01026273, 0.00982069, 0.00979097, 0.00895709,\n",
       "        0.00981488, 0.00829594, 0.01072594, 0.01046974, 0.0095531 ,\n",
       "        0.00728874, 0.00872201, 0.00828774, 0.00723349, 0.00677977,\n",
       "        0.01545538, 0.01196012, 0.02101168, 0.01323389, 0.02688574,\n",
       "        0.0117642 , 0.02306739, 0.0139249 , 0.02402571, 0.01392287,\n",
       "        0.01564084, 0.01268371, 0.01127939, 0.01291899, 0.01076122,\n",
       "        0.01182069, 0.0105052 , 0.01142817, 0.01040874, 0.01234613,\n",
       "        0.00543785, 0.00722135, 0.01510534, 0.00282452, 0.00832004,\n",
       "        0.00405931, 0.01859056, 0.01148453, 0.00743019, 0.00532665,\n",
       "        0.00848283, 0.01156837, 0.0124386 , 0.00970732, 0.01071397,\n",
       "        0.01205011, 0.00906177, 0.00949863, 0.01260485, 0.01217591,\n",
       "        0.01391016, 0.01442189, 0.01553192, 0.01412119, 0.01426432,\n",
       "        0.01418684, 0.01418129, 0.01407961, 0.01012122, 0.01112538,\n",
       "        0.01012006, 0.01056834, 0.01497027, 0.01301767, 0.00788671,\n",
       "        0.01165907, 0.01161667, 0.01198054, 0.01259392, 0.01383915,\n",
       "        0.01044948, 0.00977582, 0.00936646, 0.0109501 , 0.01303695,\n",
       "        0.01198551, 0.01223657, 0.01237368, 0.01493466, 0.01426064,\n",
       "        0.01320748, 0.01101214, 0.01099257, 0.01104432, 0.01263308,\n",
       "        0.01153209, 0.01171857, 0.01047332, 0.0063286 , 0.01097256,\n",
       "        0.01624729, 0.01417053, 0.01573144, 0.01501271, 0.01332286,\n",
       "        0.01467356, 0.01413545, 0.01411253, 0.01262181, 0.01247302,\n",
       "        0.01016159, 0.01071473, 0.01308965, 0.00943832, 0.01080641,\n",
       "        0.010332  , 0.0109146 , 0.01122516, 0.0115663 , 0.01056722,\n",
       "        0.00684554, 0.00818784, 0.00909409, 0.00993397, 0.00921911,\n",
       "        0.00957275, 0.01106055, 0.00986974, 0.00997313, 0.01026939,\n",
       "        0.0052578 , 0.00584699, 0.00598132, 0.00591483, 0.00600603,\n",
       "        0.00757769, 0.00679587, 0.00681366, 0.00738238, 0.00722376,\n",
       "        0.01147631, 0.01159483, 0.01060323, 0.01197777, 0.00906066,\n",
       "        0.01298078, 0.01329139, 0.01351397, 0.01055101, 0.01166027,\n",
       "        0.00974408, 0.0077428 , 0.00695963, 0.00734971, 0.01019075,\n",
       "        0.01273355, 0.01158095, 0.01216605, 0.01520885, 0.01439132,\n",
       "        0.0055717 , 0.00564938, 0.00846701, 0.00685008, 0.00805735,\n",
       "        0.00730683, 0.00976839, 0.00675859, 0.00877232, 0.0079764 ,\n",
       "        0.00762026, 0.00672027, 0.00642154, 0.00681548, 0.0059703 ,\n",
       "        0.00698405, 0.00513091, 0.00669418, 0.00979981, 0.00793189,\n",
       "        0.00940268, 0.0090508 , 0.00695756, 0.00862776, 0.00673773,\n",
       "        0.00876225, 0.00520777, 0.00808794, 0.00689507, 0.00840895]),\n",
       " 'rank_test_score': array([196, 191, 198, 193, 199, 194, 200, 192, 197, 195, 181, 183, 182,\n",
       "        186, 184, 185, 189, 187, 190, 188, 179, 171, 178, 172, 176, 173,\n",
       "        177, 174, 180, 175, 159, 151, 162, 153, 169, 154, 167, 155, 165,\n",
       "        152, 141, 126, 143, 127, 140, 130, 142, 128, 145, 129, 164, 157,\n",
       "        168, 160, 161, 158, 166, 156, 170, 163, 146, 124, 144, 131, 147,\n",
       "        134, 148, 137, 149, 139, 105, 104, 110, 108, 113, 107, 119, 112,\n",
       "        120, 116,  78,  77,  86,  80,  83,  87,  88,  84,  90,  89,  60,\n",
       "         54,  55,  51,  65,  61,  74,  63,  79,  67, 135, 122, 133, 121,\n",
       "        132, 123, 138, 125, 150, 136,  92,  93,  94,  96,  99, 101, 106,\n",
       "        102, 109, 111,  57,  59,  68,  58,  72,  70,  76,  71,  82,  85,\n",
       "         35,  30,  33,  38,  41,  42,  46,  43,  47,  49,  21,  19,  22,\n",
       "         20,  31,  23,  29,  25,  34,  32,  97,  91,  98,  95, 117, 100,\n",
       "        114, 103, 118, 115,  48,  53,  56,  62,  64,  69,  66,  73,  75,\n",
       "         81,  24,  27,  37,  36,  40,  39,  45,  44,  52,  50,   9,   7,\n",
       "         14,  15,  17,  13,  16,  18,  26,  28,   2,   1,   4,   3,   6,\n",
       "          5,  10,   8,  12,  11])}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote_best_param_tree.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=12, max_features=9, min_samples_leaf=3,\n",
       "                       n_estimators=500, random_state=12)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest2=RandomForestClassifier(max_depth=12, max_features=9, min_samples_leaf=3,\n",
    "                       n_estimators=500, random_state=12)\n",
    "forest2.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.67%\n",
      "Balanced Accuracy: 57.25%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     12533\n",
      "           1       0.97      0.15      0.25      1169\n",
      "\n",
      "    accuracy                           0.93     13702\n",
      "   macro avg       0.95      0.57      0.61     13702\n",
      "weighted avg       0.93      0.93      0.90     13702\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_promoted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12528</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>999</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0            0    1\n",
       "is_promoted            \n",
       "0            12528    5\n",
       "1              999  170"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = forest2.predict(X_val)\n",
    "print(f\"Accuracy: {round(metrics.accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "print(f\"Balanced Accuracy: {round(metrics.balanced_accuracy_score(Y_val, y_pred)*100, 2)}%\")\n",
    "\n",
    "print(classification_report(Y_val,y_pred))\n",
    "df_confusion = pd.crosstab(Y_val, y_pred)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
